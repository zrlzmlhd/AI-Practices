{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 经典控制环境深度解析\n",
    "\n",
    "---\n",
    "\n",
    "## 核心思想\n",
    "\n",
    "经典控制环境是一组基于**控制论经典问题**设计的低维环境。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本节内容\n",
    "\n",
    "1. **CartPole**: 倒立摆平衡 - 欠驱动系统控制\n",
    "2. **MountainCar**: 爬山车 - 稀疏奖励与探索\n",
    "3. **Pendulum**: 单摆 - 连续控制入门"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import FancyBboxPatch, Circle\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "print(f\"Gymnasium 版本: {gym.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. CartPole - 倒立摆平衡\n",
    "\n",
    "### 运动方程\n",
    "\n",
    "$$\\ddot{\\theta} = \\frac{g\\sin\\theta + \\cos\\theta \\cdot \\frac{-F - m_p l \\dot{\\theta}^2 \\sin\\theta}{m_c + m_p}}{l\\left(\\frac{4}{3} - \\frac{m_p \\cos^2\\theta}{m_c + m_p}\\right)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CartPole-v1 环境详解\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n【状态空间】\")\n",
    "state_vars = [\n",
    "    (\"小车位置 x\", env.observation_space.low[0], env.observation_space.high[0]),\n",
    "    (\"小车速度 ẋ\", env.observation_space.low[1], env.observation_space.high[1]),\n",
    "    (\"摆杆角度 θ\", env.observation_space.low[2], env.observation_space.high[2]),\n",
    "    (\"摆杆角速度 θ̇\", env.observation_space.low[3], env.observation_space.high[3]),\n",
    "]\n",
    "for name, low, high in state_vars:\n",
    "    print(f\"  {name}: [{low:.2f}, {high:.2f}]\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CartPole 系统可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.set_xlim(-3, 3)\n",
    "ax.set_ylim(-0.5, 3)\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "# 地面\n",
    "ax.axhline(y=0, color='brown', linewidth=4)\n",
    "ax.fill_between([-3, 3], [-0.3], [0], color='brown', alpha=0.3)\n",
    "\n",
    "# 小车\n",
    "cart = FancyBboxPatch((-0.4, 0.05), 0.8, 0.3, boxstyle=\"round,pad=0.02\",\n",
    "                       facecolor='steelblue', edgecolor='navy', linewidth=2)\n",
    "ax.add_patch(cart)\n",
    "\n",
    "# 轮子\n",
    "for wx in [-0.25, 0.25]:\n",
    "    wheel = Circle((wx, 0.05), 0.08, facecolor='gray', edgecolor='black')\n",
    "    ax.add_patch(wheel)\n",
    "\n",
    "# 摆杆\n",
    "theta = 0.2\n",
    "pole_length = 2.0\n",
    "pole_x = pole_length * np.sin(theta)\n",
    "pole_y = pole_length * np.cos(theta)\n",
    "ax.plot([0, pole_x], [0.35, 0.35 + pole_y], 'r-', linewidth=10, solid_capstyle='round')\n",
    "ax.plot(pole_x, 0.35 + pole_y, 'ro', markersize=18)\n",
    "\n",
    "ax.set_title('CartPole 系统示意图', fontsize=14)\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CartPole 策略实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_policy(obs):\n",
    "    return np.random.randint(2)\n",
    "\n",
    "def angle_policy(obs):\n",
    "    \"\"\"基于角度的策略\"\"\"\n",
    "    return 1 if obs[2] > 0 else 0\n",
    "\n",
    "def pd_policy(obs):\n",
    "    \"\"\"PD 控制策略\"\"\"\n",
    "    x, x_dot, theta, theta_dot = obs\n",
    "    u_theta = 50 * theta + 10 * theta_dot\n",
    "    u_x = 0.5 * x + 1.0 * x_dot\n",
    "    return 1 if (u_theta + u_x) > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_policy(env_id, policy, n_episodes=50, seed=42):\n",
    "    \"\"\"评估策略\"\"\"\n",
    "    env = gym.make(env_id)\n",
    "    rewards = []\n",
    "    for i in range(n_episodes):\n",
    "        obs, _ = env.reset(seed=seed + i)\n",
    "        total_reward = 0\n",
    "        while True:\n",
    "            action = policy(obs)\n",
    "            obs, reward, terminated, truncated, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "            if terminated or truncated:\n",
    "                break\n",
    "        rewards.append(total_reward)\n",
    "    env.close()\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CartPole 策略评估 (50 回合)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "policies = {\n",
    "    \"随机策略\": random_policy,\n",
    "    \"角度策略\": angle_policy,\n",
    "    \"PD控制\": pd_policy,\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, policy in policies.items():\n",
    "    rewards = evaluate_policy(\"CartPole-v1\", policy)\n",
    "    results[name] = rewards\n",
    "    print(f\"{name:12s}: {np.mean(rewards):6.1f} ± {np.std(rewards):5.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. MountainCar - 稀疏奖励\n",
    "\n",
    "### 动力学方程\n",
    "\n",
    "$$v_{t+1} = v_t + 0.001 \\cdot a - 0.0025 \\cdot \\cos(3x_t)$$\n",
    "$$x_{t+1} = x_t + v_{t+1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"MountainCar-v0\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MountainCar-v0 环境详解\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n位置范围: [{env.observation_space.low[0]:.2f}, {env.observation_space.high[0]:.2f}]\")\n",
    "print(f\"速度范围: [{env.observation_space.low[1]:.3f}, {env.observation_space.high[1]:.3f}]\")\n",
    "print(f\"动作: 0=向左, 1=不动, 2=向右\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 地形和能量可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 左图: 地形\n",
    "ax1 = axes[0]\n",
    "x = np.linspace(-1.2, 0.6, 300)\n",
    "y = np.sin(3 * x) * 0.45 + 0.55\n",
    "\n",
    "ax1.plot(x, y, 'b-', linewidth=3)\n",
    "ax1.fill_between(x, 0, y, alpha=0.2, color='green')\n",
    "ax1.axvline(x=-0.5, color='blue', linestyle='--', label='起点')\n",
    "ax1.axvline(x=0.5, color='red', linestyle='--', linewidth=2, label='目标')\n",
    "ax1.set_xlabel('位置')\n",
    "ax1.set_ylabel('高度')\n",
    "ax1.set_title('MountainCar 地形')\n",
    "ax1.legend()\n",
    "\n",
    "# 右图: 相图\n",
    "ax2 = axes[1]\n",
    "pos = np.linspace(-1.2, 0.6, 100)\n",
    "vel = np.linspace(-0.07, 0.07, 100)\n",
    "P, V = np.meshgrid(pos, vel)\n",
    "potential = np.sin(3 * P) * 0.45 + 0.55\n",
    "kinetic = 0.5 * V**2 * 500\n",
    "total_energy = potential + kinetic\n",
    "\n",
    "contour = ax2.contourf(P, V, total_energy, levels=20, cmap='coolwarm', alpha=0.7)\n",
    "plt.colorbar(contour, ax=ax2, label='总能量')\n",
    "ax2.axvline(x=0.5, color='red', linestyle='--', label='目标')\n",
    "ax2.set_xlabel('位置')\n",
    "ax2.set_ylabel('速度')\n",
    "ax2.set_title('相空间与能量等高线')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MountainCar 策略测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_policy_mc(obs):\n",
    "    return np.random.randint(3)\n",
    "\n",
    "def momentum_policy(obs):\n",
    "    \"\"\"跟随速度方向\"\"\"\n",
    "    return 2 if obs[1] > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MountainCar 策略评估 (20 回合)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for name, policy in [(\"随机\", random_policy_mc), (\"动量\", momentum_policy)]:\n",
    "    env = gym.make(\"MountainCar-v0\")\n",
    "    rewards = []\n",
    "    successes = 0\n",
    "    \n",
    "    for i in range(20):\n",
    "        obs, _ = env.reset(seed=i)\n",
    "        total_reward = 0\n",
    "        while True:\n",
    "            obs, reward, terminated, truncated, _ = env.step(policy(obs))\n",
    "            total_reward += reward\n",
    "            if terminated:\n",
    "                successes += 1\n",
    "                break\n",
    "            if truncated:\n",
    "                break\n",
    "        rewards.append(total_reward)\n",
    "    env.close()\n",
    "    \n",
    "    print(f\"{name:12s}: 平均奖励={np.mean(rewards):>7.1f}, 成功率={successes/20*100:>5.0f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Pendulum - 连续控制\n",
    "\n",
    "### 动力学方程\n",
    "\n",
    "$$\\ddot{\\theta} = -\\frac{3g}{2l}\\sin(\\theta + \\pi) + \\frac{3}{ml^2}u$$\n",
    "\n",
    "### 奖励函数\n",
    "\n",
    "$$r = -(\\theta^2 + 0.1\\dot{\\theta}^2 + 0.001u^2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Pendulum-v1\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Pendulum-v1 环境详解\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n观测: [cos(θ), sin(θ), θ̇]\")\n",
    "print(f\"动作: 扭矩 u ∈ [-2, 2] (连续)\")\n",
    "print(f\"奖励: r = -(θ² + 0.1·θ̇² + 0.001·u²)\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pendulum 控制策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_controller(obs, Kp=10.0, Kd=2.0):\n",
    "    \"\"\"PD 控制器\"\"\"\n",
    "    cos_theta, sin_theta, theta_dot = obs\n",
    "    theta = np.arctan2(sin_theta, cos_theta)\n",
    "    torque = -Kp * theta - Kd * theta_dot\n",
    "    return np.clip([torque], -2.0, 2.0)\n",
    "\n",
    "def energy_controller(obs):\n",
    "    \"\"\"能量成形控制器\"\"\"\n",
    "    cos_theta, sin_theta, theta_dot = obs\n",
    "    theta = np.arctan2(sin_theta, cos_theta)\n",
    "    g, l, m = 10.0, 1.0, 1.0\n",
    "    E = 0.5 * m * l**2 * theta_dot**2 - m * g * l * cos_theta\n",
    "    E_target = m * g * l\n",
    "    \n",
    "    if np.abs(theta) < 0.3:\n",
    "        torque = -10.0 * theta - 2.0 * theta_dot\n",
    "    else:\n",
    "        torque = -3.0 * (E - E_target) * theta_dot\n",
    "    \n",
    "    return np.clip([torque], -2.0, 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Pendulum-v1\")\n",
    "\n",
    "controllers = {\"PD控制\": pd_controller, \"能量控制\": energy_controller}\n",
    "all_data = {}\n",
    "\n",
    "for name, controller in controllers.items():\n",
    "    obs, _ = env.reset(seed=42)\n",
    "    thetas, torques, rewards_list = [], [], []\n",
    "    \n",
    "    for _ in range(200):\n",
    "        theta = np.arctan2(obs[1], obs[0])\n",
    "        action = controller(obs)\n",
    "        obs, reward, _, _, _ = env.step(action)\n",
    "        thetas.append(np.degrees(theta))\n",
    "        torques.append(action[0])\n",
    "        rewards_list.append(reward)\n",
    "    \n",
    "    all_data[name] = {'theta': thetas, 'torque': torques, 'reward': rewards_list}\n",
    "    print(f\"{name}: 总奖励 = {sum(rewards_list):.1f}\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 控制效果对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "colors = ['#1f77b4', '#ff7f0e']\n",
    "\n",
    "for idx, (name, data) in enumerate(all_data.items()):\n",
    "    axes[0].plot(data['theta'], color=colors[idx], label=name, linewidth=2)\n",
    "    axes[1].plot(np.cumsum(data['reward']), color=colors[idx], label=name, linewidth=2)\n",
    "\n",
    "axes[0].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "axes[0].set_xlabel('步数')\n",
    "axes[0].set_ylabel('角度 (度)')\n",
    "axes[0].set_title('摆角变化')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].set_xlabel('步数')\n",
    "axes[1].set_ylabel('累积奖励')\n",
    "axes[1].set_title('累积奖励')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. 环境对比总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import spaces\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"经典控制环境对比\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"{'环境ID':<25} {'状态维度':<10} {'动作空间':<15} {'推荐算法'}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "envs_info = [\n",
    "    (\"CartPole-v1\", \"DQN, A2C\"),\n",
    "    (\"MountainCar-v0\", \"需要探索\"),\n",
    "    (\"Acrobot-v1\", \"DQN, PPO\"),\n",
    "    (\"Pendulum-v1\", \"DDPG, SAC\"),\n",
    "]\n",
    "\n",
    "for env_id, algos in envs_info:\n",
    "    try:\n",
    "        env = gym.make(env_id)\n",
    "        obs_dim = env.observation_space.shape[0]\n",
    "        if isinstance(env.action_space, spaces.Discrete):\n",
    "            act_info = f\"Discrete({env.action_space.n})\"\n",
    "        else:\n",
    "            act_info = f\"Box({env.action_space.shape[0]})\"\n",
    "        env.close()\n",
    "        print(f\"{env_id:<25} {obs_dim:<10} {act_info:<15} {algos}\")\n",
    "    except:\n",
    "        print(f\"{env_id:<25} 未安装\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
