{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": "\"\"\"\n结合一维卷积和循环神经网络的时间序列预测\n================================================\n\n本示例展示如何结合CNN和RNN的优势来预测时间序列。\nCNN用于快速提取局部特征，RNN用于建模长期依赖关系。\n\n混合架构优势：\n1. CNN层：快速处理长序列，提取局部模式，降低维度\n2. GRU层：在CNN提取的特征上建模时序依赖关系\n3. 相比纯CNN：更好的长期依赖建模能力\n4. 相比纯RNN：更快的训练速度和更少的计算量\n\n网络架构：\n1. Conv1D层：提取时间序列的局部模式（速度快）\n2. MaxPooling层：降采样，减少后续RNN的计算量\n3. 多层卷积堆叠：提取多尺度特征\n4. GRU层：捕捉长期时序依赖关系\n5. Dense层：输出温度预测值\n\n数据集：Jena气候数据集（2009-2016年的气候观测数据）\n任务：基于过去120小时（5天）的数据预测24小时后的温度\n\"\"\"\n\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras import layers\nfrom keras.optimizers import RMSprop\n\n# 设置随机种子以保证结果可复现\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\n\n# ==================== 数据加载与预处理 ====================\n\ndata_dir = \"/home/dingziming/下载/jena_climate\"\nfname = os.path.join(data_dir, \"jena_climate_2009_2016.csv\")\n\nprint(\"正在加载Jena气候数据集...\")\nwith open(fname) as f:\n    data = f.read()\n\n# 解析CSV数据\nlines = data.split(\"\\n\")\nheader = lines[0].split(\",\")\nlines = lines[1:]\n\nprint(f\"数据特征: {header}\")\nprint(f\"数据总行数: {len(lines)}\")\n\n# 将数据转换为浮点数数组\nfloat_data = np.zeros((len(lines), len(header) - 1))\nfor i, line in enumerate(lines):\n    values = [float(x) for x in line.split(\",\")[1:]]\n    float_data[i, :] = values\n\nprint(f\"数据形状: {float_data.shape}\")\n\n# ==================== 数据可视化 ====================\n\n# 提取温度数据（第2列，索引为1）\ntemp = float_data[:, 1]\n\n# 绘制完整温度时间序列\nplt.figure(figsize=(14, 5))\nplt.plot(range(len(temp)), temp, linewidth=0.5)\nplt.title('Jena气候数据集 - 完整温度时间序列 (2009-2016)', fontsize=14, fontweight='bold')\nplt.xlabel('时间步 (10分钟/步)', fontsize=12)\nplt.ylabel('温度 (°C)', fontsize=12)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# 绘制前10天的温度数据\nplt.figure(figsize=(14, 5))\nplt.plot(range(1440), temp[:1440], linewidth=1.5)\nplt.title('Jena气候数据集 - 前10天温度变化', fontsize=14, fontweight='bold')\nplt.xlabel('时间步 (10分钟/步)', fontsize=12)\nplt.ylabel('温度 (°C)', fontsize=12)\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.show()\n\n# ==================== 数据标准化 ====================\n\n# 使用前200000个样本的统计量进行标准化（避免数据泄露）\nmean = float_data[:200000].mean(axis=0)\nstd = float_data[:200000].std(axis=0)\nfloat_data = (float_data - mean) / std\n\nprint(f\"数据标准化完成 - 均值: {mean[1]:.2f}°C, 标准差: {std[1]:.2f}°C\")\n\n# ==================== 数据生成器 ====================\n\ndef generator(data, lookback, delay, min_index, max_index, \n              shuffle=False, batch_size=128, step=6):\n    \"\"\"\n    时间序列数据生成器\n    \n    参数说明：\n    - data: 原始时间序列数据 (标准化后)\n    - lookback: 输入序列长度（回看多少个时间步）\n    - delay: 预测目标与当前时刻的时间间隔\n    - min_index, max_index: 数据索引范围\n    - shuffle: 是否随机打乱数据\n    - batch_size: 批次大小\n    - step: 采样步长（用于降采样，节省内存和计算）\n    \n    返回：\n    - samples: 输入序列 shape=(batch_size, lookback//step, features)\n    - targets: 目标值 shape=(batch_size,)\n    \"\"\"\n    if max_index is None:\n        max_index = len(data) - delay - 1\n    \n    i = min_index + lookback\n    \n    while True:\n        if shuffle:\n            # 随机采样：训练集使用\n            rows = np.random.randint(min_index + lookback, max_index, size=batch_size)\n        else:\n            # 顺序采样：验证集和测试集使用\n            if i + batch_size >= max_index:\n                i = min_index + lookback\n            rows = np.arange(i, min(i + batch_size, max_index))\n            i += len(rows)\n        \n        # 初始化样本和目标数组\n        samples = np.zeros((len(rows), lookback // step, data.shape[-1]))\n        targets = np.zeros((len(rows),))\n        \n        # 填充数据\n        for j, row in enumerate(rows):\n            indices = range(rows[j] - lookback, rows[j], step)\n            samples[j] = data[indices]\n            targets[j] = data[rows[j] + delay][1]  # 预测温度（索引1）\n        \n        yield samples, targets\n\n# ==================== 生成器参数配置 ====================\n\n# 超参数设置\n# 注意：相比纯CNN版本，这里使用更短的lookback和更密集的采样\n# 原因：CNN已经能有效压缩序列，GRU可以在更短的序列上建模长期依赖\nlookback = 720       # 回看720步 = 120小时 = 5天 (每步10分钟)\ndelay = 144          # 预测144步后 = 24小时后的温度\nstep = 3             # 每隔3步采样一次 = 每30分钟采样一次（比纯CNN更密集）\nbatch_size = 128     # 批次大小\n\nprint(\"\\n时间序列参数:\")\nprint(f\"- 输入窗口: {lookback}步 = {lookback * 10 / 60:.1f}小时 = {lookback * 10 / 60 / 24:.1f}天\")\nprint(f\"- 预测延迟: {delay}步 = {delay * 10 / 60:.1f}小时\")\nprint(f\"- 采样步长: {step}步 = {step * 10}分钟\")\nprint(f\"- 实际输入序列长度: {lookback // step}步\")\n\n# 创建数据生成器\ntrain_gen = generator(\n    float_data, lookback=lookback, delay=delay,\n    min_index=0, max_index=200000, shuffle=True,\n    step=step, batch_size=batch_size\n)\n\nval_gen = generator(\n    float_data, lookback=lookback, delay=delay,\n    min_index=200001, max_index=300000,\n    step=step, batch_size=batch_size, shuffle=False\n)\n\ntest_gen = generator(\n    float_data, lookback=lookback, delay=delay,\n    min_index=300001, max_index=None,\n    step=step, batch_size=batch_size, shuffle=False\n)\n\n# 计算验证和测试步数\nval_steps = (300000 - 200001 - lookback) // batch_size\ntest_steps = (len(float_data) - 300001 - lookback) // batch_size\n\nprint(f\"\\n数据集划分:\")\nprint(f\"- 训练集: 0 - 200000\")\nprint(f\"- 验证集: 200001 - 300000 ({val_steps}步)\")\nprint(f\"- 测试集: 300001 - {len(float_data)} ({test_steps}步)\")\n\n# ==================== 构建CNN-GRU混合网络 ====================\n\nmodel = Sequential([\n    # 第一层卷积：快速提取局部特征\n    # 32个卷积核，窗口大小5，可以捕获短期模式\n    layers.Conv1D(filters=32, kernel_size=5, activation='relu',\n                  input_shape=(lookback // step, float_data.shape[-1])),\n    \n    # 第一层池化：降采样3倍，减少后续计算量\n    layers.MaxPooling1D(pool_size=3),\n    \n    # 第二层卷积：提取更复杂的模式\n    layers.Conv1D(filters=32, kernel_size=5, activation='relu'),\n    \n    # 第二层池化：继续降维\n    layers.MaxPooling1D(pool_size=3),\n    \n    # 第三层卷积：提取高层次特征\n    layers.Conv1D(filters=32, kernel_size=5, activation='relu'),\n    \n    # GRU层：在CNN提取的特征上建模时序关系\n    # 优势：序列长度已被CNN大幅压缩，GRU计算量小\n    # dropout: 0.1 正则化，防止过拟合\n    # recurrent_dropout: 0.5 循环连接的dropout\n    layers.GRU(units=32, dropout=0.1, recurrent_dropout=0.5),\n    \n    # 输出层：回归任务，输出单个数值（温度）\n    layers.Dense(1)\n])\n\n# 编译模型\nmodel.compile(\n    optimizer=RMSprop(learning_rate=1e-3),\n    loss='mae',           # 平均绝对误差，适合回归任务\n    metrics=['mae']       # 监控指标\n)\n\n# 显示模型架构\nprint(\"\\n模型架构:\")\nmodel.summary()\n\nprint(\"\\nCNN-GRU混合架构设计思路:\")\nprint(\"=\"*60)\nprint(\"1. CNN层负责:\")\nprint(\"   - 快速处理长序列（可并行计算）\")\nprint(\"   - 提取局部时序模式\")\nprint(\"   - 降低序列维度（通过池化层）\")\nprint(\"\\n2. GRU层负责:\")\nprint(\"   - 在压缩后的特征序列上工作\")\nprint(\"   - 建模长期时序依赖关系\")\nprint(\"   - 计算量小（因为序列已被CNN压缩）\")\nprint(\"\\n3. 混合架构的优势:\")\nprint(\"   - 比纯CNN：更好的长期依赖建模\")\nprint(\"   - 比纯RNN：更快的训练速度\")\nprint(\"   - 参数效率：CNN压缩+RNN建模\")\nprint(\"=\"*60)\n\n# ==================== 模型训练 ====================\n\nprint(\"\\n开始训练模型...\")\nhistory = model.fit(\n    train_gen,\n    steps_per_epoch=500,\n    epochs=20,\n    validation_data=val_gen,\n    validation_steps=val_steps,\n    verbose=1\n)\n\n# ==================== 可视化训练过程 ====================\n\n# 提取训练历史\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nmae = history.history['mae']\nval_mae = history.history['val_mae']\nepochs_range = range(1, len(loss) + 1)\n\n# 创建图表\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\n# 绘制损失曲线\nax1.plot(epochs_range, loss, 'bo-', label='训练损失', linewidth=2)\nax1.plot(epochs_range, val_loss, 'ro-', label='验证损失', linewidth=2)\nax1.set_title('训练和验证损失曲线 (MAE)', fontsize=14, fontweight='bold')\nax1.set_xlabel('轮次', fontsize=12)\nax1.set_ylabel('平均绝对误差', fontsize=12)\nax1.legend(fontsize=11)\nax1.grid(True, alpha=0.3)\n\n# 绘制MAE曲线\nax2.plot(epochs_range, mae, 'bo-', label='训练MAE', linewidth=2)\nax2.plot(epochs_range, val_mae, 'ro-', label='验证MAE', linewidth=2)\nax2.set_title('训练和验证MAE曲线', fontsize=14, fontweight='bold')\nax2.set_xlabel('轮次', fontsize=12)\nax2.set_ylabel('平均绝对误差', fontsize=12)\nax2.legend(fontsize=11)\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# ==================== 模型评估 ====================\n\nprint(\"\\n在测试集上评估模型...\")\ntest_loss = model.evaluate(test_gen, steps=test_steps, verbose=1)\n\n# 将标准化后的MAE转换回实际温度单位\nactual_mae = test_loss * std[1]\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"模型性能分析:\")\nprint(\"=\"*60)\nprint(f\"最终训练MAE (标准化): {mae[-1]:.4f}\")\nprint(f\"最终验证MAE (标准化): {val_mae[-1]:.4f}\")\nprint(f\"测试MAE (标准化): {test_loss:.4f}\")\nprint(f\"测试MAE (实际温度): {actual_mae:.2f}°C\")\nprint(\"=\"*60)\n\nprint(\"\\nCNN-GRU混合模型特点总结:\")\nprint(\"=\"*60)\nprint(\"优势：\")\nprint(\"  1. 训练效率：CNN并行处理+GRU建模时序\")\nprint(\"  2. 特征提取：CNN自动学习局部模式\")\nprint(\"  3. 长期依赖：GRU捕捉时序关系\")\nprint(\"  4. 参数效率：通过池化降低GRU输入维度\")\nprint(\"\\n适用场景：\")\nprint(\"  1. 长序列时间序列预测\")\nprint(\"  2. 需要同时捕捉局部和全局模式\")\nprint(\"  3. 对训练速度有要求的场景\")\nprint(\"  4. 计算资源有限的情况\")\nprint(\"\\n与其他方法对比：\")\nprint(\"  vs 纯CNN：更好的长期依赖建模能力\")\nprint(\"  vs 纯RNN/GRU：更快的训练速度和更少的参数\")\nprint(\"  vs Attention：计算量更小，适合资源受限场景\")\nprint(\"=\"*60)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}