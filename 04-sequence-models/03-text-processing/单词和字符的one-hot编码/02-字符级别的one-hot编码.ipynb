{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 字符级别的One-Hot编码\n",
    "\n",
    "## 1. 概述\n",
    "\n",
    "字符级别的One-Hot编码是将文本中的每个字符（而非单词）映射为一个独热向量。与单词级编码相比，字符级编码具有不同的特点和应用场景。\n",
    "\n",
    "## 2. 单词级 vs 字符级编码\n",
    "\n",
    "| 特性 | 单词级编码 | 字符级编码 |\n",
    "|------|-----------|----------|\n",
    "| **词汇表大小** | 10,000-100,000+ | 26-128（取决于字符集）|\n",
    "| **序列长度** | 较短（几十到几百） | 较长（几百到几千） |\n",
    "| **向量维度** | 高维稀疏 | 低维稀疏 |\n",
    "| **处理OOV** | 困难（未知单词无法表示） | 容易（所有单词都是已知字符的组合） |\n",
    "| **拼写错误** | 敏感（不同单词） | 鲁棒（字符相近） |\n",
    "| **语义理解** | 较好（单词有明确含义） | 较差（需要学习字符组合） |\n",
    "| **计算成本** | 较低 | 较高（序列更长） |\n",
    "\n",
    "## 3. 字符级编码的优势\n",
    "\n",
    "### 3.1 词汇表小\n",
    "- 英文只需要约100个字符（大小写字母、数字、标点符号）\n",
    "- 中文需要几千个常用汉字\n",
    "- 内存占用远小于单词级编码\n",
    "\n",
    "### 3.2 无OOV问题\n",
    "- 任何新词都可以表示为已知字符的组合\n",
    "- 适合处理专业术语、新词、缩写\n",
    "\n",
    "### 3.3 对拼写错误鲁棒\n",
    "- \"recieve\" vs \"receive\" 在单词级是完全不同的\n",
    "- 在字符级只有一个字符不同\n",
    "\n",
    "### 3.4 跨语言通用\n",
    "- 不需要分词（中文、日文等无空格语言的难题）\n",
    "- 可以处理混合语言文本\n",
    "\n",
    "## 4. 字符级编码的劣势\n",
    "\n",
    "### 4.1 序列更长\n",
    "- 一个句子有10个单词，但可能有50-100个字符\n",
    "- 增加了模型的计算复杂度\n",
    "- 需要更深的网络来捕捉长距离依赖\n",
    "\n",
    "### 4.2 丢失显式语义\n",
    "- 单词是有明确意义的语言单元\n",
    "- 字符本身没有语义，需要模型从头学习\n",
    "- 训练收敛速度较慢\n",
    "\n",
    "## 5. 应用场景\n",
    "\n",
    "### 适合字符级编码的任务：\n",
    "1. **文本生成**：生成拼写正确的文本\n",
    "2. **拼写检查**：检测和纠正拼写错误\n",
    "3. **命名实体识别**：处理专有名词和缩写\n",
    "4. **低资源语言**：词汇表难以构建的语言\n",
    "5. **代码分析**：处理变量名、函数名等\n",
    "6. **DNA序列分析**：只有A/T/G/C四个字符\n",
    "\n",
    "### 不适合字符级编码的任务：\n",
    "1. **大规模文本分类**：计算成本高\n",
    "2. **机器翻译**：需要理解语义\n",
    "3. **问答系统**：需要词级理解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 实现：字符级One-Hot编码\n",
    "\n",
    "### 6.1 使用Python标准库\n",
    "\n",
    "我们使用`string.printable`获取所有可打印ASCII字符作为字符集。\n",
    "\n",
    "#### ASCII可打印字符集包含：\n",
    "- **数字**：0-9 (10个)\n",
    "- **大写字母**：A-Z (26个)\n",
    "- **小写字母**：a-z (26个)\n",
    "- **标点符号**：! \" # $ % & ' ( ) * + , - . / : ; < = > ? @ [ \\\\ ] ^ _ ` { | } ~ (32个)\n",
    "- **空白字符**：空格、制表符、换行符等 (6个)\n",
    "\n",
    "总共约100个字符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "\n",
    "# 设置随机种子以确保结果可复现\n",
    "np.random.seed(42)\n",
    "\n",
    "# 示例文本数据\n",
    "samples = [\"The cat sat on the mat.\", \"The dog ate my homework.\"]\n",
    "\n",
    "# 获取所有可打印ASCII字符作为字符集\n",
    "characters = string.printable\n",
    "print(f\"字符集大小: {len(characters)}\")\n",
    "print(f\"字符集内容: {repr(characters[:50])}...\\n\")\n",
    "\n",
    "# 构建字符到索引的映射\n",
    "# 索引从1开始，0保留用于填充或未知字符\n",
    "token_index = dict(zip(characters, range(1, len(characters) + 1)))\n",
    "\n",
    "print(\"部分字符索引映射：\")\n",
    "sample_chars = list(characters[:10]) + list(characters[10:20])\n",
    "for char in sample_chars:\n",
    "    print(f\"  '{char}' -> {token_index[char]}\")\n",
    "print(f\"  ...\\n\")\n",
    "\n",
    "# 设置序列最大长度\n",
    "max_length = 50  # 每个样本最多考虑前50个字符\n",
    "vocab_size = max(token_index.values()) + 1  # +1是因为索引0保留\n",
    "\n",
    "# 创建三维零矩阵：(样本数, 序列长度, 字符表大小)\n",
    "results = np.zeros((len(samples), max_length, vocab_size))\n",
    "\n",
    "print(f\"结果矩阵形状: {results.shape}\")\n",
    "print(f\"  - {results.shape[0]} 个样本\")\n",
    "print(f\"  - 每个样本最多 {results.shape[1]} 个字符\")\n",
    "print(f\"  - 每个字符编码为 {results.shape[2]} 维向量\\n\")\n",
    "\n",
    "# 对每个样本进行字符级编码\n",
    "for i, sample in enumerate(samples):\n",
    "    # 只处理前max_length个字符\n",
    "    for j, character in enumerate(sample[:max_length]):\n",
    "        # 获取字符对应的索引\n",
    "        index = token_index.get(character)\n",
    "        if index is not None:\n",
    "            # 将对应位置设置为1\n",
    "            results[i, j, index] = 1\n",
    "\n",
    "# 输出结果分析\n",
    "print(\"=\" * 60)\n",
    "print(\"第一个样本的字符级编码结果：\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"原始文本: {samples[0]}\")\n",
    "print(f\"文本长度: {len(samples[0])} 个字符\\n\")\n",
    "\n",
    "print(\"前20个字符的编码：\")\n",
    "for i, char in enumerate(samples[0][:20]):\n",
    "    char_vector = results[0, i, :]\n",
    "    non_zero_idx = np.where(char_vector == 1)[0]\n",
    "    display_char = repr(char) if char in [' ', '\\t', '\\n'] else char\n",
    "    print(f\"位置 {i:2d}: {display_char:5s} -> 索引 {non_zero_idx[0] if len(non_zero_idx) > 0 else 'None'}\")\n",
    "\n",
    "# 统计信息\n",
    "print(f\"\\n统计信息：\")\n",
    "print(f\"  样本1字符数: {len(samples[0])}\")\n",
    "print(f\"  样本2字符数: {len(samples[1])}\")\n",
    "print(f\"  唯一字符数: {len(set(''.join(samples)))}\")\n",
    "print(f\"  字符集利用率: {len(set(''.join(samples))) / len(characters):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 字符级编码的深入分析\n",
    "\n",
    "### 7.1 内存占用对比\n",
    "\n",
    "假设一个文本样本：\n",
    "- **原始文本**：\"The quick brown fox jumps\" (25个字符)\n",
    "- **单词级编码**：5个单词 × 10,000维 = 50,000维\n",
    "- **字符级编码**：25个字符 × 100维 = 2,500维\n",
    "\n",
    "但是：\n",
    "- 单词级序列长度：5\n",
    "- 字符级序列长度：25（5倍长）\n",
    "\n",
    "### 7.2 计算复杂度\n",
    "\n",
    "对于RNN/LSTM模型：\n",
    "- **时间复杂度**：O(序列长度 × 隐藏层大小²)\n",
    "- 字符级模型需要处理更长的序列\n",
    "- 需要更深的网络或更大的隐藏层\n",
    "\n",
    "### 7.3 最佳实践\n",
    "\n",
    "#### 何时使用字符级编码：\n",
    "1. **数据质量差**：含有大量拼写错误、俚语、缩写\n",
    "2. **多语言混合**：不想为每种语言维护词汇表\n",
    "3. **专业领域**：医学、法律等含有大量专业术语\n",
    "4. **代码分析**：变量名、函数名高度多样化\n",
    "5. **资源受限**：内存无法容纳大型词汇表\n",
    "\n",
    "#### 混合策略：\n",
    "现代NLP系统常使用混合方法：\n",
    "1. **子词级编码**（Subword）：BPE、WordPiece、SentencePiece\n",
    "   - 平衡了单词级和字符级的优势\n",
    "   - BERT、GPT等模型的标准做法\n",
    "2. **分层模型**：字符级CNN + 单词级RNN\n",
    "   - 底层用CNN提取字符特征\n",
    "   - 高层用RNN处理单词序列\n",
    "3. **动态选择**：常见词用单词级，罕见词用字符级\n",
    "   - 兼顾效率和鲁棒性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 字符级编码的变体\n",
    "\n",
    "### 8.1 限制字符集\n",
    "\n",
    "根据任务需求，可以只保留必要的字符："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# 只保留字母、数字和基本标点\n",
    "basic_chars = string.ascii_letters + string.digits + ' .,!?'\n",
    "print(f\"基础字符集大小: {len(basic_chars)}\")\n",
    "print(f\"字符集: {basic_chars}\\n\")\n",
    "\n",
    "# 只保留小写字母（将文本转为小写）\n",
    "lowercase_chars = string.ascii_lowercase + ' .,!?'\n",
    "print(f\"小写字符集大小: {len(lowercase_chars)}\")\n",
    "print(f\"字符集: {lowercase_chars}\\n\")\n",
    "\n",
    "# 实际应用示例\n",
    "text = \"The Quick BROWN Fox!\"\n",
    "normalized_text = text.lower()\n",
    "print(f\"原始文本: {text}\")\n",
    "print(f\"归一化后: {normalized_text}\")\n",
    "print(f\"\\n优势：\")\n",
    "print(\"  - 减少字符集大小（从52降到26个字母）\")\n",
    "print(\"  - 'The' 和 'the' 被视为相同\")\n",
    "print(\"  - 减少模型参数量\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 字符级N-gram\n",
    "\n",
    "除了单个字符，还可以考虑字符组合："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_char_ngrams(text, n=3):\n",
    "    \"\"\"\n",
    "    生成字符级n-gram\n",
    "    \n",
    "    参数:\n",
    "        text: 输入文本\n",
    "        n: n-gram的长度\n",
    "    \n",
    "    返回:\n",
    "        n-gram列表\n",
    "    \"\"\"\n",
    "    # 在文本两端添加边界标记\n",
    "    padded_text = '#' * (n - 1) + text + '#' * (n - 1)\n",
    "    ngrams = [padded_text[i:i+n] for i in range(len(padded_text) - n + 1)]\n",
    "    return ngrams\n",
    "\n",
    "# 示例\n",
    "word = \"hello\"\n",
    "trigrams = generate_char_ngrams(word, n=3)\n",
    "\n",
    "print(f\"单词: {word}\")\n",
    "print(f\"字符3-gram: {trigrams}\")\n",
    "print(f\"\\n优势：\")\n",
    "print(\"  - 捕捉字符间的局部模式\")\n",
    "print(\"  - 'hel', 'ell', 'llo' 包含了拼写信息\")\n",
    "print(\"  - FastText等词嵌入模型使用此技术\")\n",
    "\n",
    "# 对比不同n值\n",
    "print(f\"\\n不同n-gram对比：\")\n",
    "for n in [2, 3, 4]:\n",
    "    ngrams = generate_char_ngrams(word, n)\n",
    "    print(f\"  {n}-gram ({len(ngrams)}个): {ngrams[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 实战案例：拼写错误检测\n",
    "\n",
    "字符级编码在拼写错误检测中特别有用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def char_level_similarity(word1, word2):\n",
    "    \"\"\"\n",
    "    计算两个单词在字符级别的相似度\n",
    "    使用编辑距离（Levenshtein距离）的简化版本\n",
    "    \"\"\"\n",
    "    # 将单词转换为字符集合\n",
    "    chars1 = set(word1)\n",
    "    chars2 = set(word2)\n",
    "    \n",
    "    # 计算Jaccard相似度\n",
    "    intersection = len(chars1 & chars2)\n",
    "    union = len(chars1 | chars2)\n",
    "    \n",
    "    return intersection / union if union > 0 else 0\n",
    "\n",
    "# 测试案例\n",
    "test_cases = [\n",
    "    (\"receive\", \"recieve\"),  # 常见拼写错误\n",
    "    (\"hello\", \"hallo\"),       # 元音错误\n",
    "    (\"algorithm\", \"algoritm\"), # 缺少字母\n",
    "    (\"cat\", \"dog\"),           # 完全不同的词\n",
    "]\n",
    "\n",
    "print(\"字符级相似度分析：\")\n",
    "print(\"=\" * 60)\n",
    "for word1, word2 in test_cases:\n",
    "    similarity = char_level_similarity(word1, word2)\n",
    "    print(f\"{word1:12s} vs {word2:12s} => 相似度: {similarity:.2f}\")\n",
    "\n",
    "print(\"\\n观察：\")\n",
    "print(\"  - 拼写错误的单词相似度较高（> 0.7）\")\n",
    "print(\"  - 完全不同的单词相似度低（< 0.3）\")\n",
    "print(\"  - 可用于拼写纠错、模糊匹配等任务\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 总结与建议\n",
    "\n",
    "### 核心要点：\n",
    "\n",
    "1. **字符级编码适合**：\n",
    "   - 词汇表构建困难的场景\n",
    "   - 需要处理拼写错误\n",
    "   - 多语言混合文本\n",
    "   - 专业术语密集的领域\n",
    "\n",
    "2. **字符级编码不适合**：\n",
    "   - 需要快速训练的场景\n",
    "   - 计算资源受限\n",
    "   - 强调语义理解的任务\n",
    "\n",
    "3. **现代最佳实践**：\n",
    "   - 子词级编码（BPE、WordPiece）已成为主流\n",
    "   - 结合单词级和字符级的优势\n",
    "   - BERT、GPT等预训练模型普遍采用\n",
    "\n",
    "### 技术演进路线：\n",
    "```\n",
    "字符级 → 单词级 → 子词级 → 上下文嵌入\n",
    "  ↓         ↓         ↓          ↓\n",
    " 鲁棒     常用     最佳      SOTA\n",
    "```\n",
    "\n",
    "### 实践建议：\n",
    "- 对于新项目，优先考虑预训练的Tokenizer（如BERT的WordPiece）\n",
    "- 对于特定领域，可以在预训练基础上微调字符/子词表\n",
    "- 对于教学和理解，One-Hot编码仍然是很好的起点"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
