{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T07:59:00.091655Z",
     "start_time": "2025-09-20T07:59:00.089817Z"
    }
   },
   "cell_type": "markdown",
   "source": "# 循环神经网络(RNN)基础实现与应用\n\n## 教程概览\n\n本教程全面介绍循环神经网络(RNN)的核心概念、实现原理和实际应用：\n\n### 1. RNN基础实现\n- 从零开始实现RNN的前向传播\n- 理解隐藏状态的更新机制\n- 掌握RNN的核心数学公式\n\n### 2. Keras/TensorFlow实现\n- 使用高层API快速构建RNN模型\n- 理解`return_sequences`参数的作用\n- 构建深层RNN架构\n\n### 3. 实战：情感分析\n- IMDB电影评论情感分类\n- 对比SimpleRNN与LSTM的性能\n- 可视化训练过程和模型评估\n\n### 学习目标\n- 掌握RNN的工作原理和计算流程\n- 学会使用Keras构建各种RNN模型\n- 理解RNN在序列任务中的应用\n- 认识SimpleRNN的局限性和LSTM的优势",
   "id": "a64986898e1da970"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-23T09:32:38.184055Z",
     "start_time": "2025-09-23T09:32:38.063547Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n循环神经网络(RNN)的基础实现\n演示RNN的核心计算流程和状态传递机制\n\"\"\"\nimport numpy as np\n\n# 设置随机种子以保证结果可复现\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\n\n# 定义网络参数\ntimesteps = 100         # 时间序列长度\ninput_features = 32     # 每个时间步的输入特征维度\noutput_features = 64    # 隐藏状态和输出的特征维度\n\n# 生成模拟的输入序列数据\n# 形状为 (timesteps, input_features)\ninputs = np.random.rand(timesteps, input_features)\n\n# 初始化隐藏状态为零向量\nstate_t = np.zeros((output_features,))\n\n# 初始化权重矩阵\n# W: 输入到隐藏状态的权重矩阵\n# U: 前一时刻隐藏状态到当前隐藏状态的权重矩阵\n# b: 偏置向量\nW = np.random.random((output_features, input_features))\nU = np.random.random((output_features, output_features))\nb = np.random.random((output_features,))\n\n# 按时间步迭代计算RNN的输出\nsuccessive_outputs = []\nfor t in range(timesteps):\n    # RNN核心公式: h_t = tanh(W * x_t + U * h_{t-1} + b)\n    # 其中 x_t 是当前时刻的输入，h_{t-1} 是上一时刻的隐藏状态\n    output_t = np.tanh(np.dot(W, inputs[t]) + np.dot(U, state_t) + b)\n    \n    # 保存当前时刻的输出\n    successive_outputs.append(output_t)\n    \n    # 更新隐藏状态，用于下一时刻的计算\n    state_t = output_t\n\n# 将所有时间步的输出堆叠成三维张量\n# 形状为 (timesteps, output_features)\nfinal_output = np.stack(successive_outputs, axis=0)\nprint(f\"输出形状: {final_output.shape}\")\nprint(f\"期望形状: ({timesteps}, {output_features})\")",
   "id": "43740ed8eedf18ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T08:03:34.385641Z",
     "start_time": "2025-09-20T08:03:34.383893Z"
    }
   },
   "cell_type": "markdown",
   "source": "### RNN的计算机制详解\n\nRNN的核心思想是在处理序列数据时保持一个**隐藏状态(hidden state)**，该状态在每个时间步都会被更新，并影响后续时间步的计算。\n\n**关键要素：**\n1. **输入权重矩阵 W**: 将当前时刻的输入转换为隐藏状态空间\n2. **循环权重矩阵 U**: 将上一时刻的隐藏状态传递到当前时刻\n3. **偏置向量 b**: 为网络提供额外的学习自由度\n4. **激活函数**: 通常使用tanh或ReLU引入非线性\n\n**信息流动路径：**\n- 当前输入 → 通过W加权 → \n- 上一时刻状态 → 通过U加权 → \n- 两者相加加上偏置 → 激活函数 → 当前时刻的隐藏状态",
   "id": "359309d14501a732"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## RNN的数学表达式\n\n$$h_t = \\text{activation}(W \\cdot x_t + U \\cdot h_{t-1} + b)$$\n\n其中：\n- $h_t$: 当前时刻的隐藏状态\n- $x_t$: 当前时刻的输入\n- $h_{t-1}$: 上一时刻的隐藏状态\n- $W$: 输入权重矩阵\n- $U$: 循环权重矩阵(有时也记作$W_{rec}$)\n- $b$: 偏置向量\n- $\\text{activation}$: 激活函数(通常为tanh)",
   "id": "6b524736bc2216d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T09:33:00.318768Z",
     "start_time": "2025-09-23T09:33:00.142531Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n使用Keras构建简单的RNN模型\n演示嵌入层和SimpleRNN层的组合使用\n\"\"\"\nimport tensorflow as tf\nfrom keras.layers import SimpleRNN, Embedding\nfrom keras.models import Sequential\n\n# 构建基础RNN模型\nmodel = Sequential([\n    # 嵌入层: 将词索引转换为密集向量表示\n    # 参数: (词汇表大小, 嵌入维度)\n    Embedding(input_dim=10000, output_dim=32),\n    \n    # SimpleRNN层: 处理序列数据\n    # 参数: units=32表示隐藏状态的维度\n    # 默认只返回最后一个时间步的输出\n    SimpleRNN(units=32)\n])\n\nmodel.summary()",
   "id": "9af17db1cd3cee9c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T09:33:01.892681Z",
     "start_time": "2025-09-23T09:33:01.883383Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n演示return_sequences参数的作用\n当return_sequences=True时，RNN会返回所有时间步的输出\n\"\"\"\nmodel = Sequential([\n    Embedding(input_dim=10000, output_dim=32),\n    \n    # return_sequences=True: 返回完整的输出序列\n    # 输出形状: (batch_size, timesteps, units)\n    # 适用于需要序列到序列映射的任务\n    SimpleRNN(units=32, return_sequences=True)\n])\n\nmodel.summary()",
   "id": "e99050118922cc1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T09:33:02.987854Z",
     "start_time": "2025-09-23T09:33:02.971283Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n构建深层RNN网络\n通过堆叠多个RNN层来增加模型的表达能力\n\"\"\"\nmodel = Sequential([\n    Embedding(input_dim=10000, output_dim=32),\n    \n    # 第一层RNN: 必须设置return_sequences=True才能将序列传递给下一层\n    SimpleRNN(units=32, return_sequences=True),\n    \n    # 中间层RNN: 同样需要return_sequences=True\n    SimpleRNN(units=32, return_sequences=True),\n    \n    # 第三层RNN\n    SimpleRNN(units=32, return_sequences=True),\n    \n    # 最后一层RNN: 可以只返回最后一个时间步的输出\n    # 这里为了演示保持return_sequences=True\n    SimpleRNN(units=32, return_sequences=True)\n])\n\n# 注意：深层RNN容易出现梯度消失问题\n# 实践中通常使用LSTM或GRU来替代SimpleRNN\nmodel.summary()",
   "id": "574e9bc441822740",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T09:33:12.364811Z",
     "start_time": "2025-09-23T09:33:03.877588Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n准备IMDB情感分析数据集\n使用Keras内置的IMDB数据集进行演示\n\"\"\"\nimport tensorflow as tf\nimport os\nfrom keras.datasets import imdb\nfrom keras.preprocessing.sequence import pad_sequences\n\n# 数据集参数配置\nMAX_FEATURES = 10000    # 词汇表大小，只保留最常见的10000个词\nMAX_LEN = 500           # 序列最大长度\nBATCH_SIZE = 32\n\nprint(\"=\" * 70)\nprint(\"加载IMDB数据集\")\nprint(\"=\" * 70)\n\n# 加载IMDB数据集（Keras内置）\n# 数据格式: 每个样本是一个整数序列，代表单词索引\n(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=MAX_FEATURES)\n\nprint(f\"\\n训练集大小: {len(x_train)}\")\nprint(f\"测试集大小: {len(x_test)}\")\nprint(f\"标签分布 - 训练集: 负面={sum(y_train == 0)}, 正面={sum(y_train == 1)}\")\n\n# 查看第一条评论的原始数据\nprint(f\"\\n第一条评论的长度: {len(x_train[0])}\")\nprint(f\"第一条评论的前20个词索引: {x_train[0][:20]}\")\nprint(f\"对应标签: {y_train[0]} ({'正面' if y_train[0] == 1 else '负面'})\")\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"对序列进行填充和截断\")\nprint(\"=\" * 70)\n\n# 将序列填充到相同长度\n# padding='post': 在序列末尾填充\n# truncating='post': 从序列末尾截断\nx_train = pad_sequences(x_train, maxlen=MAX_LEN, padding='post', truncating='post')\nx_test = pad_sequences(x_test, maxlen=MAX_LEN, padding='post', truncating='post')\n\nprint(f\"填充后的训练集形状: {x_train.shape}\")\nprint(f\"填充后的测试集形状: {x_test.shape}\")\n\n# 创建验证集\nVALIDATION_SPLIT = 0.2\nvalidation_samples = int(VALIDATION_SPLIT * len(x_train))\n\nx_val = x_train[:validation_samples]\ny_val = y_train[:validation_samples]\nx_train_final = x_train[validation_samples:]\ny_train_final = y_train[validation_samples:]\n\nprint(f\"\\n最终数据划分:\")\nprint(f\"  训练集: {len(x_train_final)} 样本\")\nprint(f\"  验证集: {len(x_val)} 样本\")\nprint(f\"  测试集: {len(x_test)} 样本\")\n\nprint(\"\\n数据准备完成！\")",
   "id": "829ff7c70f6fdd09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T09:34:18.180032Z",
     "start_time": "2025-09-23T09:33:18.288871Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n构建并训练基于SimpleRNN的情感分析模型\n演示双层RNN架构在文本分类任务中的应用\n\"\"\"\nfrom keras.layers import Dense, Embedding, SimpleRNN\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\n\nprint(\"=\" * 70)\nprint(\"构建SimpleRNN模型\")\nprint(\"=\" * 70)\n\n# 构建模型架构\nmodel = Sequential([\n    # 嵌入层: 将词索引映射到稠密向量空间\n    Embedding(input_dim=MAX_FEATURES, output_dim=32),\n    \n    # 第一层RNN: 返回完整序列以便堆叠\n    SimpleRNN(units=32, return_sequences=True, dropout=0.2),\n    \n    # 第二层RNN: 只返回最后时间步的输出\n    SimpleRNN(units=32, dropout=0.2),\n    \n    # 输出层: 二分类任务\n    Dense(1, activation='sigmoid')\n])\n\n# 编译模型\nmodel.compile(\n    optimizer=Adam(learning_rate=0.001),\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"开始训练（使用少量epoch进行快速测试）\")\nprint(\"=\" * 70)\n\n# 训练模型\n# 注意：为了快速测试，这里只训练3个epoch\n# 实际应用中可能需要更多epoch\nhistory = model.fit(\n    x_train_final, \n    y_train_final,\n    epochs=3,                    # 测试时使用较少epoch\n    batch_size=128,\n    validation_data=(x_val, y_val),\n    verbose=1\n)\n\nprint(\"\\n训练完成！\")\nprint(f\"最终训练准确率: {history.history['accuracy'][-1]:.4f}\")\nprint(f\"最终验证准确率: {history.history['val_accuracy'][-1]:.4f}\")",
   "id": "26ebc2932105dd52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-20T09:05:56.753924Z",
     "start_time": "2025-09-20T09:05:56.651784Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n可视化训练过程\n绘制训练和验证的准确率及损失曲线\n\"\"\"\nimport matplotlib.pyplot as plt\n\n# 提取训练历史数据\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(1, len(acc) + 1)\n\n# 创建图表\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\n# 绘制准确率曲线\nax1.plot(epochs_range, acc, 'bo-', label='训练准确率', linewidth=2, markersize=8)\nax1.plot(epochs_range, val_acc, 'rs-', label='验证准确率', linewidth=2, markersize=8)\nax1.set_title('训练和验证准确率', fontsize=14, fontweight='bold')\nax1.set_xlabel('Epoch', fontsize=12)\nax1.set_ylabel('准确率', fontsize=12)\nax1.legend(fontsize=11)\nax1.grid(True, alpha=0.3)\n\n# 绘制损失曲线\nax2.plot(epochs_range, loss, 'bo-', label='训练损失', linewidth=2, markersize=8)\nax2.plot(epochs_range, val_loss, 'rs-', label='验证损失', linewidth=2, markersize=8)\nax2.set_title('训练和验证损失', fontsize=14, fontweight='bold')\nax2.set_xlabel('Epoch', fontsize=12)\nax2.set_ylabel('损失', fontsize=12)\nax2.legend(fontsize=11)\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# 分析过拟合情况\nif len(acc) > 1:\n    train_val_gap = acc[-1] - val_acc[-1]\n    if train_val_gap > 0.1:\n        print(f\"\\n⚠️  检测到过拟合: 训练准确率比验证准确率高 {train_val_gap:.2%}\")\n        print(\"建议: 增加dropout、减少模型复杂度或使用更多训练数据\")\n    else:\n        print(f\"\\n✓ 模型泛化良好: 训练-验证准确率差距为 {train_val_gap:.2%}\")",
   "id": "570d9b2cdad68b32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T09:38:18.961651Z",
     "start_time": "2025-09-23T09:34:24.294320Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n使用LSTM改进模型性能\nLSTM通过门控机制解决RNN的梯度消失问题\n\"\"\"\nfrom keras.layers import LSTM\n\nprint(\"=\" * 70)\nprint(\"构建LSTM模型\")\nprint(\"=\" * 70)\n\n# 构建LSTM模型\nlstm_model = Sequential([\n    # 嵌入层\n    Embedding(input_dim=MAX_FEATURES, output_dim=32),\n    \n    # LSTM层: 比SimpleRNN更善于捕捉长期依赖\n    # LSTM包含三个门: 遗忘门、输入门、输出门\n    LSTM(units=32, dropout=0.2, recurrent_dropout=0.2),\n    \n    # 输出层\n    Dense(1, activation='sigmoid')\n])\n\n# 编译模型\nlstm_model.compile(\n    optimizer=Adam(learning_rate=0.001),\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\nlstm_model.summary()\n\nprint(\"\\n\" + \"=\" * 70)\nprint(\"训练LSTM模型\")\nprint(\"=\" * 70)\n\n# 训练LSTM模型\nlstm_history = lstm_model.fit(\n    x_train_final,\n    y_train_final,\n    epochs=3,                    # 测试时使用较少epoch\n    batch_size=128,\n    validation_data=(x_val, y_val),\n    verbose=1\n)\n\nprint(\"\\n训练完成！\")\nprint(f\"最终训练准确率: {lstm_history.history['accuracy'][-1]:.4f}\")\nprint(f\"最终验证准确率: {lstm_history.history['val_accuracy'][-1]:.4f}\")\n\n# 在测试集上评估\ntest_loss, test_acc = lstm_model.evaluate(x_test, y_test, verbose=0)\nprint(f\"\\n测试集准确率: {test_acc:.4f}\")",
   "id": "c2a404a5a5d06101",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-23T09:38:52.379397Z",
     "start_time": "2025-09-23T09:38:52.371814Z"
    }
   },
   "cell_type": "code",
   "source": "model.summary()",
   "id": "dffcf0f3c39c8121",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │       \u001b[38;5;34m320,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">320,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m985,061\u001b[0m (3.76 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">985,061</span> (3.76 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m328,353\u001b[0m (1.25 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">328,353</span> (1.25 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m656,708\u001b[0m (2.51 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">656,708</span> (2.51 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c50a3dd38c71f6fc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}