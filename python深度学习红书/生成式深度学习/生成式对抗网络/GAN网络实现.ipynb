{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# GAN生成器网络",
   "id": "c28dfcafdc883af1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T14:26:13.721812Z",
     "start_time": "2025-09-27T14:26:13.662814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# 设置随机种子\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "latent_dim = 32 # 随机噪声的维度\n",
    "height, width, channels = 32, 32, 3 # 生成图片的尺寸\n",
    "\n",
    "generator_input = keras.Input(shape=(laten_dim,))\n",
    "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Reshape((16, 16, 128))(x)\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(256, 5, padding='same')(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
    "# 生成器Model实例化 讲形状为(laten_dim,)的张量映射为形状为(height, width, channels)的图像\n",
    "generator = keras.models.Model(generator_input, x)\n",
    "generator.summary()"
   ],
   "id": "ea1a4d44c6405e42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32)]              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32768)             1081344   \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 32768)             0         \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 256)       819456    \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 256)      1048832   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 32, 32, 256)       1638656   \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 32, 32, 256)       1638656   \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 32, 32, 3)         37635     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# GAN判别器网络",
   "id": "feed6876935d098b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T14:26:13.847322Z",
     "start_time": "2025-09-27T14:26:13.784320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "discriminator_input = layers.Input(shape=(height, width, channels))\n",
    "x = layers.Conv2D(128, 3)(discriminator_input)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides= 2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Conv2D(128, 4, strides=2)(x)\n",
    "x = layers.LeakyReLU()(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dropout(0.3)(x) # Dropout层有助于减少过拟合\n",
    "\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "# 判别器Model实例化 讲形状为(height, width, channels)的图像映射为0到1之间的实数\n",
    "discriminator = keras.models.Model(discriminator_input, x)\n",
    "discriminator.summary()\n",
    "\n",
    "discriminator_optimizer = keras.optimizers.RMSprop(\n",
    "    learning_rate=0.0008,\n",
    "    clipvalue=1.0,\n",
    "    decay=1e-8 # 限制梯度值的范围 进行梯度剪枝\n",
    ")\n",
    "\n",
    "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')"
   ],
   "id": "1700443a185b8bdf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 30, 30, 128)       3584      \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 30, 30, 128)       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 14, 14, 128)       262272    \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 14, 14, 128)       0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 6, 6, 128)         262272    \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 6, 6, 128)         0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 2, 2, 128)         262272    \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 790,913\n",
      "Trainable params: 790,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 对抗网络",
   "id": "f2f6c759e71c0275"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T14:26:13.887962Z",
     "start_time": "2025-09-27T14:26:13.854910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "discriminator.trainable = False # 判别器在对抗网络中是不可训练的\n",
    "gan_input = keras.Input(shape= (latent_dim,))\n",
    "gan_output = discriminator(generator(gan_input))\n",
    "gan = keras.models.Model(gan_input, gan_output)\n",
    "gan_optimizer = keras.optimizers.RMSprop(learning_rate=0.0004, clipvalue=1.0, decay=1e-8)\n",
    "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
   ],
   "id": "af09fe7ff79b9bf4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 训练DCGAN",
   "id": "78a29546eb208587"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T14:26:49.729157Z",
     "start_time": "2025-09-27T14:26:49.226786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import tensorflow\n",
    "from keras.preprocessing import image\n",
    "# 加载数据集\n",
    "(x_train, y_train), (_,_) = tensorflow.keras.datasets.cifar10.load_data()\n",
    "x_train = x_train.reshape((x_train.shape[0],) + (32, 32, 3)).astype('float32') / 255.0 # 数据标准化\n",
    "iterations = 10000 # 迭代次数\n",
    "batch_size = 20\n",
    "save_dir = r'C:\\Users\\Administrator\\PycharmProjects\\深度学习日常练习项目\\python深度学习红书\\生成式深度学习\\生成式对抗网络\\GAN网络生成图片'\n",
    "\n",
    "start = 0\n",
    "for step in range(iterations):\n",
    "    # 在潜在空间随机采集点\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
    "    # 通过生成器生成图像\n",
    "    generated_imags = generator.predict(random_latent_vectors)\n",
    "    stop = start + batch_size\n",
    "    real_images = x_train[start: stop] # 从真实数据集中采集图像\n",
    "    combined_images = np.concatenate([generated_imags, real_images])\n",
    "    labels = np.concatenate([np.ones((batch_size, 1)), np.zeros((batch_size, 1))]) # 生成标签 1表示真实图像 0表示生成图像 以便区分\n",
    "    labels += 0.05 * np.random.random(labels.shape) # 添加噪声\n",
    "    d_loss = discriminator.train_on_batch(combined_images, labels) # 训练判别器\n",
    "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim)) # 在潜在空间随机采集点\n",
    "    misleading_targets = np.zeros((batch_size, 1)) # 生成标签 1表示真实图像 0表示生成图像 以便区分\n",
    "    # 通过gan模型训练生成器 目标是让生成器愚弄判别器 让判别器认为生成的图像是真实的\n",
    "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets) # 训练生成器\n",
    "    start += batch_size\n",
    "    if start > len(x_train) - batch_size:\n",
    "        start = 0\n",
    "\n",
    "    # 每100步保存一次生成的图像和模型权重\n",
    "    if step % 100 == 0:\n",
    "        gan.save_weights('gan.h5')\n",
    "        # 保存生成的图像\n",
    "        print('step %d: d_loss = %f, a_loss = %f' % (step, d_loss, a_loss))\n",
    "        img = image.array_to_img(generated_imags[0] * 255., scale=False)\n",
    "        img.save(os.path.join(save_dir, 'generated_fantasy.png'))\n",
    "        img = image.array_to_img(real_images[0] * 255., scale=False)# 保存真实图像\n",
    "        img.save(os.path.join(save_dir, 'real_fantasy.png'))"
   ],
   "id": "2f5130c426898d03",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\Administrator\\\\.keras\\\\datasets\\\\cifar-10-batches-py\\\\data_batch_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m image\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 加载数据集\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m (x_train, y_train), (_,_) \u001b[38;5;241m=\u001b[39m \u001b[43mtensorflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcifar10\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m x_train \u001b[38;5;241m=\u001b[39m x_train\u001b[38;5;241m.\u001b[39mreshape((x_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m3\u001b[39m))\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m \u001b[38;5;66;03m# 数据标准化\u001b[39;00m\n\u001b[0;32m      7\u001b[0m iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m \u001b[38;5;66;03m# 迭代次数\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DeepLearning-py310\\lib\\site-packages\\keras\\datasets\\cifar10.py:98\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m6\u001b[39m):\n\u001b[0;32m     94\u001b[0m     fpath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_batch_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i))\n\u001b[0;32m     95\u001b[0m     (\n\u001b[0;32m     96\u001b[0m         x_train[(i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10000\u001b[39m : i \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10000\u001b[39m, :, :, :],\n\u001b[0;32m     97\u001b[0m         y_train[(i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10000\u001b[39m : i \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10000\u001b[39m],\n\u001b[1;32m---> 98\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mload_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m fpath \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    101\u001b[0m x_test, y_test \u001b[38;5;241m=\u001b[39m load_batch(fpath)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DeepLearning-py310\\lib\\site-packages\\keras\\datasets\\cifar.py:31\u001b[0m, in \u001b[0;36mload_batch\u001b[1;34m(fpath, label_key)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_batch\u001b[39m(fpath, label_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     21\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Internal utility for parsing CIFAR data.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m        A tuple `(data, labels)`.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     32\u001b[0m         d \u001b[38;5;241m=\u001b[39m cPickle\u001b[38;5;241m.\u001b[39mload(f, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m         \u001b[38;5;66;03m# decode utf8\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Administrator\\\\.keras\\\\datasets\\\\cifar-10-batches-py\\\\data_batch_1'"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2e24f59e3f81e8cd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}