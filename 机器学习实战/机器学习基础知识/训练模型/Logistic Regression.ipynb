{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-17T07:04:00.628Z",
     "start_time": "2025-10-17T07:04:00.623835Z"
    }
   },
   "source": "# ============================================================\n# 逻辑回归 (Logistic Regression)\n# ============================================================\n# \n# 逻辑回归是用于二分类问题的经典算法\n# 虽然名字里有\"回归\"，但它是一个分类算法\n# \n# 核心思想：\n# 1. 使用线性模型计算得分: z = θᵀx\n# 2. 通过 Sigmoid 函数将得分映射到概率: p = σ(z) = 1/(1+e^(-z))\n# 3. 使用阈值（通常0.5）进行分类\n# \n# 损失函数：交叉熵 (Cross-Entropy)\n# J(θ) = -1/m Σ[y·log(p) + (1-y)·log(1-p)]\n# ============================================================\n\nfrom sklearn import datasets\n\n# 加载鸢尾花数据集\niris = datasets.load_iris()\n\nprint(\"数据集字段:\", list(iris.keys()))\nprint(f\"\\n特征名称: {iris['feature_names']}\")\nprint(f\"目标类别: {iris['target_names']}\")\n\n# ============================================================\n# 准备二分类数据\n# ============================================================\n# 任务：根据花瓣宽度(petal width)判断是否为 Virginica 类\n\n# 只使用花瓣宽度特征（第4个特征）\nX = iris['data'][:, 3:]  # 花瓣宽度\n\n# 创建二分类标签：Virginica类(target=2)为正类(1)，其他为负类(0)\ny = (iris['target'] == 2).astype(int)\n\nprint(f\"\\n特征形状: {X.shape}\")\nprint(f\"正类样本数: {sum(y)} (Virginica)\")\nprint(f\"负类样本数: {len(y) - sum(y)} (非Virginica)\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T07:04:01.308673Z",
     "start_time": "2025-10-17T07:04:01.302673Z"
    }
   },
   "cell_type": "code",
   "source": "# ============================================================\n# 训练逻辑回归模型\n# ============================================================\n\nfrom sklearn.linear_model import LogisticRegression\n\n# 创建逻辑回归模型\n# 默认参数使用 L2 正则化 (penalty='l2')\nlog_reg = LogisticRegression(random_state=42)\n\n# 训练模型\nlog_reg.fit(X, y)\n\n# 查看学习到的参数\nprint(\"模型参数:\")\nprint(\"-\" * 40)\nprint(f\"  截距 (intercept): {log_reg.intercept_[0]:.4f}\")\nprint(f\"  系数 (coef):      {log_reg.coef_[0, 0]:.4f}\")\nprint(\"-\" * 40)\nprint(f\"\\n决策边界: 当花瓣宽度 = {-log_reg.intercept_[0]/log_reg.coef_[0,0]:.2f} cm 时，概率为 0.5\")",
   "id": "f40778120dcffa91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T07:04:01.955935Z",
     "start_time": "2025-10-17T07:04:01.890427Z"
    }
   },
   "cell_type": "code",
   "source": "# ============================================================\n# 可视化预测概率曲线\n# ============================================================\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# 设置随机种子\nnp.random.seed(42)\n\n# 设置中文字体\nplt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei']\nplt.rcParams['axes.unicode_minus'] = False\n\n# 生成测试数据点\nX_new = np.linspace(0, 3, 1000).reshape(-1, 1)\n\n# 预测概率\n# predict_proba 返回每个类别的概率 [P(y=0), P(y=1)]\ny_proba = log_reg.predict_proba(X_new)\n\n# 绘图\nplt.figure(figsize=(10, 6))\n\n# 绘制概率曲线\nplt.plot(X_new, y_proba[:, 1], \"g-\", linewidth=2, label=\"P(Virginica)\")\nplt.plot(X_new, y_proba[:, 0], \"b--\", linewidth=2, label=\"P(非Virginica)\")\n\n# 标记决策边界\ndecision_boundary = -log_reg.intercept_[0] / log_reg.coef_[0, 0]\nplt.axvline(x=decision_boundary, color='r', linestyle=':', linewidth=2, \n            label=f'决策边界 (x={decision_boundary:.2f})')\nplt.axhline(y=0.5, color='gray', linestyle=':', alpha=0.5)\n\n# 绘制训练数据点\nplt.scatter(X[y==0], np.zeros(sum(y==0)), c='blue', marker='|', s=100, alpha=0.7)\nplt.scatter(X[y==1], np.ones(sum(y==1)), c='green', marker='|', s=100, alpha=0.7)\n\nplt.xlabel('花瓣宽度 (cm)', fontsize=12)\nplt.ylabel('概率', fontsize=12)\nplt.title('逻辑回归: Sigmoid 概率曲线', fontsize=14)\nplt.legend(loc='center right')\nplt.grid(True, alpha=0.3)\nplt.ylim(-0.1, 1.1)\nplt.show()\n\nprint(\"Sigmoid函数: σ(z) = 1 / (1 + e^(-z))\")\nprint(f\"决策边界: 花瓣宽度 = {decision_boundary:.2f} cm\")",
   "id": "cde7f0a8dd4cc6ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T07:12:15.831931Z",
     "start_time": "2025-10-17T07:12:15.827931Z"
    }
   },
   "cell_type": "code",
   "source": "# ============================================================\n# 使用模型进行预测\n# ============================================================\n\n# 测试不同花瓣宽度的样本\ntest_samples = [[1.7], [1.5], [2.0], [1.0]]\n\nprint(\"预测结果:\")\nprint(\"-\" * 50)\nprint(f\"{'花瓣宽度':<10} {'预测类别':<12} {'概率':<20}\")\nprint(\"-\" * 50)\n\nfor sample in test_samples:\n    pred_class = log_reg.predict([sample])[0]\n    pred_proba = log_reg.predict_proba([sample])[0]\n    class_name = \"Virginica\" if pred_class == 1 else \"非Virginica\"\n    print(f\"{sample[0]:<10} {class_name:<12} P(V)={pred_proba[1]:.4f}\")\n    \nprint(\"-\" * 50)",
   "id": "5462a269e9e82d02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-17T07:18:04.576001Z",
     "start_time": "2025-10-17T07:18:04.564002Z"
    }
   },
   "cell_type": "code",
   "source": "# ============================================================\n# 多分类：Softmax 回归\n# ============================================================\n# \n# 当类别数 > 2 时，使用 Softmax 回归\n# Softmax 函数将得分转换为概率分布：\n# P(y=k) = exp(z_k) / Σexp(z_j)\n# \n# 确保所有类别概率之和为 1\n\n# 使用两个特征：花瓣长度和花瓣宽度\nX = iris['data'][:, (2, 3)]  # petal length, petal width\ny = iris['target']  # 3个类别：0, 1, 2\n\nprint(f\"特征形状: {X.shape}\")\nprint(f\"类别: {iris['target_names']}\")\n\n# 创建 Softmax 回归模型\n# solver='lbfgs': 使用 L-BFGS 优化算法\n# C=10: 正则化强度的倒数（C越大，正则化越弱）\nsoftmax_reg = LogisticRegression(solver=\"lbfgs\", C=10, random_state=42)\n\n# 训练模型\nsoftmax_reg.fit(X, y)\n\n# 预测新样本\ntest_sample = [[5, 2]]  # 花瓣长度=5cm, 花瓣宽度=2cm\npred_class = softmax_reg.predict(test_sample)\npred_proba = softmax_reg.predict_proba(test_sample)\n\nprint(f\"\\n测试样本: 花瓣长度={test_sample[0][0]}cm, 花瓣宽度={test_sample[0][1]}cm\")\nprint(f\"预测类别: {iris['target_names'][pred_class[0]]}\")\nprint(f\"\\n各类别概率:\")\nfor i, name in enumerate(iris['target_names']):\n    print(f\"  {name}: {pred_proba[0, i]:.4f} ({pred_proba[0, i]*100:.1f}%)\")",
   "id": "5309fb954de99728",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# ============================================================\n# 可视化 Softmax 回归决策边界\n# ============================================================\n\n# 创建网格点\nx0_min, x0_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\nx1_min, x1_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\nxx0, xx1 = np.meshgrid(np.linspace(x0_min, x0_max, 100),\n                        np.linspace(x1_min, x1_max, 100))\n\n# 预测网格点的类别\nX_grid = np.c_[xx0.ravel(), xx1.ravel()]\ny_pred = softmax_reg.predict(X_grid).reshape(xx0.shape)\n\nplt.figure(figsize=(10, 6))\n\n# 绘制决策边界\nplt.contourf(xx0, xx1, y_pred, alpha=0.3, cmap='RdYlGn')\n\n# 绘制训练样本\ncolors = ['red', 'yellow', 'green']\nfor i, name in enumerate(iris['target_names']):\n    mask = y == i\n    plt.scatter(X[mask, 0], X[mask, 1], c=colors[i], \n                edgecolors='black', s=50, label=name)\n\nplt.xlabel('花瓣长度 (cm)', fontsize=12)\nplt.ylabel('花瓣宽度 (cm)', fontsize=12)\nplt.title('Softmax 回归: 三类分类决策边界', fontsize=14)\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n\n# ============================================================\n# 知识总结\n# ============================================================\nprint(\"\\n\" + \"=\" * 60)\nprint(\"逻辑回归总结\")\nprint(\"=\" * 60)\nprint(\"\"\"\n1. 二分类逻辑回归:\n   - 使用 Sigmoid 函数: σ(z) = 1/(1+e^(-z))\n   - 输出概率 P(y=1|x)\n   - 决策边界: P = 0.5\n\n2. 多分类 Softmax 回归:\n   - 使用 Softmax 函数归一化概率\n   - 输出每个类别的概率分布\n   - 概率之和 = 1\n\n3. 常用参数:\n   - C: 正则化强度的倒数\n   - penalty: 正则化类型 ('l1', 'l2')\n   - solver: 优化算法 ('lbfgs', 'liblinear', 'saga')\n\n4. 优点:\n   - 输出概率，可解释性强\n   - 训练速度快\n   - 不易过拟合（有正则化）\n\"\"\")",
   "id": "cb658395949e6097"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}