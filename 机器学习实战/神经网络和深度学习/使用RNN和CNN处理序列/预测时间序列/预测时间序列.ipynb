{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "# 15.3预测时间序列",
   "id": "32c0c49cb1e960a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T07:41:51.421947Z",
     "start_time": "2025-10-31T07:41:50.111349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import keras.losses\n",
    "import numpy as np\n",
    "\n",
    "# 设置随机种子\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "from tensorflow.python.keras.losses import mean_squared_error\n",
    "\n",
    "\n",
    "def generate_time_series(batch_size, n_steps):\n",
    "    \"\"\"\n",
    "    生成时间序列数据的函数\n",
    "    参数:\n",
    "    batch_size (int): 每次生成的序列数量\n",
    "    n_steps (int): 每个序列的时间步长\n",
    "    返回:\n",
    "    numpy.ndarray: 形状为(batch_size, n_steps, 1)的时间序列数据\n",
    "    \"\"\"\n",
    "    # 生成4个随机数数组，分别用于控制两个正弦波的频率和相位偏移\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "    # 创建时间序列，从0到1均匀分布n_steps个点\n",
    "    time = np.linspace(0, 1, n_steps)\n",
    "    # 生成第一个正弦波，振幅为0.5\n",
    "    # 通过随机频率(freq1*10+10)和相位偏移(offsets1)控制波形\n",
    "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10))  # wave 1\n",
    "    # 添加第二个正弦波，振幅为0.2\n",
    "    # 通过不同的随机频率(freq2*20+20)和相位偏移(offsets2)控制波形\n",
    "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20))  # wave 2\n",
    "    # 添加随机噪声，振幅为0.1\n",
    "    # 使用均匀分布生成随机数并减去0.5使其均值为0\n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)  # noise\n",
    "    # 调整数组形状并转换为float32类型\n",
    "    return series[..., np.newaxis].astype(np.float32)\n",
    ""
   ],
   "id": "1b95f0ccc10c978a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-31 15:41:50.308505: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-31 15:41:50.315061: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-10-31 15:41:50.322988: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-10-31 15:41:50.325348: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-31 15:41:50.331555: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T07:41:51.444565Z",
     "start_time": "2025-10-31T07:41:51.426271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建训练集 验证集 测试集\n",
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps + 1)\n",
    "X_train,y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]"
   ],
   "id": "6712f52413efa388",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 15.3.1 基准指标",
   "id": "cb797c933f7cdc99"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T07:41:57.549435Z",
     "start_time": "2025-10-31T07:41:51.472827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[50, 1]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "model.evaluate(X_test, y_test)"
   ],
   "id": "264495ae45f61968",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dingziming/anaconda3/envs/DL-310/lib/python3.10/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761896511.545891   54330 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1761896511.571627   54330 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1761896511.572598   54330 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1761896511.574736   54330 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1761896511.575571   54330 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1761896511.576216   54330 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1761896511.673519   54330 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1761896511.674465   54330 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1761896511.675176   54330 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-10-31 15:41:51.675828: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9110 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m 75/219\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 0.4023  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1761896512.274792   54450 service.cc:146] XLA service 0x7f6cdc016bb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1761896512.274822   54450 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4080 Laptop GPU, Compute Capability 8.9\n",
      "2025-10-31 15:41:52.282333: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-31 15:41:52.298347: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 91301\n",
      "I0000 00:00:1761896512.399349   54450 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1554 - val_loss: 0.0562\n",
      "Epoch 2/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 917us/step - loss: 0.0409 - val_loss: 0.0306\n",
      "Epoch 3/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - loss: 0.0249 - val_loss: 0.0210\n",
      "Epoch 4/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - loss: 0.0179 - val_loss: 0.0163\n",
      "Epoch 5/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0142 - val_loss: 0.0133\n",
      "Epoch 6/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - loss: 0.0119 - val_loss: 0.0115\n",
      "Epoch 7/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 8/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - loss: 0.0091 - val_loss: 0.0089\n",
      "Epoch 9/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - loss: 0.0080 - val_loss: 0.0080\n",
      "Epoch 10/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - loss: 0.0072 - val_loss: 0.0071\n",
      "Epoch 11/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 12/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - loss: 0.0059 - val_loss: 0.0059\n",
      "Epoch 13/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 14/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 15/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 16/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 17/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0044 - val_loss: 0.0045\n",
      "Epoch 18/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 19/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 20/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0041 - val_loss: 0.0041\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.004255720414221287"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 15.3.2 使用RNN",
   "id": "83db58b369dce801"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T07:42:20.384088Z",
     "start_time": "2025-10-31T07:41:57.598267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "# 使用RNN\n",
    "# 目标：预测序列的下一个时间步（单值），即 Sequence-to-One 任务\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    # 1. SimpleRNN：\n",
    "    #    - 移除 return_sequences=True：让 RNN 只输出最后一个时间步的隐藏状态。\n",
    "    #    - 此时输出形状变为 (None, 50)\n",
    "    keras.layers.SimpleRNN(50, input_shape=[n_steps, 1]),\n",
    "\n",
    "    # 2. Dense 层：\n",
    "    #    - 添加一个 Dense(1) 层，将 50 个神经元压缩为最终的 1 个预测值。\n",
    "    #    - 最终模型输出形状变为 (None, 1)，与 y_train 的形状 (None, 1) 兼容。\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# 现在可以正确运行了\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))\n",
    "model.evaluate(X_test, y_test)"
   ],
   "id": "dc71113acbc586ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dingziming/anaconda3/envs/DL-310/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0163 - val_loss: 0.0058\n",
      "Epoch 2/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 3/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 4/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 5/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 6/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 7/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 8/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 9/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 10/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 11/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 12/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 13/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 14/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 15/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 16/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 17/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 18/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 19/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 20/20\n",
      "\u001b[1m219/219\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0028 - val_loss: 0.0028\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0030385295394808054"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T07:26:15.532795Z",
     "start_time": "2025-10-31T07:26:15.531135Z"
    }
   },
   "cell_type": "markdown",
   "source": "## 15.3.3 深度RNN",
   "id": "4bb8a94a30c3916"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T07:42:20.459276Z",
     "start_time": "2025-10-31T07:42:20.434992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(50, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(50, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ],
   "id": "adb68c303d1ae4df",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 15.3.4 预测未来几个时间步长",
   "id": "3f0d4ae9a21045bd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T07:44:42.274275Z",
     "start_time": "2025-10-31T07:44:41.622603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 假设 n_steps 和 generate_time_series 函数已在环境中定义\n",
    "\n",
    "# --- 辅助函数 (需自行确保定义，这里只是一个占位符示例) ---\n",
    "def generate_time_series(batch_size, n_steps):\n",
    "    # n_steps 是总序列长度 (n_steps + 10)\n",
    "\n",
    "    # 1. 修正 offsets/freqs 的形状，确保它们在 time 维度上是 1\n",
    "    # 原始代码中的 offsets/freqs 已经确保是 (batch_size, 1, 1) 的形状：\n",
    "    # freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "    # (4, 1, 1) 的形状，但用于计算时会沿着 axis=1 (n_steps) 广播。\n",
    "\n",
    "    # 2. 修正 time 的形状：从 (n_steps,) 变为 (1, n_steps, 1)\n",
    "    # 这样 time 就能与 (batch_size, 1, 1) 的 offsets 正确广播为 (batch_size, n_steps, 1)\n",
    "    freq1, freq2, offsets1, offsets2 = np.random.rand(4, batch_size, 1)\n",
    "\n",
    "    # 关键修正：使用 [np.newaxis, :, np.newaxis] 将形状变为 (1, n_steps, 1)\n",
    "    time = np.linspace(0, 1, n_steps)\n",
    "    time = time[np.newaxis, :, np.newaxis]\n",
    "\n",
    "    # 计算信号 1\n",
    "    series = 0.5 * np.sin((time - offsets1) * (freq1 * 10 + 10))\n",
    "\n",
    "    # 计算信号 2\n",
    "    series += 0.2 * np.sin((time - offsets2) * (freq2 * 20 + 20))\n",
    "\n",
    "    # 添加噪声 (噪声形状 (batch_size, n_steps, 1))\n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps, 1) - 0.5)\n",
    "\n",
    "    return series.astype(np.float32)\n",
    "\n",
    "# ... (保持主代码不变，因为修正后的 generate_time_series 会输出正确的形状)\n",
    "\n",
    "n_steps = 20 # 假设时间步长为 20\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 模型定义\n",
    "# --------------------------------------------------------------------------\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(50, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(50, return_sequences=True),\n",
    "    keras.layers.SimpleRNN(20),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# 假设模型已经编译和训练，这里省略编译和训练步骤\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "# 15.3.4 预测未来几个时间步长 (修正部分)\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "# 1. 准备数据：序列总长 n_steps (输入) + 10 (预测目标)\n",
    "steps_to_predict = 10\n",
    "series = generate_time_series(1, n_steps + steps_to_predict)\n",
    "\n",
    "# 2. 定义输入 X_new 和 真实目标值 y_new\n",
    "X_new = series[:, :n_steps]     # 输入序列 (n_steps 步)\n",
    "# 修正: y_new 必须是原始序列中 n_steps 之后的 10 个真实值，形状为 (1, 10, 1)\n",
    "y_new = series[:, n_steps:]     # 真实目标序列 (10 步)\n",
    "\n",
    "X = X_new\n",
    "print(f\"初始 X_new 形状: {X.shape}\")\n",
    "\n",
    "# 3. 多步预测循环 (自回归预测)\n",
    "for step_ahead in range(steps_to_predict):\n",
    "    # 使用当前序列 X 的 'step_ahead' 之后的部分进行预测\n",
    "    y_pred_one = model.predict(X[:, step_ahead:])[:, -1]\n",
    "\n",
    "    # 将预测值 (形状 (1, 1)) 重塑为 (1, 1, 1) 并拼接到 X 的时间轴 (axis=1) 上\n",
    "    X = np.concatenate([X, y_pred_one.reshape(-1, 1, 1)], axis=1)\n",
    "\n",
    "# 4. 提取最终的预测序列\n",
    "# 提取 X 中 n_steps 之后的部分，即 10 步预测结果\n",
    "Y_pred = X[:, n_steps:]\n",
    "print(f\"最终 Y_pred 形状: {Y_pred.shape}\")\n",
    "print(f\"最终 y_new 形状: {y_new.shape}\")\n",
    "\n",
    "# 5. 修正：将 3 维数组展平为 1 维 (或 2 维)，以满足 sklearn 的要求\n",
    "Y_pred_flat = Y_pred.ravel()\n",
    "y_new_flat = y_new.ravel()\n",
    "\n",
    "print(f\"展平后 Y_pred 形状: {Y_pred_flat.shape}\")\n",
    "print(f\"展平后 y_new 形状: {y_new_flat.shape}\")\n",
    "\n",
    "# 6. 计算均方误差\n",
    "print(\"\\n--- 评估结果 ---\")\n",
    "print(f\"预测序列的 MSE: {mean_squared_error(y_new_flat, Y_pred_flat)}\")"
   ],
   "id": "35dd5735e6c8cae2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始 X_new 形状: (1, 20, 1)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "最终 Y_pred 形状: (1, 10, 1)\n",
      "最终 y_new 形状: (1, 10, 1)\n",
      "展平后 Y_pred 形状: (10,)\n",
      "展平后 y_new 形状: (10,)\n",
      "\n",
      "--- 评估结果 ---\n",
      "预测序列的 MSE: 0.09033016115427017\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 15.3.5 序列到序列的模型",
   "id": "b04c6ea453fdb57b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T07:50:56.131957Z",
     "start_time": "2025-10-31T07:50:56.096479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "    keras.layers.TimeDistributed(keras.layers.Dense(10))\n",
    "])"
   ],
   "id": "3499b41de64c5c6f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dingziming/anaconda3/envs/DL-310/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-31T07:52:17.366768Z",
     "start_time": "2025-10-31T07:52:17.365008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 利用最后一个层进行评估\n",
    "def last_time_step_mse(Y_true, Y_pred):\n",
    "    return keras.metrics.mean_squared_error(Y_true[:, -1], Y_pred[:, -1])"
   ],
   "id": "779ba63140b5a959",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "51ddcd4f45062ebb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}