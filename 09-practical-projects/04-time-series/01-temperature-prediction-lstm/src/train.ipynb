{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69b79730",
   "metadata": {},
   "source": [
    "# LSTM温度预测模型训练脚本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22754d7d",
   "metadata": {},
   "source": [
    "使用方法:\n",
    "    python src/train.py --model_type simple --epochs 50\n",
    "    python src/train.py --model_type stacked --epochs 100\n",
    "    python src/train.py --model_type gru --epochs 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a421cd69",
   "metadata": {},
   "source": [
    "## Notebook运行提示\n",
    "- 代码已拆分为多个小单元, 按顺序运行即可在每一步观察输出与中间变量。\n",
    "- 涉及 `Path(__file__)` 或相对路径的脚本会自动注入 `__file__` 解析逻辑, Notebook 环境下也能引用原项目资源。\n",
    "- 可在每个单元下追加说明或参数试验记录, 以跟踪核心算法和数据处理步骤。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd53b1c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Notebook路径自适应处理\n",
    "import pathlib as _nb_pathlib\n",
    "def _nb_resolve_file_path():\n",
    "    if '__file__' not in globals():\n",
    "        _cwd = _nb_pathlib.Path.cwd().resolve()\n",
    "        for _candidate in (_cwd, *_cwd.parents):\n",
    "            _potential = _candidate / '09-practical-projects/04_时间序列项目/01_温度预测_LSTM中级/src/train.py'\n",
    "            if _potential.exists():\n",
    "                globals()['__file__'] = str(_potential)\n",
    "                return\n",
    "        globals()['__file__'] = str((_cwd / '09-practical-projects/04_时间序列项目/01_温度预测_LSTM中级/src/train.py').resolve())\n",
    "_nb_resolve_file_path()\n",
    "del _nb_pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa8ee2c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 添加项目根目录到路径\n",
    "project_root = Path(__file__).parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.data import prepare_temperature_data\n",
    "from src.model import TemperatureLSTMPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcd9158",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"解析命令行参数\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='训练LSTM温度预测模型')\n",
    "\n",
    "    # 模型参数\n",
    "    parser.add_argument('--model_type', type=str, default='stacked',\n",
    "                       choices=['simple', 'stacked', 'gru'],\n",
    "                       help='模型类型')\n",
    "\n",
    "    # 数据参数\n",
    "    parser.add_argument('--data_path', type=str,\n",
    "                       default='data/jena_climate_2009_2016.csv',\n",
    "                       help='数据文件路径')\n",
    "    parser.add_argument('--lookback', type=int, default=168,\n",
    "                       help='回看窗口大小（小时）')\n",
    "    parser.add_argument('--forecast_horizon', type=int, default=24,\n",
    "                       help='预测范围（小时）')\n",
    "    parser.add_argument('--sampling_rate', type=int, default=6,\n",
    "                       help='采样率（每隔多少条取一条）')\n",
    "\n",
    "    # 训练参数\n",
    "    parser.add_argument('--epochs', type=int, default=50,\n",
    "                       help='训练轮数')\n",
    "    parser.add_argument('--batch_size', type=int, default=32,\n",
    "                       help='批大小')\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.001,\n",
    "                       help='学习率')\n",
    "    parser.add_argument('--early_stopping_patience', type=int, default=10,\n",
    "                       help='早停耐心值')\n",
    "\n",
    "    # 其他参数\n",
    "    parser.add_argument('--random_state', type=int, default=42,\n",
    "                       help='随机种子')\n",
    "    parser.add_argument('--model_dir', type=str, default='models',\n",
    "                       help='模型保存目录')\n",
    "    parser.add_argument('--result_dir', type=str, default='results',\n",
    "                       help='结果保存目录')\n",
    "\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc9ef33",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_callbacks(model_path, patience=10):\n",
    "    \"\"\"\n",
    "    创建训练回调函数\n",
    "\n",
    "    Args:\n",
    "        model_path: 模型保存路径\n",
    "        patience: 早停耐心值\n",
    "\n",
    "    Returns:\n",
    "        回调函数列表\n",
    "    \"\"\"\n",
    "    callbacks = []\n",
    "\n",
    "    # ============================================\n",
    "    # ModelCheckpoint: 保存最佳模型\n",
    "    # ============================================\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath=model_path,\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode='min',\n",
    "        verbose=1\n",
    "    )\n",
    "    callbacks.append(checkpoint)\n",
    "\n",
    "    # ============================================\n",
    "    # EarlyStopping: 早停\n",
    "    # ============================================\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=patience,\n",
    "        restore_best_weights=True,\n",
    "        mode='min',\n",
    "        verbose=1\n",
    "    )\n",
    "    callbacks.append(early_stopping)\n",
    "\n",
    "    # ============================================\n",
    "    # ReduceLROnPlateau: 学习率衰减\n",
    "    # ============================================\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        mode='min',\n",
    "        verbose=1\n",
    "    )\n",
    "    callbacks.append(reduce_lr)\n",
    "\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7928405e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    # 解析参数\n",
    "    args = parse_args()\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(\"LSTM温度预测 - 模型训练\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\n配置:\")\n",
    "    for arg, value in vars(args).items():\n",
    "        print(f\"  {arg}: {value}\")\n",
    "\n",
    "    # 设置随机种子\n",
    "    np.random.seed(args.random_state)\n",
    "    tf.random.set_seed(args.random_state)\n",
    "\n",
    "    # 创建保存目录\n",
    "    project_dir = Path(__file__).parent.parent\n",
    "    model_dir = project_dir / args.model_dir\n",
    "    result_dir = project_dir / args.result_dir\n",
    "    model_dir.mkdir(exist_ok=True)\n",
    "    result_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # ============================================\n",
    "    # 步骤1: 准备数据\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤1: 准备数据\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    try:\n",
    "        (X_train, y_train), (X_val, y_val), (X_test, y_test), processor = prepare_temperature_data(\n",
    "            data_path=args.data_path,\n",
    "            lookback=args.lookback,\n",
    "            forecast_horizon=args.forecast_horizon,\n",
    "            sampling_rate=args.sampling_rate\n",
    "        )\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\n✗ 数据文件不存在: {e}\")\n",
    "        print(\"\\n请先下载数据:\")\n",
    "        print(\"  cd data\")\n",
    "        print(\"  python download_data.py\")\n",
    "        return\n",
    "\n",
    "    # 保存数据处理器\n",
    "    scaler_path = model_dir / f'{args.model_type}_scaler.pkl'\n",
    "    processor.save_scaler(scaler_path)\n",
    "\n",
    "    # ============================================\n",
    "    # 步骤2: 创建模型\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤2: 创建模型\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "    predictor = TemperatureLSTMPredictor(\n",
    "        input_shape=input_shape,\n",
    "        forecast_horizon=args.forecast_horizon,\n",
    "        model_type=args.model_type\n",
    "    )\n",
    "\n",
    "    # 打印模型摘要\n",
    "    print(f\"\\n模型结构:\")\n",
    "    predictor.summary()\n",
    "\n",
    "    # 计算参数量\n",
    "    total_params = predictor.model.count_params()\n",
    "    print(f\"\\n总参数量: {total_params:,}\")\n",
    "\n",
    "    # ============================================\n",
    "    # 步骤3: 训练模型\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤3: 训练模型\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 创建回调函数\n",
    "    model_path = model_dir / f'{args.model_type}_model.h5'\n",
    "    callbacks = create_callbacks(\n",
    "        model_path=model_path,\n",
    "        patience=args.early_stopping_patience\n",
    "    )\n",
    "\n",
    "    # 训练\n",
    "    print(f\"\\n开始训练...\")\n",
    "    history = predictor.train(\n",
    "        X_train, y_train,\n",
    "        X_val, y_val,\n",
    "        epochs=args.epochs,\n",
    "        batch_size=args.batch_size,\n",
    "        learning_rate=args.learning_rate,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # ============================================\n",
    "    # 步骤4: 评估模型\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤4: 评估模型\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 训练集评估\n",
    "    train_metrics = predictor.evaluate(X_train, y_train)\n",
    "    print(f\"\\n训练集性能:\")\n",
    "    for name, value in train_metrics.items():\n",
    "        print(f\"  {name}: {value:.4f}\")\n",
    "\n",
    "    # 验证集评估\n",
    "    val_metrics = predictor.evaluate(X_val, y_val)\n",
    "    print(f\"\\n验证集性能:\")\n",
    "    for name, value in val_metrics.items():\n",
    "        print(f\"  {name}: {value:.4f}\")\n",
    "\n",
    "    # 测试集评估\n",
    "    test_metrics = predictor.evaluate(X_test, y_test)\n",
    "    print(f\"\\n测试集性能:\")\n",
    "    for name, value in test_metrics.items():\n",
    "        print(f\"  {name}: {value:.4f}\")\n",
    "\n",
    "    # ============================================\n",
    "    # 步骤5: 详细评估（原始尺度）\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤5: 原始尺度评估\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 预测\n",
    "    y_pred_test = predictor.predict(X_test)\n",
    "\n",
    "    # 反归一化\n",
    "    y_test_original = processor.inverse_transform_target(y_test)\n",
    "    y_pred_original = processor.inverse_transform_target(y_pred_test)\n",
    "\n",
    "    # 计算原始尺度的指标\n",
    "    original_metrics = predictor.calculate_metrics(y_test_original, y_pred_original)\n",
    "    print(f\"\\n测试集性能（原始尺度）:\")\n",
    "    for name, value in original_metrics.items():\n",
    "        print(f\"  {name}: {value:.4f}\")\n",
    "\n",
    "    # ============================================\n",
    "    # 步骤6: 保存结果\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤6: 保存结果\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 保存训练历史\n",
    "    history_path = result_dir / f'{args.model_type}_history.npz'\n",
    "    np.savez(\n",
    "        history_path,\n",
    "        **history.history\n",
    "    )\n",
    "    print(f\"✓ 训练历史已保存: {history_path}\")\n",
    "\n",
    "    # 保存评估结果\n",
    "    results = {\n",
    "        'model_type': args.model_type,\n",
    "        'total_params': total_params,\n",
    "        'lookback': args.lookback,\n",
    "        'forecast_horizon': args.forecast_horizon,\n",
    "        'train_loss': train_metrics['loss'],\n",
    "        'train_mae': train_metrics['mae'],\n",
    "        'train_rmse': train_metrics['rmse'],\n",
    "        'val_loss': val_metrics['loss'],\n",
    "        'val_mae': val_metrics['mae'],\n",
    "        'val_rmse': val_metrics['rmse'],\n",
    "        'test_loss': test_metrics['loss'],\n",
    "        'test_mae': test_metrics['mae'],\n",
    "        'test_rmse': test_metrics['rmse'],\n",
    "        'test_mae_original': original_metrics['mae'],\n",
    "        'test_rmse_original': original_metrics['rmse'],\n",
    "    }\n",
    "\n",
    "    if 'mape' in original_metrics:\n",
    "        results['test_mape'] = original_metrics['mape']\n",
    "\n",
    "    results_path = result_dir / f'{args.model_type}_results.txt'\n",
    "    with open(results_path, 'w') as f:\n",
    "        for key, value in results.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "    print(f\"✓ 评估结果已保存: {results_path}\")\n",
    "\n",
    "    # 保存预测结果（用于可视化）\n",
    "    predictions_path = result_dir / f'{args.model_type}_predictions.npz'\n",
    "    np.savez(\n",
    "        predictions_path,\n",
    "        y_true=y_test_original[:100],  # 保存前100个样本\n",
    "        y_pred=y_pred_original[:100]\n",
    "    )\n",
    "    print(f\"✓ 预测结果已保存: {predictions_path}\")\n",
    "\n",
    "    # ============================================\n",
    "    # 步骤7: 示例预测\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤7: 示例预测\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 随机选择一个测试样本\n",
    "    idx = np.random.randint(0, len(X_test))\n",
    "    sample_pred = y_pred_original[idx]\n",
    "    sample_true = y_test_original[idx]\n",
    "\n",
    "    print(f\"\\n样本 {idx} 的预测结果（未来24小时温度）:\")\n",
    "    print(f\"\\n时间    真实温度(°C)  预测温度(°C)  误差(°C)\")\n",
    "    print(\"-\" * 50)\n",
    "    for hour in range(min(24, len(sample_true))):\n",
    "        error = sample_pred[hour] - sample_true[hour]\n",
    "        print(f\"{hour+1:2d}小时   {sample_true[hour]:7.2f}      {sample_pred[hour]:7.2f}      {error:+6.2f}\")\n",
    "\n",
    "    # 计算平均误差\n",
    "    mae_sample = np.mean(np.abs(sample_pred - sample_true))\n",
    "    print(f\"\\n该样本的平均绝对误差: {mae_sample:.2f}°C\")\n",
    "\n",
    "    # ============================================\n",
    "    # 总结\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"训练完成！\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\n模型保存路径: {model_path}\")\n",
    "    print(f\"数据处理器保存路径: {scaler_path}\")\n",
    "    print(f\"\\n测试集性能（原始尺度）:\")\n",
    "    print(f\"  MAE:  {original_metrics['mae']:.2f}°C\")\n",
    "    print(f\"  RMSE: {original_metrics['rmse']:.2f}°C\")\n",
    "    if 'mape' in original_metrics:\n",
    "        print(f\"  MAPE: {original_metrics['mape']:.2f}%\")\n",
    "\n",
    "    # 给出建议\n",
    "    print(f\"\\n下一步:\")\n",
    "    print(f\"  1. 查看训练历史: {history_path}\")\n",
    "    print(f\"  2. 评估模型: python src/evaluate.py --model_path {model_path} --scaler_path {scaler_path}\")\n",
    "    print(f\"  3. 尝试其他模型类型:\")\n",
    "    print(f\"     python src/train.py --model_type simple\")\n",
    "    print(f\"     python src/train.py --model_type gru\")\n",
    "\n",
    "    # 性能分析\n",
    "    print(f\"\\n性能分析:\")\n",
    "    mae_threshold = 2.0  # 2°C\n",
    "    rmse_threshold = 3.0  # 3°C\n",
    "\n",
    "    if original_metrics['mae'] < mae_threshold and original_metrics['rmse'] < rmse_threshold:\n",
    "        print(f\"  ✓✓ 模型性能优秀！\")\n",
    "        print(f\"     MAE < {mae_threshold}°C, RMSE < {rmse_threshold}°C\")\n",
    "    elif original_metrics['mae'] < mae_threshold * 1.5:\n",
    "        print(f\"  ✓ 模型性能良好\")\n",
    "        print(f\"     可以尝试:\")\n",
    "        print(f\"     - 增加训练轮数\")\n",
    "        print(f\"     - 使用更复杂的模型（stacked）\")\n",
    "        print(f\"     - 调整学习率\")\n",
    "    else:\n",
    "        print(f\"  ⚠ 模型性能有待提升，建议:\")\n",
    "        print(f\"    - 检查数据质量\")\n",
    "        print(f\"    - 增加lookback窗口\")\n",
    "        print(f\"    - 使用更多特征\")\n",
    "        print(f\"    - 增加模型复杂度\")\n",
    "\n",
    "    # 过拟合检查\n",
    "    if train_metrics['mae'] < val_metrics['mae'] * 0.7:\n",
    "        print(f\"\\n  ⚠ 检测到过拟合，建议:\")\n",
    "        print(f\"    - 增加Dropout\")\n",
    "        print(f\"    - 减少模型复杂度\")\n",
    "        print(f\"    - 增加训练数据\")\n",
    "        print(f\"    - 使用正则化\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9b72e2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
