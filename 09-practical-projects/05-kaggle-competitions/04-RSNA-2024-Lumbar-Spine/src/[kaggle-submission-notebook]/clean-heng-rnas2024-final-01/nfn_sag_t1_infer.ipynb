{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c322639e",
   "metadata": {},
   "source": [
    "# [kaggle-submission-notebook] - nfn_sag_t1_infer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c01485",
   "metadata": {},
   "source": [
    "## Notebook运行提示\n",
    "- 代码已拆分为多个小单元, 按顺序运行即可在每一步观察输出与中间变量。\n",
    "- 涉及 `Path(__file__)` 或相对路径的脚本会自动注入 `__file__` 解析逻辑, Notebook 环境下也能引用原项目资源。\n",
    "- 可在每个单元下追加说明或参数试验记录, 以跟踪核心算法和数据处理步骤。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f774d63b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data import *\n",
    "from kaggle_helper import *\n",
    "from nfn_sag_t1_all_model import Net as NFNJointNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6faa62",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_net(Net, checkpoint, cfg, device):\n",
    "    net = Net(pretrained=False, cfg=cfg)  #\n",
    "    state_dict = torch.load(\n",
    "        checkpoint,\n",
    "        map_location=lambda storage, loc: storage, weights_only=True)['state_dict']\n",
    "    print(net.load_state_dict(state_dict, strict=False))  # True\n",
    "\n",
    "    net = net.eval()\n",
    "    net.output_type = ['infer']\n",
    "    net = net.to(torch.device(device))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6024ffb1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run_nfn( valid_df, cfg, IMAGE_DIR, MODE, DEVICE ):\n",
    "\n",
    "    net = [\n",
    "        load_net(NFNJointNet, checkpoint, cfg, DEVICE)\n",
    "        for checkpoint in cfg.checkpoint\n",
    "    ]\n",
    "    num_net = len(net)\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    study_id = valid_df.study_id.unique()\n",
    "    num_study_id = len(study_id)\n",
    "    for i in range(num_study_id):\n",
    "        df = valid_df[(valid_df.study_id == study_id[i]) &\n",
    "                      (valid_df.series_description == 'Sagittal T1')]\n",
    "        series_id = df.series_id.tolist()\n",
    "        num_series_id = len(series_id)\n",
    "\n",
    "        #if 1:\n",
    "        try:\n",
    "            grade = []\n",
    "            xy, z = [], []\n",
    "            for j in range(num_series_id):\n",
    "                print('\\r', i, j, study_id[i], series_id[j], end='', flush=True)\n",
    "\n",
    "                volume, dicom_df, error_code = heng_read_series(study_id[i], series_id[j], 'Sagittal T1', IMAGE_DIR)\n",
    "                if volume is None: continue\n",
    "\n",
    "                image = np.ascontiguousarray(volume.transpose(1, 2, 0))\n",
    "                image, resize_param1 = do_resize_and_center(image, reference_size=512)  # bug #to solved later\n",
    "                image, resize_param2 = do_resize_and_center(image, reference_size=cfg.image_size)\n",
    "                image = np.ascontiguousarray(image.transpose(2, 0, 1))\n",
    "\n",
    "                if cfg.flip_tta:\n",
    "                    image1 = np.ascontiguousarray(image[::-1])\n",
    "                    batch = {\n",
    "                        'D': [len(image)] * 2,\n",
    "                        'image': torch.from_numpy(\n",
    "                            np.concatenate([image, image1]),\n",
    "                        ).cuda().byte(),\n",
    "                    }\n",
    "                else:\n",
    "                    batch = {\n",
    "                        'D': [len(image)],\n",
    "                        'image': torch.from_numpy(image).byte().to(DEVICE),\n",
    "                    }\n",
    "\n",
    "                with torch.amp.autocast(enabled=True, device_type=DEVICE):\n",
    "                    with torch.no_grad():\n",
    "                        for k in range(num_net):\n",
    "                            output = net[k](batch)\n",
    "\n",
    "                if cfg.flip_tta:\n",
    "                    #pritn('flipped')\n",
    "                    undo_tta_index = [5, 6, 7, 8, 9, 0, 1, 2, 3, 4]\n",
    "                    og  = output['grade'].data.cpu().numpy()\n",
    "                    oxy = output['xy'].data.cpu().numpy()\n",
    "                    oz  = output['z'].data.cpu().numpy()\n",
    "                    og  = (og[0] + og[1][undo_tta_index]) / 2\n",
    "                    oxy = (oxy[0] + oxy[1][undo_tta_index]) / 2\n",
    "                    oz  = (oz[0] + oz[1][undo_tta_index]) / 2\n",
    "                else:\n",
    "                    og = output['grade'].data.cpu().numpy()[0]\n",
    "                    oxy = output['xy'].data.cpu().numpy()[0]\n",
    "                    oz = output['z'].data.cpu().numpy()[0]\n",
    "\n",
    "                grade.append(og)\n",
    "                xy.append(oxy)\n",
    "                z.append(oz)\n",
    "\n",
    "            grade = np.stack(grade).mean(0)\n",
    "            xy = np.stack(xy).mean(0)\n",
    "            z = np.stack(z).mean(0)\n",
    "\n",
    "            # convert but to orginal image as in the ground truth label csv\n",
    "            # s1, dx1, dy1 = resize_param1\n",
    "            # s2, dx2, dy2 = resize_param2\n",
    "            # xy2 = (xy*4 - [[dx2, dy2]]) / s2\n",
    "            # xy1 = (xy2 - [[dx1, dy1]]) / s1\n",
    "            # xy  = xy1\n",
    "            z = np.round(z).astype(np.int32)\n",
    "            z_to_instance_number_map = {\n",
    "                z: n for (n, z) in dicom_df[['instance_number', 'z']].values\n",
    "            }\n",
    "            instance_number = [z_to_instance_number_map.get(s, -1) for s in z]\n",
    "            # ---\n",
    "\n",
    "            result[study_id[i]] = dotdict(\n",
    "                grade=grade.tolist(),\n",
    "                xy=xy.tolist(),\n",
    "                z=z.tolist(),\n",
    "                instance_number=instance_number,\n",
    "            ) #L1...5, R1...5,\n",
    "\n",
    "        #if 0:\n",
    "        except:\n",
    "            print('UNKNOWN ERROR?????', 'study_id', study_id[i])\n",
    "            pass\n",
    "\n",
    "        if (len(result) == 80) & (MODE == 'local'):\n",
    "            print('')\n",
    "            print('skipping and break!!!')\n",
    "            break\n",
    "\n",
    "        if i<2:\n",
    "            #print for debug\n",
    "            print('')\n",
    "            print('study_id', study_id[i])\n",
    "            print('series_id', series_id[j])\n",
    "            print('volume', volume.shape)\n",
    "            print('image', image.shape)\n",
    "            print('dicom_df', dicom_df.shape)\n",
    "\n",
    "            print('grade', grade.shape)\n",
    "            print(result[study_id[i]])\n",
    "            overlay = image.mean(0).astype(np.uint8)\n",
    "            overlay = cv2.cvtColor(overlay, cv2.COLOR_GRAY2BGR)\n",
    "            for l in range(10):\n",
    "                x,y = xy[l]\n",
    "                x= round(int(x*4))\n",
    "                y= round(int(y*4))\n",
    "                color=level_color[l%5]\n",
    "                cv2.circle(overlay, (x, y), 10, color, 1,cv2.LINE_AA)\n",
    "\n",
    "            plt.imshow(overlay, cmap='gray')\n",
    "            plt.show()\n",
    "    print('')\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
