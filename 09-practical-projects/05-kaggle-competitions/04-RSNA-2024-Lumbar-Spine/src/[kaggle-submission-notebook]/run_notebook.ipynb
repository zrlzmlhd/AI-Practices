{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3ef76bc",
   "metadata": {},
   "source": [
    "# # download installation wheel for kaggle notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ccc37e",
   "metadata": {},
   "source": [
    "if 0:\n",
    "    !pip download natsort -d /kaggle/working/\n",
    "    from IPython.display import FileLink\n",
    "    FileLink(r'./natsort-8.4.0-py3-none-any.whl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b76e9b",
   "metadata": {},
   "source": [
    "## Notebook运行提示\n",
    "- 代码已拆分为多个小单元, 按顺序运行即可在每一步观察输出与中间变量。\n",
    "- 涉及 `Path(__file__)` 或相对路径的脚本会自动注入 `__file__` 解析逻辑, Notebook 环境下也能引用原项目资源。\n",
    "- 可在每个单元下追加说明或参数试验记录, 以跟踪核心算法和数据处理步骤。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c287a4e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#### begining of new cell ############################################################################\n",
    "\n",
    "try:\n",
    "    import natsort\n",
    "except:\n",
    "    pass\n",
    "    # !pip install natsort\n",
    "    # !pip install natsort --no-index --find-links=file://///kaggle/input/heng-rnas2024-final-01/\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(\n",
    "    '/home/hp/work/2024/kaggle/rsna2024-lumbar-spine/[final-submit]/code/src/kaggle-submission-notebook/clean-heng-rnas2024-final-01'\n",
    "    #'/kaggle/input/clean-heng-rnas2024-final-01'\n",
    ")\n",
    "\n",
    "from data import *\n",
    "from kaggle_helper import *\n",
    "\n",
    "import pandas as pd\n",
    "from natsort import natsorted\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "print('IMPORT OK !!!!!!!!!!!!!')\n",
    "\n",
    "#### begining of new cell ############################################################################\n",
    "\n",
    "KAGGLE_DATA_DIR = (\n",
    "    # '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification'\n",
    "    '/home/hp/work/2024/kaggle/rsna2024-lumbar-spine/data/kaggle/rsna-2024-lumbar-spine-degenerative-classification'\n",
    ")\n",
    "WEIGHT_DIR =(\n",
    "    '/home/hp/work/2024/kaggle/rsna2024-lumbar-spine/[final-submit]/weight'\n",
    ")\n",
    "\n",
    "MODE   = 'submit'  # local #submit\n",
    "DEVICE = 'cuda'   # 'cpu' 'cuda'\n",
    "\n",
    "if MODE == 'local':\n",
    "    IMAGE_DIR = f'{KAGGLE_DATA_DIR}/train_images'\n",
    "    valid_df = pd.read_csv(f'{KAGGLE_DATA_DIR}/train_series_descriptions.csv')\n",
    "if MODE == 'submit':\n",
    "    IMAGE_DIR = f'{KAGGLE_DATA_DIR}/test_images'\n",
    "    valid_df = pd.read_csv(f'{KAGGLE_DATA_DIR}/test_series_descriptions.csv')\n",
    "\n",
    "# example submission file\n",
    "submit_df = make_dummy_submit(valid_df)\n",
    "\n",
    "\n",
    "nfn_cfg = dotdict(\n",
    "    bugged_pvt_v2_b4 = dotdict(\n",
    "        arch='pvt_v2_b4',\n",
    "        image_size=320,\n",
    "        flip_tta=False,\n",
    "        checkpoint=[\n",
    "            f'{WEIGHT_DIR}/nfn/nfn_model_pvtv2_b4_bugged_weight/fold0-00032592.pth',\n",
    "            f'{WEIGHT_DIR}/nfn/nfn_model_pvtv2_b4_bugged_weight/fold0-00032592.pth',\n",
    "            f'{WEIGHT_DIR}/nfn/nfn_model_pvtv2_b4_bugged_weight/fold0-00032592.pth',\n",
    "            f'{WEIGHT_DIR}/nfn/nfn_model_pvtv2_b4_bugged_weight/fold0-00032592.pth',\n",
    "            f'{WEIGHT_DIR}/nfn/nfn_model_pvtv2_b4_bugged_weight/fold0-00032592.pth',\n",
    "        ],\n",
    "    ),\n",
    "    pvt_v2_b4 = dotdict(\n",
    "        arch='pvt_v2_b4',\n",
    "        image_size=320,\n",
    "        flip_tta=True,\n",
    "        checkpoint=[\n",
    "            f'{WEIGHT_DIR}/nfn/nfn_model_pvtv2_b4_fixed_weight/fold0-fix-flip-aug-00032204.pth',\n",
    "            f'{WEIGHT_DIR}/nfn/nfn_model_pvtv2_b4_fixed_weight/fold1-fix-flip-aug-00029400.pth',\n",
    "            f'{WEIGHT_DIR}/nfn/nfn_model_pvtv2_b4_fixed_weight/fold2-fix-flip-aug-00015086.pth',\n",
    "            f'{WEIGHT_DIR}/nfn/nfn_model_pvtv2_b4_fixed_weight/fold3-fix-flip-aug-00031047.pth',\n",
    "            f'{WEIGHT_DIR}/nfn/nfn_model_pvtv2_b4_fixed_weight/fold4-fix-flip-aug-00028712.pth',\n",
    "        ],\n",
    "    ),\n",
    "    convnext_small = dotdict(\n",
    "        arch='convnext_small.fb_in22k',\n",
    "        image_size=320,\n",
    "        flip_tta=True,\n",
    "        checkpoint=[\n",
    "            f'{WEIGHT_DIR}/nfn/nfn_model_convnext_small_weight/fold0-00022892.pth',\n",
    "            f'{WEIGHT_DIR}/nfn/nfn_model_convnext_small_weight/fold1-00022736.pth',\n",
    "            f'{WEIGHT_DIR}/nfn/nfn_model_convnext_small_weight/fold2-00019850.pth',\n",
    "            f'{WEIGHT_DIR}/nfn/nfn_model_convnext_small_weight/fold3-00023580.pth',\n",
    "            f'{WEIGHT_DIR}/nfn/nfn_model_convnext_small_weight/fold4-00020176.pth',\n",
    "        ],\n",
    "    ),\n",
    "    effnet_b5=dotdict(\n",
    "        arch='tf_efficientnet_b5.ns_jft_in1k',\n",
    "        image_size=384,\n",
    "        flip_tta=True,\n",
    "        checkpoint=[\n",
    "            f'{WEIGHT_DIR}/nfn/nfn_model_effb5_weight/fold0-00023782.pth',\n",
    "            f'{WEIGHT_DIR}/nfn/nfn_model_effb5_weight/fold1-00027666.pth',\n",
    "            f'{WEIGHT_DIR}/nfn/nfn_model_effb5_weight/fold2-00031211.pth',\n",
    "            f'{WEIGHT_DIR}/nfn/nfn_model_effb5_weight/fold3-00026724.pth',\n",
    "            f'{WEIGHT_DIR}/nfn/nfn_model_effb5_weight/fold4-00032116.pth',\n",
    "        ],\n",
    "    ),\n",
    ")\n",
    "\n",
    "scs_cfg = dotdict(\n",
    "    pvt_v2_b4 = dotdict(\n",
    "        arch='pvt_v2_b4',\n",
    "        image_size=320,\n",
    "        checkpoint=[\n",
    "            f'{WEIGHT_DIR}/scs/scs_model_pvtv2_b4_weight/fold0-00009899.pth',\n",
    "            f'{WEIGHT_DIR}/scs/scs_model_pvtv2_b4_weight/fold1-00008416.pth',\n",
    "            f'{WEIGHT_DIR}/scs/scs_model_pvtv2_b4_weight/fold2-00012259.pth',\n",
    "            f'{WEIGHT_DIR}/scs/scs_model_pvtv2_b4_weight/fold3-00009486.pth',\n",
    "            f'{WEIGHT_DIR}/scs/scs_model_pvtv2_b4_weight/fold4-00006276.pth',\n",
    "        ],\n",
    "    ),\n",
    "    convnext_base = dotdict(\n",
    "        arch='convnext_base.fb_in22k',\n",
    "        image_size=320,\n",
    "        checkpoint=[\n",
    "            f'{WEIGHT_DIR}/scs/scs_model_convnext_base_weight/fold0-00010941.pth',\n",
    "            f'{WEIGHT_DIR}/scs/scs_model_convnext_base_weight/fold1-00007890.pth',\n",
    "            f'{WEIGHT_DIR}/scs/scs_model_convnext_base_weight/fold2-00010127.pth',\n",
    "            f'{WEIGHT_DIR}/scs/scs_model_convnext_base_weight/fold3-00008959.pth',\n",
    "            f'{WEIGHT_DIR}/scs/scs_model_convnext_base_weight/fold4-00008891.pth',\n",
    "        ],\n",
    "    ),\n",
    "    effnet_b4=dotdict(\n",
    "        arch='tf_efficientnet_b4.ns_jft_in1k',\n",
    "        image_size=384,\n",
    "        checkpoint=[\n",
    "            f'{WEIGHT_DIR}/scs/scs_model_effb4_weight/fold0-00015109.pth',\n",
    "            f'{WEIGHT_DIR}/scs/scs_model_effb4_weight/fold1-00014728.pth',\n",
    "            f'{WEIGHT_DIR}/scs/scs_model_effb4_weight/fold2-00019721.pth',\n",
    "            f'{WEIGHT_DIR}/scs/scs_model_effb4_weight/fold3-00011594.pth',\n",
    "            f'{WEIGHT_DIR}/scs/scs_model_effb4_weight/fold4-00013075.pth',\n",
    "        ],\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "print('SETTING OK !!!!!!!!!!!!!')\n",
    "\n",
    "\n",
    "#### begining of new cell ############################################################################\n",
    "\n",
    "\n",
    "if 1:\n",
    "    from nfn_sag_t1_infer import *\n",
    "\n",
    "    #nfn_result = run_nfn( valid_df, nfn_cfg.bugged_pvt_v2_b4, IMAGE_DIR, MODE, DEVICE )\n",
    "    #nfn_df = make_nfn_grade_submit(nfn_result)\n",
    "\n",
    "    nfn_df1 = make_nfn_grade_submit(run_nfn( valid_df, nfn_cfg.pvt_v2_b4, IMAGE_DIR, MODE, DEVICE ))\n",
    "    nfn_df2 = make_nfn_grade_submit(run_nfn( valid_df, nfn_cfg.convnext_small, IMAGE_DIR, MODE, DEVICE ))\n",
    "    nfn_df3 = make_nfn_grade_submit(run_nfn( valid_df, nfn_cfg.effnet_b5, IMAGE_DIR, MODE, DEVICE ))\n",
    "    nfn_df = (nfn_df1+nfn_df2+nfn_df3)/3\n",
    "\n",
    "    # ----\n",
    "    # merge\n",
    "    submit_df.loc[nfn_df.index, grade_col] = nfn_df\n",
    "\n",
    "    # save\n",
    "    submit_df.to_csv('submission.csv', index=True)\n",
    "    print('** FINAL SUBMIT **')\n",
    "    print(submit_df.head(30))\n",
    "    print(submit_df.shape)\n",
    "\n",
    "    print('SUBMIT OK!!!!!')\n",
    "    if MODE == 'local':\n",
    "        grade_truth_df = pd.read_csv(f'{KAGGLE_DATA_DIR}/train.csv')\n",
    "        truth_df = make_nfn_grade_truth(nfn_result, grade_truth_df)\n",
    "        truth = np.array(truth_df.values.tolist())\n",
    "        probability = np.array(nfn_df.values.tolist())\n",
    "        print('nfn:')\n",
    "        print(do_local_lb(probability, truth, False))\n",
    "\n",
    "#### begining of new cell ############################################################################\n",
    "if 1:\n",
    "    from scs_sag_t2_infer import *\n",
    "\n",
    "    # scs_result = run_scs(valid_df, scs_cfg.pvt_v2_b4, IMAGE_DIR, MODE, DEVICE)\n",
    "    # scs_result = run_scs( valid_df, scs_cfg.convnext_base, IMAGE_DIR, MODE, DEVICE )\n",
    "    scs_result = run_scs( valid_df, scs_cfg.effnet_b4, IMAGE_DIR, MODE, DEVICE )\n",
    "    scs_df = make_scs_grade_submit(scs_result)\n",
    "\n",
    "    # ----\n",
    "\n",
    "    # merge\n",
    "    submit_df.loc[scs_df.index, grade_col] = scs_df\n",
    "\n",
    "    # save\n",
    "    submit_df.to_csv('submission.csv', index=True)\n",
    "    print('** FINAL SUBMIT **')\n",
    "    print(submit_df.head(30))\n",
    "    print(submit_df.shape)\n",
    "\n",
    "    print('SUBMIT OK!!!!!')\n",
    "    if MODE == 'local':\n",
    "        grade_truth_df = pd.read_csv(f'{KAGGLE_DATA_DIR}/train.csv')\n",
    "        truth_df = make_scs_grade_truth(scs_result, grade_truth_df)\n",
    "        truth = np.array(truth_df.values.tolist())\n",
    "        probability = np.array(scs_df.values.tolist())\n",
    "        print('scs:')\n",
    "        print(do_local_lb(probability, truth, True))\n",
    "\n",
    "'''\n",
    "for debug verification \n",
    "nfn_cfg.bugged_pvt_v2_b4\n",
    "\n",
    "study_id 4003253\n",
    "series_id 1054713880\n",
    "volume (15, 384, 384)\n",
    "image (15, 320, 320)\n",
    "dicom_df (15, 13)\n",
    "grade (10, 3)\n",
    "'grade': [[0.999079704284668, 0.0009172920254059136, 3.026959348062519e-06]\n",
    "\n",
    "study_id 4646740\n",
    "series_id 3486248476\n",
    "volume (17, 540, 384)\n",
    "image (17, 320, 320)\n",
    "dicom_df (17, 13)\n",
    "grade (10, 3)\n",
    "{'grade': [[0.9185006022453308, 0.08072932809591293, 0.0007700947462581098],\n",
    "\n",
    "nfn_cfg.bugged_pvt_v2_b4\n",
    "([0.22723701218767847, 0.8666631775640278, 1.0238806241838554], 0.5134474212608597, -1)\n",
    "nfn_cfg.pvt_v2_b4\n",
    "([0.22682431068534087, 0.8538277783151468, 0.7790620735079907], 0.483031911976068, -1)\n",
    "nfn_cfg.convnext_small\n",
    "([0.21719899504804527, 0.8553222909222131, 0.924566630632426], 0.49346769173434274, -1)\n",
    "nfn_cfg.effnet_b5\n",
    "([0.2265785367620108, 0.888213609166505, 0.8170621529929115], 0.4977641791941786, -1)\n",
    "---\n",
    "scs_cfg.pvt_v2_b4\n",
    "([0.05060841049739512, 1.0678985070648728, 0.6358080051983124], 0.26964103321385474, 0.2644830739771569)\n",
    "scs_cfg.convnext_base\n",
    "([0.045310714958383604, 1.110966942427944, 0.5935163620346083], 0.2622622530060437, 0.2632618406403011)\n",
    "scs_cfg.effnet_b4\n",
    "([0.05008578044557778, 1.1748753784445447, 0.5871180228694474], 0.2710579779729628, 0.28807300030308763)\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
