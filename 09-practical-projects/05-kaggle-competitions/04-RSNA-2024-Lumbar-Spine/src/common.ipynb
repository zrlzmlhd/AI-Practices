{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf441817",
   "metadata": {},
   "source": [
    "# 04-RSNA-2024-Lumbar-Spine - common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a945a02",
   "metadata": {},
   "source": [
    "## Notebook运行提示\n",
    "- 代码已拆分为多个小单元, 按顺序运行即可在每一步观察输出与中间变量。\n",
    "- 涉及 `Path(__file__)` 或相对路径的脚本会自动注入 `__file__` 解析逻辑, Notebook 环境下也能引用原项目资源。\n",
    "- 可在每个单元下追加说明或参数试验记录, 以跟踪核心算法和数据处理步骤。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b83f0c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Notebook路径自适应处理\n",
    "import pathlib as _nb_pathlib\n",
    "def _nb_resolve_file_path():\n",
    "    if '__file__' not in globals():\n",
    "        _cwd = _nb_pathlib.Path.cwd().resolve()\n",
    "        for _candidate in (_cwd, *_cwd.parents):\n",
    "            _potential = _candidate / '09-practical-projects/05_Kaggle竞赛项目/04-RSNA-2024-Lumbar-Spine/src/common.py'\n",
    "            if _potential.exists():\n",
    "                globals()['__file__'] = str(_potential)\n",
    "                return\n",
    "        globals()['__file__'] = str((_cwd / '09-practical-projects/05_Kaggle竞赛项目/04-RSNA-2024-Lumbar-Spine/src/common.py').resolve())\n",
    "_nb_resolve_file_path()\n",
    "del _nb_pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feb9ce6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "os.environ['NUMEXPR_MAX_THREADS'] = '32'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '16'\n",
    "\n",
    "#------------------------------------------------\n",
    "# add path for local lib\n",
    "\n",
    "THIRD_PARTY_DIR = os.path.dirname(os.path.realpath(__file__)) + '/third_party'\n",
    "print('THIRD_PARTY_DIR :', THIRD_PARTY_DIR)\n",
    "sys.path.append(THIRD_PARTY_DIR)\n",
    "# mark as root sources in pycharm\n",
    "\n",
    "### common python lib ########################################\n",
    "# from my_lib.net.rate import *\n",
    "from my_lib.other import *\n",
    "from my_lib.draw import *\n",
    "from my_lib.file import *\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import json\n",
    "import zipfile\n",
    "from shutil import copyfile\n",
    "from timeit import default_timer as timer\n",
    "import itertools\n",
    "import collections\n",
    "from collections import OrderedDict\n",
    "from collections import defaultdict\n",
    "from glob import glob\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from print_dict import format_dict\n",
    "from  ast import literal_eval\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('TkAgg')\n",
    "#matplotlib.use('WXAgg')\n",
    "#matplotlib.use('Qt4Agg')\n",
    "#matplotlib.use('Qt5Agg')\n",
    "print('matplotlib.get_backend : ', matplotlib.get_backend())\n",
    "\n",
    "\n",
    "\n",
    "### deep learning framework #################################\n",
    "if 1: # for pytorch\n",
    "\timport torch\n",
    "\tfrom torch.utils.data.dataset import Dataset\n",
    "\tfrom torch.utils.data import DataLoader\n",
    "\tfrom torch.utils.data.sampler import *\n",
    "\timport torch.nn as nn\n",
    "\timport torch.nn.functional as F\n",
    "\timport torch.optim as optim\n",
    "\tfrom torch.nn.parallel.data_parallel import data_parallel\n",
    "\n",
    "\tdef pytorch_version_to_text():\n",
    "\t\ttext = ''\n",
    "\t\ttext += '\\tpytorch\\n'\n",
    "\t\ttext += '\\t\\ttorch.__version__              = %s\\n' % torch.__version__\n",
    "\t\ttext += '\\t\\ttorch.version.cuda             = %s\\n' % torch.version.cuda\n",
    "\t\ttext += '\\t\\ttorch.backends.cudnn.version() = %s\\n' % torch.backends.cudnn.version()\n",
    "\t\ttext += '\\t\\ttorch.cuda.device_count()      = %d\\n' % torch.cuda.device_count()\n",
    "\t\ttext += '\\t\\ttorch.cuda.get_device_properties() = %s\\n' % str(torch.cuda.get_device_properties(0))[22:-1]\n",
    "\t\ttext += '\\n'\n",
    "\t\treturn text\n",
    "''' \n",
    "print(common_string)\n",
    "\tpytorch\n",
    "\t\ttorch.__version__              = 2.0.1+cu117\n",
    "\t\ttorch.version.cuda             = 11.7\n",
    "\t\ttorch.backends.cudnn.version() = 8500\n",
    "\t\ttorch.cuda.device_count()      = 1\n",
    "\t\ttorch.cuda.get_device_properties() = (name='NVIDIA TITAN X (Pascal)', major=6, minor=1, total_memory=12193MB, multi_processor_count=28)\n",
    "\n",
    "\tpytorch\n",
    "\t\ttorch.__version__              = 2.3.0+cu121\n",
    "\t\ttorch.version.cuda             = 12.1\n",
    "\t\ttorch.backends.cudnn.version() = 8902\n",
    "\t\ttorch.cuda.device_count()      = 2\n",
    "\t\ttorch.cuda.get_device_properties() = (name='NVIDIA RTX 6000 Ada Generation', major=8, minor=9, total_memory=48622MB, multi_processor_count=142)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "### other kaggle task ####################################\n",
    "if 0:  # for CT scan related\n",
    "\t# https://github.com/tsangel/dicomsdl\n",
    "\timport nibabel as nib\n",
    "\timport pydicom\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################################################3\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tprint(pytorch_version_to_text())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
