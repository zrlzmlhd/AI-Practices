{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7718d811",
   "metadata": {},
   "source": [
    "# src - data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0a4d1f",
   "metadata": {},
   "source": [
    "## Notebook运行提示\n",
    "- 代码已拆分为多个小单元, 按顺序运行即可在每一步观察输出与中间变量。\n",
    "- 涉及 `Path(__file__)` 或相对路径的脚本会自动注入 `__file__` 解析逻辑, Notebook 环境下也能引用原项目资源。\n",
    "- 可在每个单元下追加说明或参数试验记录, 以跟踪核心算法和数据处理步骤。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cef3a15",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydicom\n",
    "import glob\n",
    "import cv2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from ast import literal_eval\n",
    "from natsort import natsorted\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8374c1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class dotdict(dict):\n",
    "\t__setattr__ = dict.__setitem__\n",
    "\t__delattr__ = dict.__delitem__\n",
    "\n",
    "\tdef __getattr__(self, name):\n",
    "\t\ttry:\n",
    "\t\t\treturn self[name]\n",
    "\t\texcept KeyError:\n",
    "\t\t\traise AttributeError(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14cea95",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "## data evaluation #########################################################\n",
    "\n",
    "def do_local_lb(probability,truth, is_any=False):\n",
    "\t# probability : N,2,5,3    N x condition x level x grade\n",
    "\t# truth: N,2,5\n",
    "\n",
    "\tp = probability.reshape(-1,3)\n",
    "\tt = truth.reshape(-1)\n",
    "\n",
    "\tavailable = t!=-1\n",
    "\tp = p[available]\n",
    "\tt = t[available]\n",
    "\n",
    "\tloss  = []\n",
    "\tcount = []\n",
    "\tfor i in [0, 1, 2]: #3 grade\n",
    "\t\tl = -np.log(p[t == i][:, i])\n",
    "\t\tL = len(l)\n",
    "\t\tif L == 0:\n",
    "\t\t\tcount.append(0)\n",
    "\t\t\tloss.append(0)\n",
    "\t\telse:\n",
    "\t\t\tcount.append(L)\n",
    "\t\t\tloss.append(l.mean())\n",
    "\n",
    "\tweight=[1,2,4]\n",
    "\tweighted_loss = (\n",
    "\t\t (weight[0]*count[0] * loss[0]  + weight[1]*count[1] * loss[1]  + weight[2]*count[2] * loss[2] ) /\n",
    "\t\t (weight[0]*count[0] + weight[1]*count[1] + weight[2]*count[2] )\n",
    "\t)\n",
    "\tif is_any==False:\n",
    "\t\treturn loss, weighted_loss\n",
    "\n",
    "\t#---\n",
    "\tif 1:\n",
    "\t\tany_truth = truth.reshape(-1, 5)\n",
    "\t\tany_prob  = probability.reshape(-1, 5, 3)\n",
    "\n",
    "\t\tt  = (any_truth.reshape(-1, 5) == 2).max(-1).astype(int)\n",
    "\t\tp  = (any_prob.reshape(-1, 5, 3)[..., 2]).max(-1)\n",
    "\t\tweight = (t == 1) * 4 + (t != 1) * 1\n",
    "\t\tany_loss = sklearn.metrics.log_loss(\n",
    "\t\t\ty_true=t,\n",
    "\t\t\ty_pred=p,\n",
    "\t\t\tsample_weight=weight,\n",
    "\t\t)\n",
    "\treturn loss, weighted_loss, any_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d598397f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def do_compute_point_error(xy, z, xyz_truth, threshold = [1,2,3,5]):\n",
    "\txyz_truth = xyz_truth.reshape(-1,3)\n",
    "\txy = xy.reshape(-1,2)\n",
    "\tz = z.reshape(-1)\n",
    "\n",
    "\tx_t,y_t,z_t = xyz_truth.T\n",
    "\tx,y = xy.T\n",
    "\n",
    "\tx_diff = np.abs(x-x_t)\n",
    "\ty_diff = np.abs(y-y_t)\n",
    "\tz_diff = np.abs(z-z_t)\n",
    "\tx_err = [(x_diff<=th).mean() for th in threshold]\n",
    "\ty_err = [(y_diff<=th).mean() for th in threshold]\n",
    "\tz_err = [(z_diff<=th).mean() for th in threshold]\n",
    "\n",
    "\treturn x_err,y_err,z_err,threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab22926",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "## read/write data #########################################################\n",
    "\n",
    "grade_map = {\n",
    "\t'Missing': -1,\n",
    "\t'Normal/Mild': 0,\n",
    "\t'Moderate': 1,\n",
    "\t'Severe': 2,\n",
    "}\n",
    "condition_map = {  # follow sample submission order\n",
    "\t'Left Neural Foraminal Narrowing': 'left_neural_foraminal_narrowing',\n",
    "\t'Left Subarticular Stenosis': 'left_subarticular_stenosis',\n",
    "\t'Right Neural Foraminal Narrowing': 'right_neural_foraminal_narrowing',\n",
    "\t'Right Subarticular Stenosis': 'right_subarticular_stenosis',\n",
    "\t'Spinal Canal Stenosis': 'spinal_canal_stenosis',\n",
    "}\n",
    "level_map = {\n",
    "\t'L1/L2': 'l1_l2',\n",
    "\t'L2/L3': 'l2_l3',\n",
    "\t'L3/L4': 'l3_l4',\n",
    "\t'L4/L5': 'l4_l5',\n",
    "\t'L5/S1': 'l5_s1',\n",
    "}\n",
    "description_map = {\n",
    "\t'Sagittal T2/STIR': 'sagittal_t2',\n",
    "\t'Sagittal T1': 'sagittal_t1',\n",
    "\t'Axial T2': 'axial_t2',\n",
    "}\n",
    "\n",
    "level_col = ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']\n",
    "\n",
    "condition_level_col = [  # follow sample submission order\n",
    "\t'left_neural_foraminal_narrowing_l1_l2',\n",
    "\t'left_neural_foraminal_narrowing_l2_l3',\n",
    "\t'left_neural_foraminal_narrowing_l3_l4',\n",
    "\t'left_neural_foraminal_narrowing_l4_l5',\n",
    "\t'left_neural_foraminal_narrowing_l5_s1',\n",
    "\t'left_subarticular_stenosis_l1_l2',\n",
    "\t'left_subarticular_stenosis_l2_l3',\n",
    "\t'left_subarticular_stenosis_l3_l4',\n",
    "\t'left_subarticular_stenosis_l4_l5',\n",
    "\t'left_subarticular_stenosis_l5_s1',\n",
    "\t'right_neural_foraminal_narrowing_l1_l2',\n",
    "\t'right_neural_foraminal_narrowing_l2_l3',\n",
    "\t'right_neural_foraminal_narrowing_l3_l4',\n",
    "\t'right_neural_foraminal_narrowing_l4_l5',\n",
    "\t'right_neural_foraminal_narrowing_l5_s1',\n",
    "\t'right_subarticular_stenosis_l1_l2',\n",
    "\t'right_subarticular_stenosis_l2_l3',\n",
    "\t'right_subarticular_stenosis_l3_l4',\n",
    "\t'right_subarticular_stenosis_l4_l5',\n",
    "\t'right_subarticular_stenosis_l5_s1',\n",
    "\t'spinal_canal_stenosis_l1_l2',\n",
    "\t'spinal_canal_stenosis_l2_l3',\n",
    "\t'spinal_canal_stenosis_l3_l4',\n",
    "\t'spinal_canal_stenosis_l4_l5',\n",
    "\t'spinal_canal_stenosis_l5_s1',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053d1c4c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_kaggle_csv(DATA_KAGGLE_DIR):\n",
    "\tid_df    = pd.read_csv(f'{DATA_KAGGLE_DIR}/train_series_descriptions.csv')\n",
    "\tgrade_df = pd.read_csv(f'{DATA_KAGGLE_DIR}/train.csv')\n",
    "\tcoord_df = pd.read_csv(f'{DATA_KAGGLE_DIR}/train_label_coordinates.csv')\n",
    "\n",
    "\tid_df.loc[:, 'series_description'] = id_df['series_description'].map(description_map)\n",
    "\tgrade_df = grade_df.fillna(value='Missing')\n",
    "\tgrade_df = grade_df.set_index('study_id')\n",
    "\tgrade_df = grade_df[condition_level_col]\n",
    "\tgrade_df = grade_df.map(lambda x: grade_map[x])\n",
    "\tgrade_df = grade_df.reset_index(drop=False)\n",
    "\tcoord_df.loc[:, 'condition'] = coord_df['condition'].map(condition_map)\n",
    "\tcoord_df.loc[:, 'level'] = coord_df['level'].map(level_map)\n",
    "\treturn id_df,grade_df,coord_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afe2ad2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#EVAL_COL=['ImagePositionPatient','ImageOrientationPatient','PixelSpacing']\n",
    "def do_clean_by_eval_df(df, col):\n",
    "\tfor c in col:\n",
    "\t\ttry:\n",
    "\t\t\tdf.loc[:,c] = df[c].apply(lambda x: literal_eval(x))\n",
    "\t\texcept:\n",
    "\t\t\tcontinue\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a255ab8",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "##############################################################################333\n",
    "# read data\n",
    "def np_dot(a, b):\n",
    "\treturn np.sum(a * b, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa01368",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def normalise_to_8bit(x, lower=0.1, upper=99.9):\n",
    "\tlower, upper = np.percentile(x, (lower, upper))\n",
    "\tx = np.clip(x, lower, upper)\n",
    "\tx = x - np.min(x)\n",
    "\tx = x / np.max(x)\n",
    "\treturn (x * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d1da7c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# https://www.kaggle.com/competitions/rsna-2024-lumbar-spine-degenerative-classification/discussion/537339\n",
    "def heng_read_series(study_id, series_id, series_description, image_dir):\n",
    "\tdicom_dir = f'{image_dir}/{study_id}/{series_id}'\n",
    "\n",
    "\t# read dicom file\n",
    "\tdicom_file = natsorted(glob.glob(f'{dicom_dir}/*.dcm'))\n",
    "\tif len(dicom_file) == 0:\n",
    "\t\treturn None, None, ['empty-dir']\n",
    "\n",
    "\tinstance_number = [int(f.split('/')[-1].split('.')[0]) for f in dicom_file]\n",
    "\tdicom = [pydicom.dcmread(f) for f in dicom_file]\n",
    "\n",
    "\t# make dicom header df\n",
    "\tdicom_df = []\n",
    "\tfor i, d in zip(instance_number, dicom):  # d__.dict__\n",
    "\t\tdicom_df.append(\n",
    "\t\t\tdotdict(\n",
    "\t\t\t\tstudy_id=study_id,\n",
    "\t\t\t\tseries_id=series_id,\n",
    "\t\t\t\tseries_description=series_description,\n",
    "\t\t\t\tinstance_number=i,\n",
    "\n",
    "\t\t\t\tH=d.pixel_array.shape[0],\n",
    "\t\t\t\tW=d.pixel_array.shape[1],\n",
    "\n",
    "\t\t\t\tImagePositionPatient=[float(v) for v in d.ImagePositionPatient],\n",
    "\t\t\t\tImageOrientationPatient=[float(v) for v in d.ImageOrientationPatient],\n",
    "\t\t\t\tPixelSpacing=[float(v) for v in d.PixelSpacing],\n",
    "\t\t\t\tgrouping=str([round(float(v), 3) for v in d.ImageOrientationPatient]),\n",
    "\n",
    "\t\t\t\t# error for hidden test\n",
    "\t\t\t\t##  SpacingBetweenSlices=float(d.SpacingBetweenSlices),\n",
    "\t\t\t\t##  SliceThickness=float(d.SliceThickness),\n",
    "\t\t\t)\n",
    "\t\t)\n",
    "\tdicom_df = pd.DataFrame(dicom_df)\n",
    "\t# dicom_df.to_csv('dicom_df.csv',index=False)\n",
    "\n",
    "\t# ----\n",
    "\tWmax = dicom_df.W.max()\n",
    "\tHmax = dicom_df.H.max()\n",
    "\n",
    "\terror_code = []\n",
    "\tif ((dicom_df.W.nunique() != 1) or (dicom_df.H.nunique() != 1)):\n",
    "\t\terror_code.append('multi-shape')\n",
    "\n",
    "\t\t# sort slices\n",
    "\tdicom_df = [d for _, d in dicom_df.groupby('grouping')]\n",
    "\n",
    "\tdata = []\n",
    "\tsort_data_by_group = []\n",
    "\tfor df in dicom_df:\n",
    "\t\tposition = np.array(df['ImagePositionPatient'].values.tolist())\n",
    "\t\torientation = np.array(df['ImageOrientationPatient'].values.tolist())\n",
    "\t\tnormal = np.cross(orientation[:, :3], orientation[:, 3:])\n",
    "\t\tprojection = np_dot(normal, position)\n",
    "\t\tdf.loc[:, 'projection'] = projection\n",
    "\t\tdf = df.sort_values('projection')\n",
    "\n",
    "\t\tvolume = []\n",
    "\t\tfor i in df.instance_number:\n",
    "\t\t\tv = dicom[instance_number.index(i)].pixel_array\n",
    "\t\t\tif 'multi-shape' in error_code:\n",
    "\t\t\t\tH, W = v.shape\n",
    "\t\t\t\tv = np.pad(v, [(0, Hmax - H), (0, Wmax - W)], 'reflect')\n",
    "\t\t\tvolume.append(v)\n",
    "\n",
    "\t\tvolume = np.stack(volume)\n",
    "\t\tvolume = normalise_to_8bit(volume)\n",
    "\n",
    "\t\tdata.append(dotdict(\n",
    "\t\t\tdf=df,\n",
    "\t\t\tvolume=volume,\n",
    "\t\t))\n",
    "\n",
    "\t\tif 'sagittal' in series_description.lower():\n",
    "\t\t\tsort_data_by_group.append(position[0, 0])  # x\n",
    "\t\tif 'axial' in series_description.lower():\n",
    "\t\t\tsort_data_by_group.append(position[0, 2])  # z\n",
    "\n",
    "\tdata = [r for _, r in sorted(zip(sort_data_by_group, data))]\n",
    "\tfor i, r in enumerate(data):\n",
    "\t\tr.df.loc[:, 'group'] = i\n",
    "\n",
    "\tdf = pd.concat([r.df for r in data])\n",
    "\tdf.loc[:, 'z'] = np.arange(len(df))\n",
    "\tvolume = np.concatenate([r.volume for r in data])\n",
    "\treturn volume, df, error_code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
