{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffa7e744",
   "metadata": {},
   "source": [
    "# src - run_make_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b253a0d",
   "metadata": {},
   "source": [
    "## Notebook运行提示\n",
    "- 代码已拆分为多个小单元, 按顺序运行即可在每一步观察输出与中间变量。\n",
    "- 涉及 `Path(__file__)` 或相对路径的脚本会自动注入 `__file__` 解析逻辑, Notebook 环境下也能引用原项目资源。\n",
    "- 可在每个单元下追加说明或参数试验记录, 以跟踪核心算法和数据处理步骤。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea16392a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from common import *\n",
    "from _dir_setting_ import *\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63054a7e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# convert dicom data to np array and dicom header to csv file\n",
    "def run_make_series_data():\n",
    "\tid_df = pd.read_csv(f'{DATA_KAGGLE_DIR}/train_series_descriptions.csv')\n",
    "\timage_dir = f'{DATA_KAGGLE_DIR}/train_images'\n",
    "\n",
    "\tfor i,d in id_df.iterrows():\n",
    "\t\tprint(i,d.study_id, d.series_id )\n",
    "\t\t#if i==30: exit(0)\n",
    "\t\tvolume, df, error_code = heng_read_series(d.study_id, d.series_id, d.series_description, image_dir)\n",
    "\n",
    "\t\tdata_dir = f'{DATA_PROCESSED_DIR}/mini-clean5.0/{d.study_id}/{d.series_id}'\n",
    "\t\tos.makedirs(data_dir, exist_ok=True)\n",
    "\t\tdf.to_csv(f'{data_dir}/df.csv', index=False)\n",
    "\t\tnp.savez_compressed(f'{data_dir}/volume.npz', volume=volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872aa0b9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\t\t# os.makedirs(f'{data_dir}/png', exist_ok=True)\n",
    "\t\t# for z, v in enumerate(volume):\n",
    "\t\t#     cv2.imwrite(f'{data_dir}/png/{z:02}.png', v)\n",
    "\n",
    "# nfn train data : processed_df\n",
    "def run_make_nfn_data():\n",
    "\terror_series_id = [\n",
    "\t\t#error in left point\n",
    "\t\t8785691, 3355993164, 4066376844,\n",
    "\t\t#left/right point overlap\n",
    "\t\t3230157587, 692927423, 2289719834, 4030602643, 856763877,\n",
    "\t]\n",
    "\n",
    "\ttarget_condition   = ['left_neural_foraminal_narrowing', 'right_neural_foraminal_narrowing']\n",
    "\ttarget_description = 'sagittal_t1'\n",
    "\tid_df, grade_df,coord_df = load_kaggle_csv(DATA_KAGGLE_DIR)\n",
    "\tid_df = id_df[id_df.series_description==target_description]\n",
    "\n",
    "\tprocessed_df = []\n",
    "\tfor i, d in id_df.iterrows():\n",
    "\t\tif d['series_id'] in error_series_id:  continue\n",
    "\t\tprint(i, d.series_id )\n",
    "\n",
    "\t\tdicom_df = pd.read_csv(f'{DATA_PROCESSED_DIR}/mini-clean5.0/{d.study_id}/{d.series_id}/df.csv')\n",
    "\t\tinstance_number_to_z_map = {\n",
    "\t\t\tn: z for (n, z) in dicom_df[['instance_number', 'z']].values\n",
    "\t\t}\n",
    "\n",
    "\t\tthis_left_coord_df = coord_df[\n",
    "\t\t\t  (coord_df.study_id == d.study_id)\n",
    "\t\t\t& (coord_df.series_id == d.series_id)\n",
    "\t\t\t& (coord_df.condition == 'left_neural_foraminal_narrowing')\n",
    "\t\t]\n",
    "\t\tthis_right_coord_df = coord_df[\n",
    "\t\t\t  (coord_df.study_id == d.study_id)\n",
    "\t\t\t& (coord_df.series_id == d.series_id)\n",
    "\t\t\t& (coord_df.condition == 'right_neural_foraminal_narrowing')\n",
    "\t\t]\n",
    "\t\tthis_grade_df = grade_df[\n",
    "\t\t\t(grade_df.study_id == d.study_id)\n",
    "\t\t]\n",
    "\t\tif not ((len(this_right_coord_df) == 5) & (len(this_left_coord_df) == 5)): continue\n",
    "\n",
    "\t\tzz = 0\n",
    "\t\tthis_left_coord_df  = this_left_coord_df.sort_values('level')\n",
    "\t\tthis_right_coord_df = this_right_coord_df.sort_values('level')\n",
    "\t\tthis_coord_df = pd.concat([this_left_coord_df, this_right_coord_df])\n",
    "\n",
    "\t\tinstance_number = this_coord_df['instance_number'].tolist()\n",
    "\t\txy = this_coord_df[['x', 'y']].values.tolist()\n",
    "\t\tz = [instance_number_to_z_map[n] for n in instance_number]\n",
    "\n",
    "\t\t# check same xyz in left right\n",
    "\t\tleft_xyz  = np.array([[xy[i][0], xy[i][1], z[i]] for i in range(0, 5)])\n",
    "\t\tright_xyz = np.array([[xy[i][0], xy[i][1], z[i]] for i in range(5, 10)])\n",
    "\t\tdiff = np.fabs(left_xyz.reshape(1, 5, 3) - right_xyz.reshape(5, 1, 3)).sum(-1)\n",
    "\t\tif (diff < 2).any():\n",
    "\t\t\tprint('error : same left/right ???', i, d)\n",
    "\t\t\t# 3230157587,692927423,2289719834,4030602643,856763877\n",
    "\t\t\traise NotImplementedError\n",
    "\n",
    "\t\tgrade = this_grade_df[\n",
    "\t\t\t  ['left_neural_foraminal_narrowing_' + l for l in level_col]\n",
    "\t\t\t+ ['right_neural_foraminal_narrowing_' + l for l in level_col]\n",
    "\t\t].values[0].tolist()\n",
    "\n",
    "\t\tone_row = dotdict(\n",
    "\t\t\tstudy_id=d.study_id,\n",
    "\t\t\tseries_id=d.series_id,\n",
    "\t\t\tseries_description=target_description,\n",
    "\t\t\tgrade=grade,\n",
    "\t\t\tinstance_number=instance_number,\n",
    "\t\t\tz=z,\n",
    "\t\t\txy=xy,\n",
    "\t\t)\n",
    "\t\tprocessed_df.append(one_row)\n",
    "\n",
    "\tprocessed_df = pd.DataFrame(processed_df)\n",
    "\tprint(processed_df)\n",
    "\tprocessed_df = processed_df.reset_index(drop=True)\n",
    "\n",
    "\tcsv_file = f'{DATA_PROCESSED_DIR}/nfn_sag_t1_processed_df.csv'\n",
    "\tprocessed_df.to_csv(csv_file, index=False)\n",
    "\tprint('saved:', csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e47e3dd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\t#[1959 rows x 7 columns]\n",
    "\n",
    "def run_make_scs_data():\n",
    "\terror_id = [  # (study_id,series_id)\n",
    "\t\t(3637444890, 3892989905),\n",
    "\t]\n",
    "\n",
    "\ttarget_condition = ['spinal_canal_stenosis']\n",
    "\ttarget_description = 'sagittal_t2'\n",
    "\tid_df, grade_df, coord_df = load_kaggle_csv(DATA_KAGGLE_DIR)\n",
    "\n",
    "\t#hand corrected level points for SCS from team mate @lhwcv\n",
    "\tcoord_df = pd.read_csv(f'{DATA_PROCESSED_DIR}/train_label_coordinates.fix01b.csv')\n",
    "\tcoord_df = coord_df.sort_values(['study_id', 'series_id', 'level', 'condition', ])\n",
    "\n",
    "\tid_df = id_df[id_df.series_description==target_description]\n",
    "\tprocessed_df = []\n",
    "\tfor i,d in id_df.iterrows():\n",
    "\n",
    "\t\tdicom_df = pd.read_csv(f'{DATA_PROCESSED_DIR}/mini-clean5.0/{d.study_id}/{d.series_id}/df.csv')\n",
    "\t\tinstance_number_to_z_map={\n",
    "\t\t\tn:z for (n,z) in dicom_df[['instance_number', 'z']].values\n",
    "\t\t}\n",
    "\t\tthis_coord_df = coord_df[\n",
    "\t\t\t\t(coord_df.study_id == d.study_id)\n",
    "\t\t\t\t& (coord_df.series_id == d.series_id)\n",
    "\t\t\t\t& (coord_df.condition == 'spinal_canal_stenosis')\n",
    "\t\t\t]\n",
    "\t\tthis_grade_df = grade_df[\n",
    "\t\t\t(grade_df.study_id == d.study_id)\n",
    "\t\t]\n",
    "\t\tif not((len(this_coord_df)==5)):\n",
    "\t\t\tprint('skipping',d.study_id, d.series_id)\n",
    "\t\t\t#skipping 3637444890\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tthis_coord_df = this_coord_df.sort_values('level')\n",
    "\t\tinstance_number = this_coord_df['instance_number'].tolist()\n",
    "\t\tz = [instance_number_to_z_map[n] for n in instance_number]\n",
    "\t\txy = this_coord_df[['x','y']].values.tolist()\n",
    "\t\txyz = [[x,y,s] for s,(x,y) in zip(z,xy)]\n",
    "\n",
    "\t\tgrade = this_grade_df[\n",
    "\t\t\t['spinal_canal_stenosis_' + l for l in level_col]\n",
    "\t\t].values[0].tolist()\n",
    "\t\tlevel = level_col\n",
    "\n",
    "\t\tone_row = dotdict(\n",
    "\t\t\tstudy_id=d.study_id,\n",
    "\t\t\tseries_id=d.series_id,\n",
    "\t\t\tseries_description=target_description,\n",
    "\t\t\tinstance_number = instance_number,\n",
    "\t\t\tlevel = level,\n",
    "\t\t\tgrade = grade,\n",
    "\t\t\txyz = xyz,\n",
    "\t\t)\n",
    "\t\tprocessed_df.append(one_row)\n",
    "\n",
    "\tprocessed_df= pd.DataFrame(processed_df)\n",
    "\tprint(processed_df)\n",
    "\tprocessed_df = processed_df.reset_index(drop=True)\n",
    "\n",
    "\tcsv_file = f'{DATA_PROCESSED_DIR}/scs_sag_t2_processed_df.csv'\n",
    "\tprocessed_df.to_csv(csv_file, index=False)\n",
    "\tprint('saved:', csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d1b965",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\t#[1973 rows x 7 columns]\n",
    "\n",
    "\n",
    "\n",
    "# main #################################################################\n",
    "if __name__ == '__main__':\n",
    "\trun_make_series_data()\n",
    "\trun_make_nfn_data()\n",
    "\trun_make_scs_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
