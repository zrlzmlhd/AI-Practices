{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a70ac48",
   "metadata": {},
   "source": [
    "# src - model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2d6ee3",
   "metadata": {},
   "source": [
    "## Notebook运行提示\n",
    "- 代码已拆分为多个小单元, 按顺序运行即可在每一步观察输出与中间变量。\n",
    "- 涉及 `Path(__file__)` 或相对路径的脚本会自动注入 `__file__` 解析逻辑, Notebook 环境下也能引用原项目资源。\n",
    "- 可在每个单元下追加说明或参数试验记录, 以跟踪核心算法和数据处理步骤。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e23f14",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import timm\n",
    "#from timm.models.convnext import *\n",
    "\n",
    "from decoder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b39cb3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#------------------------------------------------\n",
    "# processing\n",
    "\n",
    "def heatmap_to_coord(heatmap):\n",
    "    device = heatmap.device\n",
    "    B, num_point, H, W = heatmap.shape\n",
    "\n",
    "    # create coordinates grid.\n",
    "    x = torch.linspace(0, W - 1, W, device=device)\n",
    "    y = torch.linspace(0, H - 1, H, device=device)\n",
    "    # if normalized_coordinates:\n",
    "    #     xs = (xs / (width - 1) - 0.5) * 2\n",
    "    #     ys = (ys / (height - 1) - 0.5) * 2\n",
    "    grid = torch.meshgrid([x, y], indexing='xy')\n",
    "    pos_x = grid[0].reshape(1,1,-1)\n",
    "    pos_y = grid[1].reshape(1,1,-1)\n",
    "\n",
    "    h = heatmap.reshape(B, num_point, -1)\n",
    "    y = torch.sum(pos_y * h, -1, keepdim=True)\n",
    "    x = torch.sum(pos_x * h, -1, keepdim=True)\n",
    "    xy = torch.cat([x, y], -1)\n",
    "    xy = xy.reshape(B,num_point,2)\n",
    "    return xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898ba6b5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def heatmap_to_grade(grade_mask, level_mask):\n",
    "    num_image, num_level, h, w = level_mask.shape\n",
    "    num_image, num_grade, h, w = grade_mask.shape\n",
    "\n",
    "    e = level_mask.reshape(num_image, num_level, 1, h, w)\n",
    "    g = grade_mask.reshape(num_image, 1, num_grade, h, w)\n",
    "    grade = (e * g).sum(dim=(-2, -1))\n",
    "    return grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad03c01",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# dynamic matching\n",
    "def do_dynamic_match_truth(xy, truth_xyz, threshold=3):\n",
    "    num_image, num_point, _2_ = xy.shape\n",
    "    t = truth_xyz[:, :, 1].reshape(num_image, 1, 5)\n",
    "    p = xy[:, :, 1].reshape(num_image, 5, 1)\n",
    "    diff = torch.abs(p - t)\n",
    "    value, index = diff.min(-1)\n",
    "    valid = (value < threshold)\n",
    "    return index.detach(), valid.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1378f26",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#------------------------------------------------\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, pretrained=False, cfg=None):\n",
    "        super(Net, self).__init__()\n",
    "        self.output_type = ['infer', 'loss', ]\n",
    "        self.register_buffer('D', torch.tensor(0))\n",
    "\n",
    "        num_grade=3\n",
    "        num_level=5\n",
    "\n",
    "        self.arch = 'pvt_v2_b4'\n",
    "        if cfg is not None:\n",
    "            self.arch = cfg.arch\n",
    "\n",
    "        encoder_dim = {\n",
    "            'resnet18': [64, 64, 128, 256, 512, ],\n",
    "            'resnet18d': [64, 64, 128, 256, 512, ],\n",
    "            'resnet34': [64, 64, 128, 256, 512, ],\n",
    "            'resnet50d': [64, 256, 512, 1024, 2048, ],\n",
    "            'seresnext26d_32x4d': [64, 256, 512, 1024, 2048, ],\n",
    "            'convnext_small.fb_in22k': [96, 192, 384, 768],\n",
    "            'convnext_tiny.fb_in22k': [96, 192, 384, 768],\n",
    "            'convnext_base.fb_in22k': [128, 256, 512, 1024],\n",
    "            'tf_efficientnet_b4.ns_jft_in1k':[32, 56, 160, 448],\n",
    "            'tf_efficientnet_b5.ns_jft_in1k':[40, 64, 176, 512],\n",
    "            'pvt_v2_b1': [64, 128, 320, 512],\n",
    "            'pvt_v2_b2': [64, 128, 320, 512],\n",
    "            'pvt_v2_b4': [64, 128, 320, 512],\n",
    "        }.get(self.arch, [768])\n",
    "        decoder_dim = \\\n",
    "              [384, 192, 96]\n",
    "\n",
    "        self.encoder = timm.create_model(\n",
    "            model_name=self.arch, pretrained=pretrained, in_chans=3, num_classes=0, global_pool='', features_only=True,\n",
    "        )\n",
    "        self.decoder = MyUnetDecoder(\n",
    "            in_channel=encoder_dim[-1],\n",
    "            skip_channel=encoder_dim[:-1][::-1],\n",
    "            out_channel=decoder_dim,\n",
    "        )\n",
    "        self.z_mask = nn.Sequential(\n",
    "            nn.Linear(decoder_dim[-1],64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, num_level),\n",
    "        )\n",
    "        self.level_mask = nn.Sequential(\n",
    "            nn.Conv2d(decoder_dim[-1], 64, kernel_size=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Conv2d(64, num_level, kernel_size=1),\n",
    "        )\n",
    "        self.grade_mask = nn.Sequential(\n",
    "            nn.Conv2d(decoder_dim[-1], 64, kernel_size=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.SiLU(inplace=True),\n",
    "            nn.Conv2d(64, num_grade, kernel_size=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, batch):\n",
    "        device = self.D.device\n",
    "\n",
    "        image = batch['image'].to(device)\n",
    "        D = batch['D']\n",
    "        num_image = len(D)\n",
    "        B, H, W = image.shape\n",
    "        image = image.reshape(B, 1, H, W)\n",
    "\n",
    "        x = (image.float() / 255 - 0.5) / 0.5\n",
    "        x = x.expand(-1, 3, -1, -1)\n",
    "\n",
    "        encode = self.encoder(x)[-4:]\n",
    "        # [print(f'encode_{i}', e.shape) for i,e in enumerate(encode)]\n",
    "        last, decode = self.decoder(\n",
    "            feature=encode[-1], skip=encode[:-1][::-1]\n",
    "        )\n",
    "        z_pool = last.mean(dim=(2, 3))\n",
    "        z_mask = self.z_mask(z_pool)\n",
    "        z_mask = torch.cat([torch.softmax(z, 0) for z in torch.split_with_sizes(z_mask, D, 0)])\n",
    "        # print('z_logit', z_logit.shape)\n",
    "\n",
    "        # ---\n",
    "        xy_pool = []\n",
    "        for f, z in zip(\n",
    "                torch.split_with_sizes(last, D, 0),\n",
    "                torch.split_with_sizes(z_mask, D, 0)):\n",
    "            d = len(f)\n",
    "            z = z.mean(1).detach()\n",
    "            z = (z*torch.arange(d,device=device)).sum().item()\n",
    "            z = int(round(z))\n",
    "            zmin = max(0,z-3)  #crop 7 neighbour slices\n",
    "            zmax = min(d,z+3+1)\n",
    "            pool = f[zmin:zmax].mean(0)\n",
    "            xy_pool.append(pool)\n",
    "        xy_pool = torch.stack(xy_pool)\n",
    "\n",
    "\n",
    "        # pool level mask to xy ---\n",
    "        level_mask = self.level_mask(xy_pool)\n",
    "        num_image, _5_, h, w = level_mask.shape\n",
    "        level_mask = level_mask.reshape(num_image, 5, -1)\n",
    "        level_mask = F.softmax(level_mask, dim=-1)\n",
    "        level_mask = level_mask.reshape(num_image, 5, h, w )\n",
    "        xy = heatmap_to_coord(level_mask)\n",
    "\n",
    "        # pool grade mask to grade ---\n",
    "        grade_mask = self.grade_mask(xy_pool)\n",
    "        grade_mask = F.softmax(grade_mask, 1)\n",
    "        grade = heatmap_to_grade(grade_mask, level_mask)\n",
    "\n",
    "        output = {}\n",
    "        if 'loss' in self.output_type:\n",
    "            output['z_mask_loss'] = F_z_mask_loss(z_mask, batch['xyz'].to(device),D)\n",
    "            output['xy_loss'] = F.mse_loss(xy, batch['xyz'].to(device)[...,:2])\n",
    "            output['level_mask_loss'] = F_level_mask_loss(level_mask, batch['level_mask'].to(device))\n",
    "\n",
    "            output['grade_loss'] = F_grade_loss(grade,  batch['grade'].to(device))\n",
    "            if 1:\n",
    "                #pool grade mask to grade (truth)\n",
    "                xyz_truth = batch['xyz'].to(device).reshape(-1,3)\n",
    "                ii = torch.arange(num_image).to(device).reshape(num_image,1).repeat(1,5).reshape(-1)\n",
    "                h,w = grade_mask.shape[-2:]\n",
    "                for dx,dy in [\n",
    "                          (-1,0),\n",
    "                    (0,-1),(0,0),(0,1),\n",
    "                           (1,0),\n",
    "                ]:\n",
    "                    xx = torch.round(xyz_truth[:,0]+dx*0.5).long()\n",
    "                    yy = torch.round(xyz_truth[:,1]+dy*0.5).long()\n",
    "                    xx = torch.clamp(xx,0,w-1)\n",
    "                    yy = torch.clamp(yy,0,h-1)\n",
    "                    grade_from_truth = grade_mask[ii,:,yy,xx]\n",
    "                    weight = 0.500 if (dx==0)&(dy==0) else 0.125\n",
    "                    output['grade_loss'] += weight* F_grade_loss(grade_from_truth, batch['grade'].to(device))\n",
    "\n",
    "\n",
    "        if 'infer' in self.output_type:\n",
    "            output['level_mask'] = level_mask\n",
    "            output['grade'] = grade\n",
    "            output['z_mask'] = z_mask\n",
    "            output['xy'] = xy\n",
    "            output['z'] = torch.stack([z.argmax(0) for z in torch.split_with_sizes(z_mask, D, 0)])\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b3e2f1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    " #https://discuss.pytorch.org/t/jensen-shannon-divergence/2626/11\n",
    "\n",
    "def F_grade_loss(grade, truth):\n",
    "    eps = 1e-5\n",
    "    weight = torch.FloatTensor([1,2,4]).to(grade.device)\n",
    "    t = truth.reshape(-1)\n",
    "    g = grade.reshape(-1,3)\n",
    "    loss = F.nll_loss(torch.clamp(g, eps, 1-eps).log(), t,weight=weight, ignore_index=-1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb95b9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def F_level_mask_loss(level_mask, truth):\n",
    "    p,q = truth, level_mask\n",
    "    B,_5_,h,w = p.shape\n",
    "\n",
    "    eps = 1e-8\n",
    "    p = torch.clamp(p.transpose(1,0).reshape(-1,h*w),eps,1-eps)\n",
    "    q = torch.clamp(q.transpose(1,0).reshape(-1,h*w),eps,1-eps)\n",
    "    m = (0.5 * (p + q)).log()\n",
    "\n",
    "    kl = lambda x,t: F.kl_div(x,t, reduction='batchmean', log_target=True)\n",
    "    loss = 0.5 * (kl(m, p.log()) + kl(m, q.log()))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1007dc9d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def F_z_mask_loss(z_mask, truth, D):\n",
    "    eps = 1e-8\n",
    "    z_mask =  torch.split_with_sizes(z_mask, D, 0)\n",
    "    num_image = len(D)\n",
    "\n",
    "    loss = 0\n",
    "    for i in range(num_image):\n",
    "        g = z_mask[i].transpose(1,0)\n",
    "        t =  truth[i,:,2].long()\n",
    "        #loss += F.cross_entropy(g, t, ignore_index=-1,)# label_smoothing=0.1)\n",
    "        loss += F.nll_loss(torch.clamp(g, eps, 1 - eps).log(), t, ignore_index=-1)\n",
    "    loss = loss/num_image\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413508b7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "def run_check_net():\n",
    "\n",
    "    D = [7, 6, 9, 11, 10, 14, 15]\n",
    "    num_image  = len(D)\n",
    "    B = sum(D)\n",
    "\n",
    "    image_size = 320\n",
    "    mask_size  = 320//4\n",
    "    num_grade = 3\n",
    "    num_level = 5\n",
    "\n",
    "    batch = {\n",
    "        'D': D,\n",
    "        'image': torch.from_numpy(np.random.choice(256, (B, image_size, image_size))).byte(),\n",
    "        'level_mask': torch.from_numpy(np.random.choice(1, (num_image,  num_level, mask_size, mask_size))).float(),\n",
    "        'grade': torch.from_numpy(np.random.choice(3, (num_image, num_level))).long(),\n",
    "        'xyz': torch.from_numpy(np.random.choice(min(D), (num_image, num_level, 3))).float(),\n",
    "    }\n",
    "\n",
    "    net = Net(pretrained=True, cfg=None).cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            output = net(batch)\n",
    "    # ---\n",
    "    print('batch')\n",
    "    for k, v in batch.items():\n",
    "        if k == 'D':\n",
    "            print(f'{k:>32} : {v} ')\n",
    "        else:\n",
    "            print(f'{k:>32} : {v.shape} ')\n",
    "\n",
    "    print('output')\n",
    "    for k, v in output.items():\n",
    "        if 'loss' not in k:\n",
    "            print(f'{k:>32} : {v.shape} ')\n",
    "    print('loss')\n",
    "    for k, v in output.items():\n",
    "        if 'loss' in k:\n",
    "            print(f'{k:>32} : {v.item()} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c77ba96",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# main #################################################################\n",
    "if __name__ == '__main__':\n",
    "    run_check_net()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
