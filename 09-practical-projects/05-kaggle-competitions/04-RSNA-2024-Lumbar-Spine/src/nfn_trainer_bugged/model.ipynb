{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37213b14",
   "metadata": {},
   "source": [
    "# src - model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f10b929",
   "metadata": {},
   "source": [
    "## Notebook运行提示\n",
    "- 代码已拆分为多个小单元, 按顺序运行即可在每一步观察输出与中间变量。\n",
    "- 涉及 `Path(__file__)` 或相对路径的脚本会自动注入 `__file__` 解析逻辑, Notebook 环境下也能引用原项目资源。\n",
    "- 可在每个单元下追加说明或参数试验记录, 以跟踪核心算法和数据处理步骤。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080a01ba",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import timm\n",
    "print('timm:',timm.__version__)\n",
    "\n",
    "#------------------------------------------------\n",
    "from decoder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449696cc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def pvtv2_encode(x, e):\n",
    "    encode = []\n",
    "    x = e.patch_embed(x)\n",
    "    for stage in e.stages:\n",
    "        x = stage(x); encode.append(x)\n",
    "    return encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aa7331",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#------------------------------------------------\n",
    "#dsnt\n",
    "#https://github.com/kornia/kornia/blob/93114bf3f499eaac7c5f0f25f3e53ec356b191e2/kornia/geometry/subpix/dsnt.py\n",
    "\n",
    "def heatmap_to_coord(heatmap):\n",
    "    num_image = len(heatmap)\n",
    "    device = heatmap[0].device\n",
    "    _,_, H, W = heatmap[0].shape\n",
    "    D = max([h.shape[1] for h in heatmap])\n",
    "\n",
    "    # create coordinates grid.\n",
    "    x = torch.linspace(0, W - 1, W, device=device)\n",
    "    y = torch.linspace(0, H - 1, H, device=device)\n",
    "    z = torch.linspace(0, D - 1, D, device=device)\n",
    "\n",
    "    point_xy=[]\n",
    "    point_z =[]\n",
    "    for i in range(num_image):\n",
    "        num_point, D, H, W = heatmap[i].shape\n",
    "        pos_x = x.reshape(1,1,1,W)\n",
    "        pos_y = y.reshape(1,1,H,1)\n",
    "        pos_z = z[:D].reshape(1,D,1,1)\n",
    "\n",
    "        py = torch.sum(pos_y * heatmap[i], dim=(1,2,3))\n",
    "        px = torch.sum(pos_x * heatmap[i], dim=(1,2,3))\n",
    "        pz = torch.sum(pos_z * heatmap[i], dim=(1,2,3))\n",
    "\n",
    "        point_xy.append(torch.stack([px,py]).T)\n",
    "        point_z.append(pz)\n",
    "\n",
    "    xy = torch.stack(point_xy)\n",
    "    z = torch.stack(point_z)\n",
    "    return xy, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3bd7d0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def heatmap_to_grade(heatmap, grade_mask):\n",
    "    num_image = len(heatmap)\n",
    "    grade = []\n",
    "    for i in range(num_image):\n",
    "        num_point, D, H, W = heatmap[i].shape\n",
    "        C, D, H, W = grade_mask[i].shape\n",
    "        g = grade_mask[i].reshape(1,C,D,H,W)#.detach()\n",
    "        h = heatmap[i].reshape(num_point,1,D,H,W)#.detach()\n",
    "        g = (h*g).sum(dim=(2,3,4))\n",
    "        grade.append(g)\n",
    "    grade = torch.stack(grade)\n",
    "    return grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786d1f60",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# ----dynamic matching ---\n",
    "def do_dynmaic_match_truth(xy, truth_xy, threshold=3):\n",
    "    num_image, num_point, _2_ = xy.shape\n",
    "    t = truth_xy[:, :5, 1].reshape(num_image, 5, 1)\n",
    "    p = xy[:, :5, 1].reshape(num_image, 1, 5)\n",
    "    diff = torch.abs(p - t)\n",
    "    left, left_i = diff.min(-1)\n",
    "    left_t = (left < threshold)\n",
    "\n",
    "    # closest_i = left_i.tolist()\n",
    "    # for j in range(num_image):\n",
    "    #     if closest_i[j] !=[0,1,2,3,4]: print('left',closest_i[j], valid[j])\n",
    "\n",
    "    t = truth_xy[:, 5:, 1].reshape(num_image, 5, 1)\n",
    "    p = xy[:, 5:, 1].reshape(num_image, 1, 5)\n",
    "    diff = torch.abs(p - t)\n",
    "    right, right_i = diff.min(-1)\n",
    "    right_t = (right < threshold)\n",
    "\n",
    "    # closest_i = right_i.tolist()\n",
    "    # for j in range(num_image):\n",
    "    #     if closest_i[j] !=[0,1,2,3,4]: print('right',closest_i[j], valid[j])\n",
    "\n",
    "    index = torch.cat([left_i, right_i + 5], 1).detach()\n",
    "    valid = torch.cat([left_t, right_t], 1).detach()\n",
    "    return index, valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a056b48",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, pretrained=False, cfg=None):\n",
    "        super(Net, self).__init__()\n",
    "        self.output_type = ['infer', 'loss']\n",
    "        self.register_buffer('D', torch.tensor(0))\n",
    "\n",
    "        num_grade=3\n",
    "        num_level=5\n",
    "\n",
    "        self.arch = 'pvt_v2_b4'\n",
    "        if cfg is not None:\n",
    "            self.arch = cfg.arch\n",
    "\n",
    "        encoder_dim = {\n",
    "            'resnet18': [64, 64, 128, 256, 512, ],\n",
    "            'resnet18d': [64, 64, 128, 256, 512, ],\n",
    "            'resnet34': [ 64, 128, 256, 512, ],\n",
    "            'resnet50d': [256, 512, 1024, 2048, ],\n",
    "            'seresnext26d_32x4d': [256, 512, 1024, 2048,],\n",
    "            'convnext_small.fb_in22k': [96, 192, 384, 768],\n",
    "            'convnext_tiny.fb_in22k': [96, 192, 384, 768],\n",
    "            'convnext_base.fb_in22k': [96, 192, 384, 768],\n",
    "            'tf_efficientnet_b4.ns_jft_in1k':[32, 56, 160, 448],\n",
    "            'tf_efficientnet_b5.ns_jft_in1k':[40, 64, 176, 512],\n",
    "            'pvt_v2_b1': [64, 128, 320, 512],\n",
    "            'pvt_v2_b2': [64, 128, 320, 512],\n",
    "            'pvt_v2_b3': [64, 128, 320, 512],\n",
    "            'pvt_v2_b4': [64, 128, 320, 512],\n",
    "        }.get( self.arch,None)\n",
    "\n",
    "        decoder_dim =  [384, 192, 96]\n",
    "\n",
    "        if  self.arch == 'pvt_v2_b4':\n",
    "            #legacy code\n",
    "            self.encoder = timm.create_model(\n",
    "                model_name=self.arch, pretrained=pretrained, in_chans=3, num_classes=0, global_pool=''\n",
    "            )\n",
    "        else:\n",
    "            self.encoder = timm.create_model(\n",
    "                model_name=self.arch, pretrained=pretrained, in_chans=3, num_classes=0, global_pool='', features_only=True\n",
    "            )\n",
    "\n",
    "        self.decoder = MyUnetDecoder3d(\n",
    "            in_channel=encoder_dim[-1],\n",
    "            skip_channel=encoder_dim[:-1][::-1],\n",
    "            out_channel=decoder_dim,\n",
    "        )\n",
    "\n",
    "        self.zxy_mask = nn.Conv3d(decoder_dim[-1], 10, kernel_size=1)\n",
    "        self.grade_mask = nn.Conv3d(decoder_dim[-1], 128, kernel_size=1)\n",
    "        self.grade = nn.Sequential(\n",
    "            nn.Linear(128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 3),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, batch):\n",
    "        device = self.D.device\n",
    "        image = batch['image'].to(device)\n",
    "        D = batch['D']\n",
    "        num_image = len(D)\n",
    "\n",
    "        B, H, W = image.shape\n",
    "        image = image.reshape(B, 1, H, W)\n",
    "\n",
    "        x = (image.float() / 255 - 0.5) / 0.5\n",
    "        x = x.expand(-1, 3, -1, -1)\n",
    "\n",
    "        #---\n",
    "        if self.arch == 'pvt_v2_b4':\n",
    "            #legacy code\n",
    "            encode = pvtv2_encode(x, self.encoder)\n",
    "        else:\n",
    "            encode = self.encoder(x)[-4:]\n",
    "\n",
    "        ##[print(f'encode_{i}', e.shape) for i,e in enumerate(encode)]\n",
    "        encode = [ torch.split_with_sizes(e, D, 0) for e in encode ]\n",
    "\n",
    "        zxy_mask_logit = []\n",
    "        zxy_mask_prob  = []\n",
    "        grade_mask_logit = []\n",
    "        for i in range(num_image):\n",
    "            e = [ encode[s][i].transpose(1,0).unsqueeze(0) for s in range(4) ]\n",
    "            l, d = self.decoder(\n",
    "                feature=e[-1], skip=e[:-1][::-1]\n",
    "            )\n",
    "\n",
    "            g = self.grade_mask(l).squeeze(0)\n",
    "            zxy = self.zxy_mask(l).squeeze(0)\n",
    "            grade_mask_logit.append(g)\n",
    "            zxy_mask_logit.append(zxy)\n",
    "\n",
    "            _,d,h,w = zxy.shape\n",
    "            zxy_p = zxy.flatten(1).softmax(-1).reshape(-1,d,h,w)\n",
    "            zxy_mask_prob.append(zxy_p)\n",
    "\n",
    "        xy, z = heatmap_to_coord(zxy_mask_prob)\n",
    "        #---\n",
    "        num_point = xy.shape[1]\n",
    "        grade = heatmap_to_grade(zxy_mask_prob, grade_mask_logit)\n",
    "        grade = grade.reshape(num_image*num_point,-1)\n",
    "        grade = self.grade(grade)\n",
    "        grade = grade.reshape(num_image,num_point,3)\n",
    "\n",
    "        #---\n",
    "        zxy_mask = torch.cat(zxy_mask_prob, 1).transpose(1, 0)\n",
    "\n",
    "\n",
    "        output = {}\n",
    "        if 'loss' in self.output_type:\n",
    "            output['zxy_loss'] = F_zxy_loss(z, xy, batch['z'].to(device), batch['xy'].to(device))\n",
    "            output['zxy_mask_loss'] = F_divergence_loss(zxy_mask, batch['zxy_mask'].to(device), D)\n",
    "\n",
    "            #output['grade_loss'] = F_grade_loss(grade,  batch['grade'].to(device))\n",
    "            if 1:\n",
    "                index, valid = do_dynmaic_match_truth(xy, batch['xy'].to(device))\n",
    "                truth = batch['grade'].to(device)\n",
    "                truth_matched = []\n",
    "                for i in range(num_image):\n",
    "                    truth_matched.append(truth[i][index[i]])\n",
    "                truth_matched = torch.stack(truth_matched)\n",
    "                output['grade_loss'] = F_grade_loss(grade[valid],  truth_matched[valid])\n",
    "\n",
    "        if 'infer' in self.output_type:\n",
    "            output['grade'] = F.softmax(grade,-1)\n",
    "            output['zxy_mask'] = zxy_mask\n",
    "            output['xy'] = xy\n",
    "            output['z'] = z\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42526911",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#--------------------------------------------------------------------------\n",
    "def F_zxy_loss(z, xy,  z_truth, xy_truth):\n",
    "    m = z_truth!=-1\n",
    "    z_truth = z_truth.float()\n",
    "    loss = (\n",
    "        F.mse_loss(z[m], z_truth[m]) + F.mse_loss(xy[m], xy_truth[m])\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246b79fe",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def F_grade_loss(grade, truth):\n",
    "    eps = 1e-5\n",
    "    weight = torch.FloatTensor([1,2,4]).to(grade.device)\n",
    "    t = truth.reshape(-1)\n",
    "    g = grade.reshape(-1,3)\n",
    "    #loss = F.nll_loss( torch.clamp(g, eps, 1-eps).log(), t,weight=weight, ignore_index=-1)\n",
    "    loss = F.cross_entropy(g, t,weight=weight, ignore_index=-1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2076a9fa",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#https://discuss.pytorch.org/t/jensen-shannon-divergence/2626/11\n",
    "#Jensen-Shannon divergence\n",
    "def F_divergence_loss(heatmap, truth, D):\n",
    "    heatmap =  torch.split_with_sizes(heatmap, D, 0)\n",
    "    truth =  torch.split_with_sizes(truth, D, 0)\n",
    "    num_image = len(heatmap)\n",
    "\n",
    "    loss =0\n",
    "    for i in range(num_image):\n",
    "        p,q = truth[i], heatmap[i]\n",
    "        D,num_point,H,W = p.shape\n",
    "\n",
    "        eps = 1e-8\n",
    "        p = torch.clamp(p.transpose(1,0).flatten(1),eps,1-eps)\n",
    "        q = torch.clamp(q.transpose(1,0).flatten(1),eps,1-eps)\n",
    "        m = (0.5 * (p + q)).log()\n",
    "\n",
    "        kl = lambda x,t: F.kl_div(x,t, reduction='batchmean', log_target=True)\n",
    "        loss += 0.5 * (kl(m, p.log()) + kl(m, q.log()))\n",
    "    loss = loss/num_image\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10089ee9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###################################################################################################################\n",
    "def run_check_net():\n",
    "    D = [6, 7, 9, 11, 3, 4, 5]\n",
    "    image_size = 320\n",
    "    mask_size  = image_size//4\n",
    "    num_image  = len(D)\n",
    "    B = sum(D)\n",
    "    num_point = 10\n",
    "\n",
    "    batch = {\n",
    "        'D': D,\n",
    "        'image': torch.from_numpy( np.random.uniform(-1, 1, ( B, image_size, image_size))).byte(),\n",
    "        'z': torch.from_numpy(np.random.choice(min(D), (num_image, num_point))).long(),\n",
    "        'xy': torch.from_numpy(np.random.choice(image_size, (num_image, num_point, 2))).float(),\n",
    "        'grade': torch.from_numpy(np.random.choice(3, (num_image, num_point))).long(),\n",
    "        'zxy_mask': torch.from_numpy(np.random.uniform(0,1,(B, num_point, mask_size, mask_size))).float(),\n",
    "    }\n",
    "\n",
    "    net = Net(pretrained=True, cfg=None).cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with torch.cuda.amp.autocast(enabled=True):\n",
    "            output = net(batch)\n",
    "    # ---\n",
    "    print('batch')\n",
    "    for k, v in batch.items():\n",
    "        if k == 'D':\n",
    "            print(f'{k:>32} : {v} ')\n",
    "        else:\n",
    "            print(f'{k:>32} : {v.shape} ')\n",
    "\n",
    "    print('output')\n",
    "    for k, v in output.items():\n",
    "        if 'loss' not in k:\n",
    "            print(f'{k:>32} : {v.shape} ')\n",
    "    print('loss')\n",
    "    for k, v in output.items():\n",
    "        if 'loss' in k:\n",
    "            print(f'{k:>32} : {v.item()} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a84d906",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# main #################################################################\n",
    "if __name__ == '__main__':\n",
    "    run_check_net()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
