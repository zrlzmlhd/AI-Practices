{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71416d18",
   "metadata": {},
   "source": [
    "# src - dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c4194e",
   "metadata": {},
   "source": [
    "## Notebook运行提示\n",
    "- 代码已拆分为多个小单元, 按顺序运行即可在每一步观察输出与中间变量。\n",
    "- 涉及 `Path(__file__)` 或相对路径的脚本会自动注入 `__file__` 解析逻辑, Notebook 环境下也能引用原项目资源。\n",
    "- 可在每个单元下追加说明或参数试验记录, 以跟踪核心算法和数据处理步骤。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6c4099",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../data_process')\n",
    "from common import *\n",
    "from _dir_setting_ import *\n",
    "from data import *\n",
    "from configure import *\n",
    "\n",
    "import torch\n",
    "from functools import *\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from augmentation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213c3374",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_csv():\n",
    "    csv_file = f'{DATA_PROCESSED_DIR}/nfn_sag_t1_processed_df.csv'\n",
    "    processed_df = pd.read_csv(csv_file)\n",
    "    processed_df = do_clean_by_eval_df(processed_df, col=['grade','instance_number','z','xy'])\n",
    "    return processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2be5129",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# ---\n",
    "def make_zxy_mask(xy, z, sigma=1, mask_shape=(5,80,80)):\n",
    "    D,H,W = mask_shape\n",
    "    num_point = len(xy)\n",
    "\n",
    "    if sigma==0:\n",
    "        mask = np.zeros( (num_point,D,H,W), dtype=np.float32)\n",
    "        for i in range(num_point):\n",
    "            x,y = xy[i]\n",
    "            x = int(round(x))\n",
    "            y = int(round(y))\n",
    "            if z[i]!=-1:\n",
    "                mask[i,z[i],y,x] = 1\n",
    "    else:\n",
    "\n",
    "        mask = np.zeros( (num_point,D,H,W), dtype=np.float32)\n",
    "        for i in range(num_point):\n",
    "            # Create coordinates grid.\n",
    "            pos_x = np.linspace(0,W-1,W).reshape(1,1,W)\n",
    "            pos_y = np.linspace(0,H-1,H).reshape(1,H,1)\n",
    "            pos_z = np.linspace(0,D-1,D).reshape(D,1,1)\n",
    "\n",
    "            # Gaussian PDF = exp(-(x - \\mu)^2 / (2 \\sigma^2))\n",
    "            #              = exp(dists * ks),\n",
    "            #                where dists = (x - \\mu)^2 and ks = -1 / (2 \\sigma^2)\n",
    "\n",
    "            dist_x = (pos_x - xy[i,0]) ** 2\n",
    "            dist_y = (pos_y - xy[i,1]) ** 2\n",
    "            dist_z = (pos_z - z[i]) ** 2\n",
    "            k_x = -0.5 * 1/(sigma*sigma)\n",
    "            k_y = -0.5 * 1/(sigma*sigma)\n",
    "            k_z = -0.5 * 1/(1*1)\n",
    "\n",
    "            gauss =  np.exp(dist_x * k_x) * np.exp(dist_y * k_y)* np.exp(dist_z * k_z)\n",
    "            gauss_sum = gauss.sum((0,1,2), keepdims=True)\n",
    "            gauss = np.clip(gauss/gauss_sum, a_min=1e-32, a_max=np.inf)\n",
    "            mask[i]= gauss\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d7862e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "######################################################################3\n",
    "\n",
    "def make_valid_augment(cfg):\n",
    "    transform = A.Compose([\n",
    "            A.LongestMaxSize(max_size=cfg.image_size, interpolation=1),\n",
    "            A.PadIfNeeded(min_height=cfg.image_size, min_width=cfg.image_size, border_mode=0, value=(0, 0, 0)),\n",
    "        ],\n",
    "        keypoint_params=A.KeypointParams(format='xy',),\n",
    "        p=1.)\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2536c4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#https://github.com/albumentations-team/albumentations/issues/718\n",
    "def make_train_augment(cfg):\n",
    "\n",
    "    transform = A.Compose([\n",
    "            A.LongestMaxSize(max_size=cfg.image_size, interpolation=1),\n",
    "            A.PadIfNeeded(min_height=cfg.image_size, min_width=cfg.image_size, border_mode=0, value=(0, 0, 0)),\n",
    "\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=(-0.2, 0.2),\n",
    "                contrast_limit=(-0.2, 0.2),\n",
    "                p=0.75\n",
    "            ),\n",
    "\n",
    "            A.OneOf([\n",
    "                    A.MotionBlur(blur_limit=5),\n",
    "                    A.MedianBlur(blur_limit=5),\n",
    "                    A.GaussianBlur(blur_limit=5),\n",
    "                    A.GaussNoise(var_limit=(10.0, 50.0)),\n",
    "            ], p=0.5),\n",
    "        ],\n",
    "        keypoint_params=A.KeypointParams(format='xy',remove_invisible=False),\n",
    "        p=1.)\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443ca20f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#---------------------------------\n",
    "def make_random_split( fold=1, num_fold=5):\n",
    "\n",
    "    all_df = pd.read_csv(f'{DATA_KAGGLE_DIR}/train.csv')\n",
    "    all_id = sorted(all_df.study_id.values.tolist())\n",
    "    all_id = np.array(all_id)\n",
    "\n",
    "    rng   = np.random.RandomState(42)\n",
    "    choice = rng.choice(num_fold, len(all_id))\n",
    "    train_id = all_id[np.where(choice!=fold)[0]]\n",
    "    valid_id = all_id[np.where(choice==fold)[0]]\n",
    "    train_id = np.sort(train_id)\n",
    "    valid_id = np.sort(valid_id)\n",
    "    return train_id, valid_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17ca00d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class SplineDataset(Dataset):\n",
    "    def __init__(self, processed_df, sample_id, cfg, augment=make_valid_augment, mode='train'):\n",
    "\n",
    "        self.mode = mode\n",
    "        self.cfg = cfg\n",
    "        self.df = processed_df[processed_df.study_id.isin(sample_id)].reset_index(drop=True)\n",
    "        self.sample_id = sample_id\n",
    "        self.augment = augment(cfg)\n",
    "        self.length = len(self.df)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __str__(self):\n",
    "        text = ''\n",
    "        text += f'\\tlen = {len(self)}\\n'\n",
    "        text += f'\\t\\tnum_study_id : {len(self.df.study_id.unique())}\\n'\n",
    "        text += f'\\t\\tnum_series_id : {len(self.df.series_id.unique())}\\n'\n",
    "        text += f'\\t\\tnum_points: {len(self.df.series_id.unique())*10}\\n'\n",
    "\n",
    "        if 1:\n",
    "            gradename = [\n",
    "                'normal/mild', 'moderate', 'severe'\n",
    "            ]\n",
    "            weight = [1, 2, 4]\n",
    "\n",
    "            grade = np.array(self.df.grade.tolist())\n",
    "            count = [(grade == i).sum() for i in [0, 1, 2]]\n",
    "            L = len(grade)\n",
    "            wL = sum(weight[i] * count[i] for i in [0, 1, 2])\n",
    "            for i in [0, 1, 2]:\n",
    "                text += f'\\t\\t{i} {gradename[i]:>16}: {count[i]:5d} {count[i] / L:0.3f}  ({weight[i] * count[i] / wL:0.3f})\\n'\n",
    "        return text\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        d = self.df.iloc[index]\n",
    "        volume = np.load(f'{DATA_PROCESSED_DIR}/mini-clean5.0/{d.study_id}/{d.series_id}/volume.npz')['volume']\n",
    "        image = np.ascontiguousarray(volume.transpose(1,2,0))\n",
    "\n",
    "        grade = np.array(d.grade, dtype=np.int32)\n",
    "        z = np.array(d.z, dtype=np.int32)\n",
    "\n",
    "        point = np.array(d.xy)\n",
    "        image, point = do_resize_and_center(image, point, reference_size=512)\n",
    "\n",
    "        # start of uagmentation -------------------------------------------------------\n",
    "        if self.mode == 'train':\n",
    "            if np.random.rand() < 0.5: #flip\n",
    "                z = np.array([s if s ==-1 else image.shape[-1] - 1 - s for s in z], dtype=np.int32)\n",
    "                image = np.ascontiguousarray(image[..., ::-1])\n",
    "                # BUGGED !!!! point order needs to be reordered.\n",
    "\n",
    "                # correction:\n",
    "                # point = point[[5,6,7,8,9,0,1,2,3,4]]\n",
    "                # grade = grade[[5,6,7,8,9,0,1,2,3,4]]\n",
    "                # z = z[[5,6,7,8,9,0,1,2,3,4]]\n",
    "\n",
    "            u = np.random.choice([0,1,2,],p=[0.1,0.7,0.2])\n",
    "            if u==1:\n",
    "                mean_512_shape = np.load(f'{DATA_PROCESSED_DIR}/nfn_sag_t1_mean_shape.512.npy')\n",
    "                mean_512_shape = mean_512_shape[:10].astype(np.float32)\n",
    "\n",
    "                mat = get_rotate_scale_by_reference_mat(\n",
    "                    point, (512,512), mean_512_shape,\n",
    "                    scale_limit=(-0.25, 0.35),\n",
    "                    rotate_limit=(-20, 20),\n",
    "                    shift_limit=(10, 10),\n",
    "                    border=5\n",
    "                )\n",
    "                image, point = apply_affine( image, point, mat )\n",
    "\n",
    "            if u==2:\n",
    "                mat = get_safe_custom_mat(\n",
    "                    point, (512,512),\n",
    "                    affline_limit = (-0.25,0.25),\n",
    "                    border=5\n",
    "                )\n",
    "                image, point = apply_perspective( image, point, mat )\n",
    "\n",
    "            #-------\n",
    "            if np.random.random() < 0.5:\n",
    "                image = do_random_cutout(image, point)\n",
    "\n",
    "        if self.mode=='train':\n",
    "            r = self.augment(image=image.copy(), keypoints=point)\n",
    "\n",
    "        if self.mode=='valid':\n",
    "            r = self.augment(image=image.copy(), keypoints=point)\n",
    "\n",
    "        point = r['keypoints']\n",
    "        image = r['image']\n",
    "        image = np.ascontiguousarray(image.transpose(2,0,1))\n",
    "\n",
    "        # end of uagmentation -------------------------------------------------------\n",
    "\n",
    "\n",
    "        #make attention mask for supervision\n",
    "        _,h,w = image.shape\n",
    "        xy = np.array(point)*[[self.cfg.mask_size/w, self.cfg.mask_size/h ]]\n",
    "        mask_shape = [len(image),self.cfg.mask_size, self.cfg.mask_size]\n",
    "        zxy_mask   = make_zxy_mask(xy, z, sigma=self.cfg.point_sigma, mask_shape=mask_shape)\n",
    "\n",
    "        r = {}\n",
    "        r['index'] = index\n",
    "        r['d'] = d\n",
    "        r['D'] = len(image)\n",
    "        r['image'  ] = torch.from_numpy(image)\n",
    "        r['zxy_mask'] = torch.from_numpy(zxy_mask.transpose(1,0,2,3))\n",
    "        r['z' ] = torch.from_numpy(z)\n",
    "        r['xy'] = torch.from_numpy(xy)\n",
    "        r['grade'] = torch.from_numpy(grade)\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d40968",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tensor_key = ['image','zxy_mask','z','xy', 'grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028f5e96",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def null_collate(batch):\n",
    "    d = {}\n",
    "    key = batch[0].keys()\n",
    "    for k in key:\n",
    "        d[k] = [b[k] for b in batch]\n",
    "\n",
    "    d['image'] = torch.cat(d['image']).byte()\n",
    "    d['zxy_mask'] = torch.cat(d['zxy_mask']).float()\n",
    "    d['z'] = torch.stack(d['z']).long()\n",
    "    d['xy'] = torch.stack(d['xy']).float()\n",
    "    d['grade'] = torch.stack(d['grade']).long()\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f23e852",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##########################################################################################3\n",
    "\n",
    "def run_check_dataset():\n",
    "    from configure import default_cfg as cfg\n",
    "\n",
    "    processed_df = load_csv()\n",
    "    train_id, valid_id = make_random_split()\n",
    "    #dataset = SplineDataset(processed_df, train_id, cfg=default_cfg, augment=make_valid_augment, mode='valid')\n",
    "    dataset = SplineDataset(processed_df, train_id, cfg=default_cfg, augment=make_train_augment, mode='train')\n",
    "    print(dataset)\n",
    "\n",
    "    for i in range(10):\n",
    "        r = dataset[i]\n",
    "\n",
    "        print(r['index'], '--------------------')\n",
    "        for k in tensor_key:\n",
    "            v = r[k]\n",
    "            print(k)\n",
    "            print('\\t', 'dtype:', v.dtype)\n",
    "            print('\\t', 'shape:', v.shape)\n",
    "            if len(v) != 0:\n",
    "                print('\\t', 'min/max:', v.min().item(), '/', v.max().item())\n",
    "                print('\\t', 'sum:', v.sum().item())\n",
    "                print('\\t', 'is_contiguous:', v.is_contiguous())\n",
    "                print('\\t', 'values:')\n",
    "                print('\\t\\t', v.reshape(-1)[:3].data.numpy().tolist(), '...', v.reshape(-1)[-3:].data.numpy().tolist())\n",
    "        print('')\n",
    "\n",
    "\n",
    "        if 1:\n",
    "            # draw\n",
    "            print(r['d'])\n",
    "\n",
    "            image = r['image'].data.cpu().numpy()\n",
    "            zxy_mask  = r['zxy_mask'].float().data.cpu().numpy()\n",
    "\n",
    "            image = image.mean(0)\n",
    "            image = cv2.cvtColor(image.astype(np.uint8), cv2.COLOR_GRAY2BGR)\n",
    "            xy_mask = zxy_mask.sum((0,1)).astype(np.float32)\n",
    "            xy_mask = cv2.resize(xy_mask, (cfg.image_size,cfg.image_size))\n",
    "            xy_mask = xy_mask/xy_mask.max()\n",
    "            image[...,2] =255-(1-xy_mask)*(255-image[...,2])\n",
    "\n",
    "            image_show_norm('image', image)#, type='rgb')\n",
    "            image_show_norm('xy_mask',xy_mask,resize=1)\n",
    "            cv2.waitKey(0)\n",
    "\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        sampler=SequentialSampler(dataset),\n",
    "        batch_size=7,\n",
    "        drop_last=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=False,\n",
    "        worker_init_fn=lambda id: np.random.seed(torch.initial_seed() // 2 ** 32 + id),\n",
    "        collate_fn=null_collate,\n",
    "    )\n",
    "    print(f'batch_size   : {loader.batch_size}')\n",
    "    print(f'len(loader)  : {len(loader)}')\n",
    "    print(f'len(dataset) : {len(dataset)}')\n",
    "    print('')\n",
    "\n",
    "    for t, batch in enumerate(loader):\n",
    "        if t > 5: break\n",
    "        print('batch ', t, '===================')\n",
    "        print('index', batch['index'])\n",
    "        print('D', batch['D'])\n",
    "\n",
    "        for k in tensor_key:\n",
    "            v = batch[k]\n",
    "            print(k)\n",
    "            print('\\t', v.data.shape)\n",
    "            print('\\t', 'is_contiguous:', v.is_contiguous())\n",
    "\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e968f2e2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# main #################################################################\n",
    "if __name__ == '__main__':\n",
    "    run_check_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
