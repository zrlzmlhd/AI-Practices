{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1747aece",
   "metadata": {},
   "source": [
    "# 02-Feedback-ELL-1st-Place - inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc779361",
   "metadata": {},
   "source": [
    "## Notebook运行提示\n",
    "- 代码已拆分为多个小单元, 按顺序运行即可在每一步观察输出与中间变量。\n",
    "- 涉及 `Path(__file__)` 或相对路径的脚本会自动注入 `__file__` 解析逻辑, Notebook 环境下也能引用原项目资源。\n",
    "- 可在每个单元下追加说明或参数试验记录, 以跟踪核心算法和数据处理步骤。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c50b79",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from dataset.datasets import get_test_dataloader\n",
    "from data.preprocessing import get_max_len_from_df, make_folds, preprocess_text\n",
    "from utils import get_config, load_filepaths\n",
    "from models.utils import get_model\n",
    "from dataset.collators import collate\n",
    "from utils import dictionary_to_namespace\n",
    "\n",
    "import argparse\n",
    "from utils import str_to_bool\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185c8669",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model_dir_path', type=str)\n",
    "    parser.add_argument('--mode', type=str)\n",
    "    parser.add_argument('--debug', type=str_to_bool, default=False)\n",
    "    arguments = parser.parse_args()\n",
    "    return arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0bf251",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3c6253",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def inference_fn(test_loader, model, device):\n",
    "    preds = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(test_loader, total=len(test_loader))\n",
    "    for inputs in tk0:\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        preds.append(y_preds.to('cpu').numpy())\n",
    "    predictions = np.concatenate(preds)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7542f9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    args = parse_args()\n",
    "\n",
    "    model_id = args.model_dir_path.split(\"/\")[-1]\n",
    "    filepaths = load_filepaths()\n",
    "\n",
    "    config_path = os.path.join(filepaths['CONFIGS_DIR_PATH'], f'{model_id}_training_config.yaml')\n",
    "    config = get_config(config_path)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(os.path.join(args.model_dir_path, 'tokenizer/'))\n",
    "\n",
    "    config = dictionary_to_namespace(config)\n",
    "    config.tokenizer = tokenizer\n",
    "    config.model.pretrained_backbone = False\n",
    "\n",
    "    assert args.mode in ['prev_pseudolabels', 'curr_pseudolabels', 'submission', 'oofs']\n",
    "\n",
    "    seed_everything(seed=config.general.seed)\n",
    "\n",
    "    dataframe_path = None\n",
    "    if args.mode == 'submission':\n",
    "        dataframe_path = filepaths['TEST_CSV_PATH']\n",
    "    elif args.mode == 'oofs':\n",
    "        dataframe_path = filepaths['TRAIN_CSV_PATH']\n",
    "    elif args.mode == 'prev_pseudolabels':\n",
    "        dataframe_path = filepaths['PREVIOUS_DATA_CSV_PATH']\n",
    "    elif args.mode == 'curr_pseudolabels':\n",
    "        dataframe_path = filepaths['TRAIN_CSV_PATH']\n",
    "\n",
    "    test_df = pd.read_csv(dataframe_path)\n",
    "\n",
    "    if args.mode == 'oofs':\n",
    "        test_df = make_folds(test_df,\n",
    "                             target_cols=config.general.target_columns,\n",
    "                             n_splits=config.general.n_folds,\n",
    "                             random_state=config.general.seed)\n",
    "\n",
    "    elif args.mode == 'prev_pseudolabels':\n",
    "        df = pd.read_csv(filepaths['TRAIN_CSV_PATH'])\n",
    "        test_df['in_fb3'] = test_df['text_id'].apply(lambda x: x in df.text_id.values)\n",
    "        test_df = test_df[~test_df['in_fb3'].values]\n",
    "\n",
    "    if args.debug:\n",
    "        test_df = test_df.sample(50, random_state=42)\n",
    "\n",
    "    test_df['full_text'] = test_df['full_text'].apply(preprocess_text)\n",
    "\n",
    "    test_df['tokenize_length'] = [len(config.tokenizer(text)['input_ids']) for text in test_df['full_text'].values]\n",
    "    test_df = test_df.sort_values('tokenize_length', ascending=True).reset_index(drop=True)\n",
    "\n",
    "    if config.general.set_max_length_from_data:\n",
    "        config.general.max_length = get_max_len_from_df(test_df, config.tokenizer)\n",
    "\n",
    "    if args.debug:\n",
    "        test_df = test_df.sample(50, random_state=1)\n",
    "\n",
    "    target_columns = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n",
    "\n",
    "    predictions = []\n",
    "    oofs_list = []\n",
    "    for fold in range(config.general.n_folds):\n",
    "\n",
    "        subset = test_df.copy()\n",
    "        if args.mode == 'oofs':\n",
    "            subset = subset[subset['fold'] == fold].reset_index(drop=True)\n",
    "\n",
    "        test_dataloader = get_test_dataloader(config, subset)\n",
    "\n",
    "        backbone_type = config.model.backbone_type.replace('/', '-')\n",
    "        model_checkpoint_path = os.path.join(args.model_dir_path, f\"{backbone_type}_fold{fold}_best.pth\")\n",
    "        backbone_config_path = os.path.join(args.model_dir_path, 'config.pth')\n",
    "\n",
    "        model = get_model(config,\n",
    "                          backbone_config_path=backbone_config_path,\n",
    "                          model_checkpoint_path=model_checkpoint_path,\n",
    "                          train=False)\n",
    "\n",
    "        prediction = inference_fn(test_dataloader, model, device)\n",
    "        predictions.append(prediction)\n",
    "\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        if args.mode in ['prev_pseudolabels', 'curr_pseudolabels', 'oofs']:\n",
    "            out = pd.DataFrame(prediction, columns=['cohesion', 'syntax', 'vocabulary',\n",
    "                                                    'phraseology', 'grammar', 'conventions'])\n",
    "\n",
    "            for col in ['text_id', 'full_text', 'tokenize_length', 'in_fb3']:\n",
    "                if col in subset.columns:\n",
    "                    out[col] = subset[col]\n",
    "\n",
    "            if args.mode in ['prev_pseudolabels', 'curr_pseudolabels']:\n",
    "                pseudo_path = filepaths['PREVIOUS_DATA_PSEUDOLABELS_DIR_PATH'] \\\n",
    "                    if args.mode == 'prev_pseudolabels' \\\n",
    "                    else filepaths['CURRENT_DATA_PSEUDOLABELS_DIR_PATH']\n",
    "\n",
    "                dir_path = os.path.join(pseudo_path, f'{model_id}_pseudolabels')\n",
    "                if not os.path.isdir(dir_path):\n",
    "                    os.mkdir(dir_path)\n",
    "\n",
    "                out.to_csv(os.path.join(dir_path, f'pseudolabels_fold{fold}.csv'), index=False)\n",
    "\n",
    "            if args.mode == 'oofs':\n",
    "                oofs_list.append(out)\n",
    "\n",
    "        del model, prediction\n",
    "\n",
    "    if args.mode == 'submission':\n",
    "        predictions = np.mean(predictions, axis=0)\n",
    "\n",
    "        test_df[target_columns] = predictions\n",
    "\n",
    "        submission = pd.read_csv(filepaths['SAMPLE_SUBMISSION_CSV_PATH'])\n",
    "        submission = submission.drop(columns=target_columns) \\\n",
    "            .merge(test_df[['text_id'] + target_columns], on='text_id', how='left')\n",
    "        submission[['text_id'] + target_columns].to_csv(os.path.join(filepaths['SUBMISSIONS_DIR_PATH'], f'{model_id}_submission.csv'), index=False)\n",
    "\n",
    "    elif args.mode == 'oofs':\n",
    "        oof_df = pd.concat(oofs_list)\n",
    "        oof_df.to_csv(os.path.join(filepaths['OOFS_DIR_PATH'], f'{model_id}.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
