{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33412f5e",
   "metadata": {},
   "source": [
    "# src - sift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2da5f5",
   "metadata": {},
   "source": [
    "## Notebook运行提示\n",
    "- 代码已拆分为多个小单元, 按顺序运行即可在每一步观察输出与中间变量。\n",
    "- 涉及 `Path(__file__)` 或相对路径的脚本会自动注入 `__file__` 解析逻辑, Notebook 环境下也能引用原项目资源。\n",
    "- 可在每个单元下追加说明或参数试验记录, 以跟踪核心算法和数据处理步骤。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adf71a5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft, Inc. 2020\n",
    "#\n",
    "# This source code is licensed under the MIT license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "#\n",
    "# Author: penhe@microsoft.com\n",
    "# Date: 01/25/2021\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35410c44",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "__all__ = ['PerturbationLayer', 'AdversarialLearner', 'hook_sift_layer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc26184",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class PerturbationLayer(torch.nn.Module):\n",
    "    def __init__(self, hidden_size, learning_rate=1e-4, init_perturbation=1e-2):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.init_perturbation = init_perturbation\n",
    "        self.delta = None\n",
    "        self.LayerNorm = torch.nn.LayerNorm(hidden_size, 1e-7, elementwise_affine=False)\n",
    "        self.adversarial_mode = False\n",
    "\n",
    "    def adversarial_(self, adversarial = True):\n",
    "        self.adversarial_mode = adversarial\n",
    "        if not adversarial:\n",
    "            self.delta = None\n",
    "\n",
    "    def forward(self, input):\n",
    "        if not self.adversarial_mode:\n",
    "            self.input = self.LayerNorm(input)\n",
    "            return self.input\n",
    "        else:\n",
    "            if self.delta is None:\n",
    "                self.update_delta(requires_grad=True)\n",
    "            return self.perturbated_input\n",
    "\n",
    "    def update_delta(self, requires_grad = False):\n",
    "        if not self.adversarial_mode:\n",
    "            return True\n",
    "        if self.delta is None:\n",
    "            delta = torch.clamp(self.input.new(self.input.size()).normal_(0, self.init_perturbation).float(), - 2 *self.init_perturbation, 2* self.init_perturbation)\n",
    "        else:\n",
    "            grad = self.delta.grad\n",
    "            self.delta.grad = None\n",
    "            delta = self.delta\n",
    "            norm = grad.norm()\n",
    "            if torch.isnan(norm) or torch.isinf(norm):\n",
    "                return False\n",
    "            eps = self.learning_rate\n",
    "            with torch.no_grad():\n",
    "                delta = delta + eps * grad / (1e-6 + grad.abs().max(-1, keepdim=True)[0])\n",
    "        self.delta = delta.float().detach().requires_grad_(requires_grad)\n",
    "        self.perturbated_input = (self.input.to(delta).detach() + self.delta).to(self.input)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6cc97b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def hook_sift_layer(model, hidden_size, learning_rate=1e-4, init_perturbation=1e-2,\n",
    "                    target_module='embeddings.LayerNorm'):\n",
    "    \"\"\"\n",
    "    Hook the sift perturbation layer to and existing model. With this method, you can apply adversarial training\n",
    "    without changing the existing model implementation.\n",
    "    Params:\n",
    "      `model`: The model instance to apply adversarial training\n",
    "      `hidden_size`: The dimmension size of the perturbated embedding\n",
    "      `learning_rate`: The learning rate to update the perturbation\n",
    "      `init_perturbation`: The initial range of perturbation\n",
    "      `target_module`: The module to apply perturbation. It can be the name of the sub-module of the model or the sub-module instance.\n",
    "      The perturbation layer will be inserted before the sub-module.\n",
    "    Outputs:\n",
    "      The perturbation layers.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(target_module, str):\n",
    "        _modules = [k for n, k in model.named_modules() if target_module in n]\n",
    "        print(f'Will apply pertubations to layers: {_modules}')\n",
    "    else:\n",
    "        assert isinstance(target_module,\n",
    "                          torch.nn.Module), f'{type(target_module)} is not an instance of torch.nn.Module'\n",
    "        _modules = [target_module]\n",
    "    adv_modules = []\n",
    "    for m in _modules:\n",
    "        adv = PerturbationLayer(hidden_size, learning_rate, init_perturbation)\n",
    "\n",
    "        def adv_hook(module, inputs):\n",
    "            return adv(inputs[0])\n",
    "\n",
    "        for h in list(m._forward_pre_hooks.keys()):\n",
    "            if m._forward_pre_hooks[h].__name__ == 'adv_hook':\n",
    "                del m._forward_pre_hooks[h]\n",
    "        m.register_forward_pre_hook(adv_hook)\n",
    "        adv_modules.append(adv)\n",
    "    return adv_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962f1a92",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class AdversarialLearner:\n",
    "    \"\"\" Adversarial Learner\n",
    "    This class is the helper class for adversarial training.\n",
    "    Params:\n",
    "      `model`: The model instance to apply adversarial training\n",
    "      `perturbation_modules`: The sub modules in the model that will generate perturbations. If it's `None`,\n",
    "      the constructor will detect sub-modules of type `PerturbationLayer` in the model.\n",
    "    Example usage:\n",
    "    ```python\n",
    "    # Create DeBERTa model\n",
    "    adv_modules = hook_sift_layer(model, hidden_size=768)\n",
    "    adv = AdversarialLearner(model, adv_modules)\n",
    "    def logits_fn(model, *wargs, **kwargs):\n",
    "      logits,_ = model(*wargs, **kwargs)\n",
    "      return logits\n",
    "    logits,loss = model(**data)\n",
    "    loss = loss + adv.loss(logits, logits_fn, **data)\n",
    "    # Other steps is the same as general training.\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, adv_modules=None):\n",
    "        if adv_modules is None:\n",
    "            self.adv_modules = [m for m in model.modules() if isinstance(m, PerturbationLayer)]\n",
    "        else:\n",
    "            self.adv_modules = adv_modules\n",
    "        self.parameters = [p for p in model.parameters()]\n",
    "        self.model = model\n",
    "\n",
    "    def loss(self, target, logits_fn, loss_fn='symmetric-kl', *wargs, **kwargs):\n",
    "        \"\"\"\n",
    "        Calculate the adversarial loss based on the given logits fucntion and loss function.\n",
    "        Inputs:\n",
    "        `target`: the logits from original inputs.\n",
    "        `logits_fn`: the function that produces logits based on perturbated inputs. E.g.,\n",
    "        ```python\n",
    "        def logits_fn(model, *wargs, **kwargs):\n",
    "          logits = model(*wargs, **kwargs)\n",
    "          return logits\n",
    "        ```\n",
    "        `loss_fn`: the function that caclulate the loss from perturbated logits and target logits.\n",
    "          - If it's a string, it can be pre-built loss functions, i.e. kl, symmetric_kl, mse.\n",
    "          - If it's a function, it will be called to calculate the loss, the signature of the function will be,\n",
    "          ```python\n",
    "          def loss_fn(source_logits, target_logits):\n",
    "            # Calculate the loss\n",
    "            return loss\n",
    "          ```\n",
    "        `*wargs`: the positional arguments that will be passed to the model\n",
    "        `**kwargs`: the key-word arguments that will be passed to the model\n",
    "        Outputs:\n",
    "          The loss based on pertubated inputs.\n",
    "        \"\"\"\n",
    "        self.prepare()\n",
    "        if isinstance(loss_fn, str):\n",
    "            loss_fn = perturbation_loss_fns[loss_fn]\n",
    "        pert_logits = logits_fn(self.model, *wargs, **kwargs)\n",
    "        pert_loss = loss_fn(pert_logits, target.detach()).sum()\n",
    "        pert_loss.backward()\n",
    "        for m in self.adv_modules:\n",
    "            ok = m.update_delta(True)\n",
    "\n",
    "        for r, p in zip(self.prev, self.parameters):\n",
    "            p.requires_grad_(r)\n",
    "        pert_logits = logits_fn(self.model, *wargs, **kwargs)\n",
    "        pert_loss = symmetric_kl(pert_logits, target)\n",
    "\n",
    "        self.cleanup()\n",
    "        return pert_loss.mean()\n",
    "\n",
    "    def prepare(self):\n",
    "        self.prev = [p.requires_grad for p in self.parameters]\n",
    "        for p in self.parameters:\n",
    "            p.requires_grad_(False)\n",
    "        for m in self.adv_modules:\n",
    "            m.adversarial_(True)\n",
    "\n",
    "    def cleanup(self):\n",
    "        for r, p in zip(self.prev, self.parameters):\n",
    "            p.requires_grad_(r)\n",
    "\n",
    "        for m in self.adv_modules:\n",
    "            m.adversarial_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92194b7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def symmetric_kl(logits, target):\n",
    "    logit_stu = logits.view(-1, logits.size(-1)).float()\n",
    "    logit_tea = target.view(-1, target.size(-1)).float()\n",
    "    logprob_stu = F.log_softmax(logit_stu, -1)\n",
    "    logprob_tea = F.log_softmax(logit_tea, -1)\n",
    "    prob_tea = logprob_tea.exp().detach()\n",
    "    prob_stu = logprob_stu.exp().detach()\n",
    "    floss = ((prob_tea * (-logprob_stu)).sum(-1))  # Cross Entropy\n",
    "    bloss = ((prob_stu * (-logprob_tea)).sum(-1))  # Cross Entropy\n",
    "    loss = floss + bloss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af2c59e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def kl(logits, target):\n",
    "    logit_stu = logits.view(-1, logits.size(-1)).float()\n",
    "    logit_tea = target.view(-1, target.size(-1)).float()\n",
    "    logprob_stu = F.log_softmax(logit_stu, -1)\n",
    "    logprob_tea = F.log_softmax(logit_tea.detach(), -1)\n",
    "    prob_tea = logprob_tea.exp()\n",
    "    loss = ((prob_tea * (-logprob_stu)).sum(-1))  # Cross Entropy\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e952b15",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def mse(logits, target):\n",
    "    logit_stu = logits.view(-1, logits.size(-1)).float()\n",
    "    logit_tea = target.view(-1, target.size(-1)).float()\n",
    "    return F.mse_loss(logit_stu.view(-1), logit_tea.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8eb0006",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "perturbation_loss_fns = {\n",
    "    'symmetric-kl': symmetric_kl,\n",
    "    'kl': kl,\n",
    "    'mse': mse\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
