{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c9b3672",
   "metadata": {},
   "source": [
    "# 02-Feedback-ELL-1st-Place - train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e630d09",
   "metadata": {},
   "source": [
    "## Notebook运行提示\n",
    "- 代码已拆分为多个小单元, 按顺序运行即可在每一步观察输出与中间变量。\n",
    "- 涉及 `Path(__file__)` 或相对路径的脚本会自动注入 `__file__` 解析逻辑, Notebook 环境下也能引用原项目资源。\n",
    "- 可在每个单元下追加说明或参数试验记录, 以跟踪核心算法和数据处理步骤。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa6d603",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import wandb\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "sys.path.append('../src')\n",
    "\n",
    "from utils import load_filepaths\n",
    "from utils import get_config, dictionary_to_namespace, get_logger, save_config, update_filepaths\n",
    "from criterion.score import get_score\n",
    "from data.preprocessing import make_folds, get_max_len_from_df, get_additional_special_tokens, preprocess_text\n",
    "from dataset.datasets import get_train_dataloader, get_valid_dataloader\n",
    "from dataset.collators import collate\n",
    "from models.utils import get_model\n",
    "from optimizer.optimizer import get_optimizer\n",
    "from utils import AverageMeter, time_since, get_evaluation_steps\n",
    "from scheduler.scheduler import get_scheduler\n",
    "from adversarial_learning.awp import AWP\n",
    "from criterion.criterion import get_criterion\n",
    "\n",
    "from datetime import datetime\n",
    "from utils import str_to_bool, create_dirs_if_not_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce3de89",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--config_name', type=str)\n",
    "    parser.add_argument('--run_id', type=str)\n",
    "    parser.add_argument('--debug', type=str_to_bool, default=False)\n",
    "    parser.add_argument('--use_wandb', type=str_to_bool, default=True)\n",
    "    parser.add_argument('--fold', type=int)\n",
    "    arguments = parser.parse_args()\n",
    "    return arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1758d135",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409bd580",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def valid_fn(valid_dataloader, model, criterion, epoch):\n",
    "    valid_losses = AverageMeter()\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    start = time.time()\n",
    "\n",
    "    for step, (inputs, labels) in enumerate(valid_dataloader):\n",
    "        inputs = collate(inputs)\n",
    "\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        batch_size = labels.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "            loss = criterion(y_preds, labels)\n",
    "\n",
    "        if config.training.gradient_accumulation_steps > 1:\n",
    "            loss = loss / config.training.gradient_accumulation_steps\n",
    "\n",
    "        valid_losses.update(loss.item(), batch_size)\n",
    "        predictions.append(y_preds.to('cpu').numpy())\n",
    "\n",
    "        if step % config.general.valid_print_frequency == 0 or step == (len(valid_dataloader) - 1):\n",
    "            remain = time_since(start, float(step + 1) / len(valid_dataloader))\n",
    "            logger.info('EVAL: [{0}][{1}/{2}] '\n",
    "                        'Elapsed: {remain:s} '\n",
    "                        'Loss: {loss.avg:.4f} '\n",
    "                        .format(epoch+1, step+1, len(valid_dataloader),\n",
    "                                remain=remain,\n",
    "                                loss=valid_losses))\n",
    "\n",
    "        if args.use_wandb:\n",
    "            wandb.log({f\"Validation loss\": valid_losses.val})\n",
    "\n",
    "    predictions = np.concatenate(predictions)\n",
    "    return valid_losses, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1b4a4a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def inference_fn(test_loader, model):\n",
    "    predictions = []\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    tk0 = tqdm(test_loader, total=len(test_loader))\n",
    "    for inputs in tk0:\n",
    "        inputs = collate(inputs)\n",
    "        for k, v in inputs.items():\n",
    "            inputs[k] = v.to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(inputs)\n",
    "        predictions.append(y_preds.to('cpu').numpy())\n",
    "    predictions = np.concatenate(predictions)\n",
    "    return 0, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2e1f90",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_loop(train_folds,\n",
    "               valid_folds,\n",
    "               model_checkpoint_path=None):\n",
    "\n",
    "    train_dataloader = get_train_dataloader(config, train_folds)\n",
    "    valid_dataloader = get_valid_dataloader(config, valid_folds)\n",
    "\n",
    "    valid_labels = valid_folds[config.general.target_columns].values\n",
    "\n",
    "    model = get_model(config, model_checkpoint_path=model_checkpoint_path)\n",
    "    torch.save(model.backbone_config, filepaths['backbone_config_fn_path'])\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = get_optimizer(model, config)\n",
    "\n",
    "    train_steps_per_epoch = int(len(train_folds) / config.general.train_batch_size)\n",
    "    num_train_steps = train_steps_per_epoch * config.training.epochs\n",
    "\n",
    "    eval_steps = get_evaluation_steps(train_steps_per_epoch,\n",
    "                                      config.training.evaluate_n_times_per_epoch)\n",
    "\n",
    "    scheduler = get_scheduler(optimizer, config, num_train_steps)\n",
    "\n",
    "    awp = AWP(model=model,\n",
    "              optimizer=optimizer,\n",
    "              adv_lr=config.adversarial_learning.adversarial_lr,\n",
    "              adv_eps=config.adversarial_learning.adversarial_eps,\n",
    "              adv_epoch=config.adversarial_learning.adversarial_epoch_start)\n",
    "\n",
    "    criterion = get_criterion(config)\n",
    "\n",
    "    best_score = np.inf\n",
    "    for epoch in range(config.training.epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        scaler = torch.cuda.amp.GradScaler(enabled=config.training.apex)\n",
    "\n",
    "        train_losses = AverageMeter()\n",
    "        valid_losses = None\n",
    "        score, scores = None, None\n",
    "\n",
    "        start = time.time()\n",
    "        global_step = 0\n",
    "\n",
    "        for step, (inputs, labels) in enumerate(train_dataloader):\n",
    "            inputs = collate(inputs)\n",
    "\n",
    "            for k, v in inputs.items():\n",
    "                inputs[k] = v.to(device)\n",
    "\n",
    "            labels = labels.to(device)\n",
    "            awp.perturb(epoch)\n",
    "\n",
    "            batch_size = labels.size(0)\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=config.training.apex):\n",
    "                y_preds = model(inputs)\n",
    "                loss = criterion(y_preds, labels)\n",
    "\n",
    "            if config.training.gradient_accumulation_steps > 1:\n",
    "                loss = loss / config.training.gradient_accumulation_steps\n",
    "\n",
    "            train_losses.update(loss.item(), batch_size)\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            awp.restore()\n",
    "\n",
    "            if config.training.unscale:\n",
    "                scaler.unscale_(optimizer)\n",
    "\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), config.training.max_grad_norm)\n",
    "\n",
    "            if args.use_wandb:\n",
    "                wandb.log({f\"Training loss\": train_losses.val})\n",
    "\n",
    "            if (step + 1) % config.training.gradient_accumulation_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                global_step += 1\n",
    "                if config.scheduler.batch_scheduler:\n",
    "                    scheduler.step()\n",
    "\n",
    "            if (step % config.general.train_print_frequency == 0) or \\\n",
    "                    (step == (len(train_dataloader) - 1)) or \\\n",
    "                    (step + 1 in eval_steps) or \\\n",
    "                    (step - 1 in eval_steps):\n",
    "\n",
    "                remain = time_since(start, float(step + 1) / len(train_dataloader))\n",
    "                logger.info(f'Epoch: [{epoch+1}][{step+1}/{len(train_dataloader)}] '\n",
    "                            f'Elapsed {remain:s} '\n",
    "                            f'Loss: {train_losses.val:.4f}({train_losses.avg:.4f}) '\n",
    "                            f'Grad: {grad_norm:.4f}  '\n",
    "                            f'LR: {scheduler.get_lr()[0]:.8f}  ')\n",
    "\n",
    "            if (step + 1) in eval_steps:\n",
    "                valid_losses, predictions = valid_fn(valid_dataloader, model, criterion, epoch)\n",
    "                score, scores = get_score(valid_labels, predictions)\n",
    "\n",
    "                model.train()\n",
    "\n",
    "                logger.info(f'Epoch {epoch+1} - Score: {score:.4f}  Scores: {scores}')\n",
    "                if score < best_score:\n",
    "                    best_score = score\n",
    "\n",
    "                    torch.save({'model': model.state_dict(), 'predictions': predictions}, filepaths['model_fn_path'])\n",
    "                    logger.info(f'\\nEpoch {epoch + 1} - Save Best Score: {best_score:.4f} Model\\n')\n",
    "\n",
    "                unique_parameters = ['.'.join(name.split('.')[:4]) for name, _ in model.named_parameters()]\n",
    "                learning_rates = list(set(zip(unique_parameters, scheduler.get_lr())))\n",
    "\n",
    "                if args.use_wandb:\n",
    "                    wandb.log({f'{parameter} lr': lr for parameter, lr in learning_rates})\n",
    "                    wandb.log({f'Best Score': best_score})\n",
    "\n",
    "        if config.optimizer.use_swa:\n",
    "            optimizer.swap_swa_sgd()\n",
    "\n",
    "        elapsed = time.time() - start_time\n",
    "\n",
    "        logger.info(f'Epoch {epoch + 1} - avg_train_loss: {train_losses.avg:.4f} '\n",
    "                    f'avg_val_loss: {valid_losses.avg:.4f} time: {elapsed:.0f}s '\n",
    "                    f'Epoch {epoch + 1} - Score: {score:.4f}  Scores: {scores}\\n'\n",
    "                    '=============================================================================\\n')\n",
    "\n",
    "        if args.use_wandb:\n",
    "            wandb.log({f\"Epoch\": epoch + 1,\n",
    "                       f\"avg_train_loss\": train_losses.avg,\n",
    "                       f\"avg_val_loss\": valid_losses.avg,\n",
    "                       f\"Score\": score,\n",
    "                       f\"Cohesion rmse\": scores[0],\n",
    "                       f\"Syntax rmse\": scores[1],\n",
    "                       f\"Vocabulary rmse\": scores[2],\n",
    "                       f\"Phraseology rmse\": scores[3],\n",
    "                       f\"Grammar rmse\": scores[4],\n",
    "                       f\"Conventions rmse\": scores[5]})\n",
    "\n",
    "    predictions = torch.load(filepaths['model_fn_path'], map_location=torch.device('cpu'))['predictions']\n",
    "    valid_folds[[f\"pred_{c}\" for c in config.general.target_columns]] = predictions\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return valid_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7601214",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_result(oof_df):\n",
    "    labels = oof_df[config.general.target_columns].values\n",
    "    preds = oof_df[[f\"pred_{c}\" for c in config.general.target_columns]].values\n",
    "    score, scores = get_score(labels, preds)\n",
    "    print(f'Score: {score:<.4f}  Scores: {scores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e010f5fc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def check_arguments():\n",
    "    all_folds = [i for i in range(config.general.n_folds)]\n",
    "    assert args.fold in all_folds, \\\n",
    "        f'Invalid training fold, fold number must be in {all_folds}'\n",
    "\n",
    "    if config.general.use_current_data_pseudo_labels and config.general.use_current_data_true_labels:\n",
    "        logger.warning('Both use_current_data_pseudo_labels and use_current_data_true_labels are True. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e13486",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def init_wandb():\n",
    "    job_type = 'debug' if args.debug else 'train'\n",
    "    mode = 'finetuning/from checkpoint' if config['model']['from_checkpoint'] == '' else 'pretraining/from scratch'\n",
    "    backbone_type = config['model']['backbone_type']\n",
    "    criterion_type = config['criterion']['criterion_type']\n",
    "    pooling_type = config['model']['pooling_type']\n",
    "\n",
    "    wandb.login(key='')\n",
    "\n",
    "    wandb_run = wandb.init(\n",
    "                    project=config['logging']['wandb']['project'],\n",
    "                    # group=config['model']['backbone_type'],\n",
    "                    group=args.run_id,\n",
    "                    job_type=job_type,\n",
    "                    tags=[backbone_type, mode, job_type, 'fold'+str(args.fold),\n",
    "                          criterion_type, pooling_type, args.run_id],\n",
    "                    config=config,\n",
    "                    name=f'{args.run_id}-fold{args.fold}'\n",
    "    )\n",
    "    return wandb_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e18dcdb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main():\n",
    "    train = pd.read_csv(filepaths['TRAIN_CSV_PATH'])\n",
    "\n",
    "    train = make_folds(train,\n",
    "                       target_cols=config.general.target_columns,\n",
    "                       n_splits=config.general.n_folds,\n",
    "                       random_state=config.general.seed)\n",
    "\n",
    "    train['full_text'] = train['full_text'].apply(preprocess_text)\n",
    "\n",
    "    special_tokens_replacement = get_additional_special_tokens()\n",
    "    all_special_tokens = list(special_tokens_replacement.values())\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.model.backbone_type,\n",
    "                                              use_fast=True,\n",
    "                                              additional_special_tokens=all_special_tokens, )\n",
    "\n",
    "    tokenizer.save_pretrained(filepaths['tokenizer_dir_path'])\n",
    "    config.tokenizer = tokenizer\n",
    "\n",
    "    train_df = pd.DataFrame(columns=train.columns)\n",
    "    valid_df = train[train['fold'] == fold].reset_index(drop=True)\n",
    "\n",
    "    if config.general.use_current_data_true_labels:\n",
    "        train_df = pd.concat([train_df, train[train['fold'] != fold].reset_index(drop=True)], axis=0)\n",
    "\n",
    "    if config.general.use_previous_data_pseudo_labels:\n",
    "        pseudo_path = filepaths[\"prev_data_pseudo_fn_path\"]\n",
    "        logger.info(f'Loading previous data pseudo labels: {pseudo_path}')\n",
    "\n",
    "        fold_pseudo = pd.read_csv(pseudo_path)\n",
    "        fold_pseudo['in_train'] = fold_pseudo['text_id'].apply(lambda x: x in train['text_id'].values)\n",
    "        fold_pseudo = fold_pseudo[~fold_pseudo['in_train'].values]\n",
    "        fold_pseudo = fold_pseudo[['text_id', 'full_text'] + config.general.target_columns]\n",
    "\n",
    "        train_df = pd.concat([train_df, fold_pseudo], axis=0).reset_index(drop=True)\n",
    "\n",
    "    if config.general.use_current_data_pseudo_labels:\n",
    "        pseudo_path = filepaths['curr_data_pseudo_fn_path']\n",
    "        logger.info(f'Loading current data pseudo labels: {pseudo_path}')\n",
    "\n",
    "        fold_pseudo = pd.read_csv(pseudo_path)\n",
    "        fold_pseudo = fold_pseudo[['text_id'] + config.general.target_columns]\n",
    "        fold_pseudo = pd.merge(fold_pseudo, train[['text_id', 'full_text', 'fold']], on='text_id', how='left')\n",
    "        fold_pseudo = fold_pseudo[fold_pseudo['fold'] != fold].reset_index(drop=True)\n",
    "\n",
    "        train_df = pd.concat([train_df, fold_pseudo], axis=0).reset_index(drop=True)\n",
    "\n",
    "    train_df[config.general.target_columns] = train_df[config.general.target_columns].clip(1, 5)\n",
    "\n",
    "    if args.debug:\n",
    "        logger.info('Debug mode: using only 50 samples')\n",
    "        train_df = train_df.sample(n=50, random_state=config.general.seed).reset_index(drop=True)\n",
    "        valid_df = valid_df.sample(n=50, random_state=config.general.seed).reset_index(drop=True)\n",
    "\n",
    "    logger.info(f'Train shape: {train_df.shape}')\n",
    "    logger.info(f'Valid shape: {valid_df.shape}')\n",
    "\n",
    "    if config.general.set_max_length_from_data:\n",
    "        logger.info('Setting max length from data')\n",
    "        config.general.max_length = get_max_len_from_df(train_df, tokenizer)\n",
    "\n",
    "    logger.info(f\"Max tokenized sequence len: {config.general.max_length}\")\n",
    "    logger.info(f\"==================== fold: {fold} training ====================\")\n",
    "\n",
    "    model_checkpoint_path = filepaths['model_checkpoint_fn_path'] if config.model.from_checkpoint else None\n",
    "    logger.info(f'Using model checkpoint from: {model_checkpoint_path}')\n",
    "\n",
    "    if args.debug:\n",
    "        config.training.epochs = 1\n",
    "\n",
    "    if config.general.check_cv_on_all_data and not args.debug:\n",
    "        '''\n",
    "            For models 15 and 16 pretraining step I checked CV on all available data, instead of 1 folds\n",
    "            Its results in overfitting, and I changed it later, but keep it here to reproduce results,\n",
    "            since I used pseudolabels from model 16 to train model 17, so without this \n",
    "        '''\n",
    "        fold_out = train_loop(train_df,\n",
    "                              train,\n",
    "                              model_checkpoint_path=model_checkpoint_path, )\n",
    "    else:\n",
    "        fold_out = train_loop(train_df,\n",
    "                              valid_df,\n",
    "                              model_checkpoint_path=model_checkpoint_path,)\n",
    "\n",
    "    fold_out.to_csv(filepaths['oof_fn_path'], index=False)\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b540f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "    filepaths = load_filepaths()\n",
    "\n",
    "    config_path = os.path.join(filepaths['CONFIGS_DIR_PATH'], args.config_name)\n",
    "    config = get_config(config_path)\n",
    "\n",
    "    fold = args.fold\n",
    "    if args.use_wandb:\n",
    "        run = init_wandb()\n",
    "\n",
    "    filepaths = update_filepaths(filepaths, config, args.run_id, fold)\n",
    "    create_dirs_if_not_exists(filepaths)\n",
    "\n",
    "    if not os.path.exists(filepaths['run_dir_path']):\n",
    "        os.makedirs(filepaths['run_dir_path'])\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logger = get_logger(filename=filepaths['log_fn_path'])\n",
    "\n",
    "    if os.path.isfile(filepaths['model_fn_path']):\n",
    "        new_name = filepaths[\"model_fn_path\"]+f'_renamed_at_{str(datetime.now())}'\n",
    "        logger.warning(f'{filepaths[\"model_fn_path\"]} is already exists, renaming this file to {new_name}')\n",
    "        os.rename(filepaths[\"model_fn_path\"], new_name)\n",
    "\n",
    "    # save_config(config, filepaths['training_config_fn_path'])\n",
    "\n",
    "    config = dictionary_to_namespace(config)\n",
    "\n",
    "    seed_everything(seed=config.general.seed)\n",
    "\n",
    "    check_arguments()\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
