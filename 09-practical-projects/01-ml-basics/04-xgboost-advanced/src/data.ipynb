{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0fbcf09",
   "metadata": {},
   "source": [
    "# XGBoost高级技巧 - 数据处理模块"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a672d488",
   "metadata": {},
   "source": [
    "\n",
    "本模块展示竞赛级别的数据处理技巧：\n",
    "1. 高级特征工程（统计特征、交互特征、目标编码）\n",
    "2. 特征选择（重要性、相关性、递归消除）\n",
    "3. 数据增强和采样\n",
    "4. 特征缩放和归一化\n",
    "\n",
    "【推荐数据集】：\n",
    "- Kaggle竞赛数据集\n",
    "- UCI机器学习库\n",
    "- 本项目使用：California Housing（回归）或 Credit Card Fraud（分类）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a34bb8",
   "metadata": {},
   "source": [
    "## 高级数据处理策略\n",
    "1. 使用 `load_california_housing_data` 或 make_classification 生成基准数据, 并转换成结构化 DataFrame。\n",
    "2. `AdvancedFeatureEngineering` 提供统计、交互、多项式、分箱、目标编码等竞赛级技巧。\n",
    "3. `AdvancedFeatureSelector` 结合 SelectKBest、相关系数、递归消除等方法筛选特征。\n",
    "4. `prepare_advanced_features` 统一调度特征构造/选择/缩放, 并输出 train/test Split。\n",
    "\n",
    "> **核心提示**: 每一步都在 Notebook 中记录创建了多少新特征, 方便控制特征爆炸。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0796cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "XGBoost高级技巧 - 数据处理模块\n",
    "\n",
    "本模块展示竞赛级别的数据处理技巧：\n",
    "1. 高级特征工程（统计特征、交互特征、目标编码）\n",
    "2. 特征选择（重要性、相关性、递归消除）\n",
    "3. 数据增强和采样\n",
    "4. 特征缩放和归一化\n",
    "\n",
    "【推荐数据集】：\n",
    "- Kaggle竞赛数据集\n",
    "- UCI机器学习库\n",
    "- 本项目使用：California Housing（回归）或 Credit Card Fraud（分类）\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.datasets import fetch_california_housing, make_classification\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class AdvancedFeatureEngineering:\n",
    "    \"\"\"\n",
    "    高级特征工程\n",
    "\n",
    "    【是什么】：竞赛级别的特征构造技巧\n",
    "    【包含】：\n",
    "        - 统计特征（均值、方差、分位数）\n",
    "        - 交互特征（乘法、除法、多项式）\n",
    "        - 聚合特征（分组统计）\n",
    "        - 目标编码（Target Encoding）\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.target_encoders = {}\n",
    "        self.feature_names = []\n",
    "\n",
    "    def create_statistical_features(self, df, numeric_cols):\n",
    "        \"\"\"\n",
    "        创建统计特征\n",
    "\n",
    "        【是什么】：基于现有特征的统计量\n",
    "        【为什么】：捕获数据的分布特性\n",
    "        \"\"\"\n",
    "        print(\"\\n创建统计特征...\")\n",
    "        new_features = pd.DataFrame()\n",
    "\n",
    "        # 【行统计】：每个样本的统计量\n",
    "        new_features['row_mean'] = df[numeric_cols].mean(axis=1)\n",
    "        new_features['row_std'] = df[numeric_cols].std(axis=1)\n",
    "        new_features['row_min'] = df[numeric_cols].min(axis=1)\n",
    "        new_features['row_max'] = df[numeric_cols].max(axis=1)\n",
    "        new_features['row_median'] = df[numeric_cols].median(axis=1)\n",
    "\n",
    "        # 【范围特征】\n",
    "        new_features['row_range'] = new_features['row_max'] - new_features['row_min']\n",
    "\n",
    "        # 【偏度和峰度】：分布形状\n",
    "        new_features['row_skew'] = df[numeric_cols].skew(axis=1)\n",
    "        new_features['row_kurt'] = df[numeric_cols].kurtosis(axis=1)\n",
    "\n",
    "        print(f\"  创建了 {len(new_features.columns)} 个统计特征\")\n",
    "        return new_features\n",
    "\n",
    "    def create_interaction_features(self, df, numeric_cols, max_interactions=20):\n",
    "        \"\"\"\n",
    "        创建交互特征\n",
    "\n",
    "        【是什么】：特征之间的组合\n",
    "        【为什么】：捕获特征间的非线性关系\n",
    "        【技巧】：\n",
    "            - 乘法：f1 * f2（联合效应）\n",
    "            - 除法：f1 / f2（比率）\n",
    "            - 差值：f1 - f2（对比）\n",
    "        \"\"\"\n",
    "        print(\"\\n创建交互特征...\")\n",
    "        new_features = pd.DataFrame()\n",
    "\n",
    "        # 选择最重要的特征进行交互（避免特征爆炸）\n",
    "        selected_cols = numeric_cols[:min(len(numeric_cols), 5)]\n",
    "\n",
    "        count = 0\n",
    "        for i, col1 in enumerate(selected_cols):\n",
    "            for col2 in selected_cols[i+1:]:\n",
    "                if count >= max_interactions:\n",
    "                    break\n",
    "\n",
    "                # 乘法\n",
    "                new_features[f'{col1}_x_{col2}'] = df[col1] * df[col2]\n",
    "\n",
    "                # 除法（避免除零）\n",
    "                new_features[f'{col1}_div_{col2}'] = df[col1] / (df[col2] + 1e-5)\n",
    "\n",
    "                # 差值\n",
    "                new_features[f'{col1}_minus_{col2}'] = df[col1] - df[col2]\n",
    "\n",
    "                count += 1\n",
    "\n",
    "        print(f\"  创建了 {len(new_features.columns)} 个交互特征\")\n",
    "        return new_features\n",
    "\n",
    "    def create_polynomial_features(self, df, numeric_cols, degree=2, max_features=10):\n",
    "        \"\"\"\n",
    "        创建多项式特征\n",
    "\n",
    "        【是什么】：特征的幂次方\n",
    "        【为什么】：捕获非线性关系\n",
    "        \"\"\"\n",
    "        print(\"\\n创建多项式特征...\")\n",
    "        new_features = pd.DataFrame()\n",
    "\n",
    "        selected_cols = numeric_cols[:min(len(numeric_cols), max_features)]\n",
    "\n",
    "        for col in selected_cols:\n",
    "            for d in range(2, degree + 1):\n",
    "                new_features[f'{col}_pow{d}'] = df[col] ** d\n",
    "\n",
    "        print(f\"  创建了 {len(new_features.columns)} 个多项式特征\")\n",
    "        return new_features\n",
    "\n",
    "    def create_binning_features(self, df, numeric_cols, n_bins=5):\n",
    "        \"\"\"\n",
    "        创建分箱特征\n",
    "\n",
    "        【是什么】：将连续特征离散化\n",
    "        【为什么】：\n",
    "            - 减少异常值影响\n",
    "            - 捕获非线性关系\n",
    "            - 提高模型鲁棒性\n",
    "        \"\"\"\n",
    "        print(\"\\n创建分箱特征...\")\n",
    "        new_features = pd.DataFrame()\n",
    "\n",
    "        for col in numeric_cols[:5]:  # 只对前5个特征分箱\n",
    "            new_features[f'{col}_bin'] = pd.qcut(\n",
    "                df[col],\n",
    "                q=n_bins,\n",
    "                labels=False,\n",
    "                duplicates='drop'\n",
    "            )\n",
    "\n",
    "        print(f\"  创建了 {len(new_features.columns)} 个分箱特征\")\n",
    "        return new_features\n",
    "\n",
    "    def create_target_encoding(self, df, categorical_cols, target, smoothing=10):\n",
    "        \"\"\"\n",
    "        目标编码（Target Encoding）\n",
    "\n",
    "        【是什么】：用目标变量的统计量编码类别特征\n",
    "        【为什么】：\n",
    "            - 比One-Hot编码更紧凑\n",
    "            - 包含目标信息\n",
    "            - 适合高基数类别特征\n",
    "\n",
    "        【技巧】：平滑处理防止过拟合\n",
    "        公式：encoded = (n * mean + smoothing * global_mean) / (n + smoothing)\n",
    "        \"\"\"\n",
    "        print(\"\\n创建目标编码...\")\n",
    "        new_features = pd.DataFrame()\n",
    "\n",
    "        global_mean = target.mean()\n",
    "\n",
    "        for col in categorical_cols:\n",
    "            # 计算每个类别的目标均值和计数\n",
    "            agg = df.groupby(col)[target.name].agg(['mean', 'count'])\n",
    "\n",
    "            # 平滑处理\n",
    "            smoothed_mean = (\n",
    "                agg['count'] * agg['mean'] + smoothing * global_mean\n",
    "            ) / (agg['count'] + smoothing)\n",
    "\n",
    "            # 映射\n",
    "            new_features[f'{col}_target_enc'] = df[col].map(smoothed_mean)\n",
    "\n",
    "            # 保存编码器（用于测试集）\n",
    "            self.target_encoders[col] = smoothed_mean\n",
    "\n",
    "        print(f\"  创建了 {len(new_features.columns)} 个目标编码特征\")\n",
    "        return new_features\n",
    "\n",
    "    def apply_target_encoding(self, df, categorical_cols, global_mean):\n",
    "        \"\"\"应用已训练的目标编码\"\"\"\n",
    "        new_features = pd.DataFrame()\n",
    "\n",
    "        for col in categorical_cols:\n",
    "            if col in self.target_encoders:\n",
    "                new_features[f'{col}_target_enc'] = df[col].map(\n",
    "                    self.target_encoders[col]\n",
    "                ).fillna(global_mean)\n",
    "\n",
    "        return new_features\n",
    "\n",
    "\n",
    "class AdvancedFeatureSelector:\n",
    "    \"\"\"\n",
    "    高级特征选择\n",
    "\n",
    "    【是什么】：选择最有价值的特征\n",
    "    【方法】：\n",
    "        - 基于重要性（XGBoost特征重要性）\n",
    "        - 基于相关性（去除冗余特征）\n",
    "        - 基于统计检验（卡方、互信息）\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.selected_features = None\n",
    "\n",
    "    def select_by_importance(self, X, y, feature_names, top_k=50, method='xgboost'):\n",
    "        \"\"\"\n",
    "        基于重要性选择特征\n",
    "\n",
    "        【原理】：训练模型，根据特征重要性排序\n",
    "        \"\"\"\n",
    "        print(f\"\\n基于{method}重要性选择特征...\")\n",
    "\n",
    "        if method == 'xgboost':\n",
    "            import xgboost as xgb\n",
    "\n",
    "            # 训练XGBoost\n",
    "            model = xgb.XGBClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=5,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "            model.fit(X, y)\n",
    "\n",
    "            # 获取重要性\n",
    "            importance = model.feature_importances_\n",
    "\n",
    "        else:  # mutual_info\n",
    "            importance = mutual_info_classif(X, y, random_state=42)\n",
    "\n",
    "        # 排序\n",
    "        indices = np.argsort(importance)[::-1][:top_k]\n",
    "        self.selected_features = [feature_names[i] for i in indices]\n",
    "\n",
    "        print(f\"  选择了 {len(self.selected_features)} 个特征\")\n",
    "        return self.selected_features, importance[indices]\n",
    "\n",
    "    def remove_correlated_features(self, X, feature_names, threshold=0.95):\n",
    "        \"\"\"\n",
    "        去除高度相关的特征\n",
    "\n",
    "        【为什么】：\n",
    "            - 减少冗余\n",
    "            - 降低过拟合风险\n",
    "            - 提高训练速度\n",
    "        \"\"\"\n",
    "        print(f\"\\n去除相关性 > {threshold} 的特征...\")\n",
    "\n",
    "        # 计算相关矩阵\n",
    "        corr_matrix = pd.DataFrame(X, columns=feature_names).corr().abs()\n",
    "\n",
    "        # 找到高度相关的特征对\n",
    "        upper = corr_matrix.where(\n",
    "            np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "        )\n",
    "\n",
    "        # 删除相关性高的特征\n",
    "        to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "\n",
    "        remaining_features = [f for f in feature_names if f not in to_drop]\n",
    "\n",
    "        print(f\"  删除了 {len(to_drop)} 个高度相关的特征\")\n",
    "        print(f\"  保留了 {len(remaining_features)} 个特征\")\n",
    "\n",
    "        return remaining_features\n",
    "\n",
    "\n",
    "def load_california_housing_data():\n",
    "    \"\"\"\n",
    "    加载California Housing数据集\n",
    "\n",
    "    【是什么】：加州房价预测数据集\n",
    "    【任务】：回归任务\n",
    "    \"\"\"\n",
    "    print(\"\\n加载California Housing数据集...\")\n",
    "\n",
    "    data = fetch_california_housing(as_frame=True)\n",
    "    df = data.frame\n",
    "\n",
    "    X = df.drop('MedHouseVal', axis=1)\n",
    "    y = df['MedHouseVal']\n",
    "\n",
    "    print(f\"  样本数: {len(df)}\")\n",
    "    print(f\"  特征数: {X.shape[1]}\")\n",
    "    print(f\"  特征: {list(X.columns)}\")\n",
    "\n",
    "    return X, y, list(X.columns)\n",
    "\n",
    "\n",
    "def prepare_advanced_features(\n",
    "    X, y,\n",
    "    task_type='classification',\n",
    "    create_interactions=True,\n",
    "    create_polynomials=True,\n",
    "    create_statistical=True,\n",
    "    target_encoding=False,\n",
    "    feature_selection=True,\n",
    "    top_k_features=100\n",
    "):\n",
    "    \"\"\"\n",
    "    准备高级特征\n",
    "\n",
    "    【完整流程】：\n",
    "    1. 特征工程（统计、交互、多项式）\n",
    "    2. 特征选择\n",
    "    3. 数据划分\n",
    "\n",
    "    Args:\n",
    "        X: 原始特征\n",
    "        y: 目标变量\n",
    "        task_type: 任务类型 ('classification' 或 'regression')\n",
    "        create_interactions: 是否创建交互特征\n",
    "        create_polynomials: 是否创建多项式特征\n",
    "        create_statistical: 是否创建统计特征\n",
    "        target_encoding: 是否使用目标编码\n",
    "        feature_selection: 是否进行特征选择\n",
    "        top_k_features: 保留的特征数\n",
    "\n",
    "    Returns:\n",
    "        (X_train, y_train), (X_test, y_test), feature_names\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"高级特征工程\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 转换为DataFrame\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        X = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])\n",
    "\n",
    "    if not isinstance(y, pd.Series):\n",
    "        y = pd.Series(y, name='target')\n",
    "\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    # ============================================\n",
    "    # 1. 特征工程\n",
    "    # ============================================\n",
    "    feature_engineer = AdvancedFeatureEngineering()\n",
    "    all_features = [X.copy()]\n",
    "\n",
    "    if create_statistical and len(numeric_cols) > 1:\n",
    "        stat_features = feature_engineer.create_statistical_features(X, numeric_cols)\n",
    "        all_features.append(stat_features)\n",
    "\n",
    "    if create_interactions and len(numeric_cols) > 1:\n",
    "        interaction_features = feature_engineer.create_interaction_features(\n",
    "            X, numeric_cols, max_interactions=20\n",
    "        )\n",
    "        all_features.append(interaction_features)\n",
    "\n",
    "    if create_polynomials and len(numeric_cols) > 0:\n",
    "        poly_features = feature_engineer.create_polynomial_features(\n",
    "            X, numeric_cols, degree=2, max_features=5\n",
    "        )\n",
    "        all_features.append(poly_features)\n",
    "\n",
    "    # 合并所有特征\n",
    "    X_engineered = pd.concat(all_features, axis=1)\n",
    "\n",
    "    print(f\"\\n特征工程后:\")\n",
    "    print(f\"  原始特征数: {X.shape[1]}\")\n",
    "    print(f\"  工程后特征数: {X_engineered.shape[1]}\")\n",
    "\n",
    "    # ============================================\n",
    "    # 2. 特征选择\n",
    "    # ============================================\n",
    "    if feature_selection and X_engineered.shape[1] > top_k_features:\n",
    "        selector = AdvancedFeatureSelector()\n",
    "\n",
    "        # 转换为numpy数组\n",
    "        X_array = X_engineered.values\n",
    "        y_array = y.values\n",
    "\n",
    "        # 选择特征\n",
    "        selected_features, importance = selector.select_by_importance(\n",
    "            X_array, y_array,\n",
    "            X_engineered.columns.tolist(),\n",
    "            top_k=top_k_features,\n",
    "            method='xgboost' if task_type == 'classification' else 'mutual_info'\n",
    "        )\n",
    "\n",
    "        X_selected = X_engineered[selected_features]\n",
    "\n",
    "        print(f\"\\n特征选择后:\")\n",
    "        print(f\"  保留特征数: {len(selected_features)}\")\n",
    "\n",
    "    else:\n",
    "        X_selected = X_engineered\n",
    "        selected_features = X_engineered.columns.tolist()\n",
    "\n",
    "    # ============================================\n",
    "    # 3. 数据划分\n",
    "    # ============================================\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_selected, y,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y if task_type == 'classification' else None\n",
    "    )\n",
    "\n",
    "    print(f\"\\n数据划分:\")\n",
    "    print(f\"  训练集: {X_train.shape}\")\n",
    "    print(f\"  测试集: {X_test.shape}\")\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test), selected_features\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \"\"\"测试数据处理模块\"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBoost高级技巧 - 数据处理测试\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 加载数据\n",
    "    X, y, feature_names = load_california_housing_data()\n",
    "\n",
    "    # 转换为分类任务（简化测试）\n",
    "    y_binary = (y > y.median()).astype(int)\n",
    "\n",
    "    # 准备高级特征\n",
    "    (X_train, y_train), (X_test, y_test), selected_features = \\\n",
    "        prepare_advanced_features(\n",
    "            X, y_binary,\n",
    "            task_type='classification',\n",
    "            create_interactions=True,\n",
    "            create_polynomials=True,\n",
    "            create_statistical=True,\n",
    "            feature_selection=True,\n",
    "            top_k_features=50\n",
    "        )\n",
    "\n",
    "    print(\"\\n✓ 数据处理测试通过！\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
