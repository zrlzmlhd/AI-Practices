{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "800b0c1d",
   "metadata": {},
   "source": [
    "# XGBoost高级技巧训练脚本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817f64f8",
   "metadata": {},
   "source": [
    "\n",
    "使用方法:\n",
    "    python src/train.py --mode basic\n",
    "    python src/train.py --mode optimize --n_trials 50\n",
    "    python src/train.py --mode ensemble --n_models 5\n",
    "\n",
    "【训练模式】:\n",
    "- basic: 基础训练\n",
    "- optimize: 超参数优化\n",
    "- ensemble: 集成模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e61032",
   "metadata": {},
   "source": [
    "## 高级训练流程\n",
    "1. 通过参数单元选择 basic/optimize/ensemble 模式, 并配置特征工程（交互/多项式/统计/特征选择）。\n",
    "2. 数据加载后先转换为二分类任务, 再执行高级特征工程与 train/val/test 划分。\n",
    "3. basic 模式直接训练, optimize 模式调用 Optuna 搜索, ensemble 模式训练多个模型并做平均。\n",
    "4. Notebook 生成训练历史、特征重要性、优化历史等可视化, 并将模型/日志写入磁盘。\n",
    "\n",
    "> **实践提示**: 可在 Notebook 中逐步增开功能, 观察各技巧对验证集 AUC/Accuracy 的影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba987b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook路径自适应处理\n",
    "import pathlib as _nb_pathlib\n",
    "def _nb_resolve_file_path():\n",
    "    if '__file__' not in globals():\n",
    "        _cwd = _nb_pathlib.Path.cwd().resolve()\n",
    "        for _candidate in (_cwd, *_cwd.parents):\n",
    "            _potential = _candidate / '09-practical-projects/01_机器学习基础项目/04_XGBoost高级技巧_高级/src/train.py'\n",
    "            if _potential.exists():\n",
    "                globals()['__file__'] = str(_potential)\n",
    "                return\n",
    "        globals()['__file__'] = str((_cwd / '09-practical-projects/01_机器学习基础项目/04_XGBoost高级技巧_高级/src/train.py').resolve())\n",
    "_nb_resolve_file_path()\n",
    "del _nb_pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01032cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "XGBoost高级技巧训练脚本\n",
    "\n",
    "使用方法:\n",
    "    python src/train.py --mode basic\n",
    "    python src/train.py --mode optimize --n_trials 50\n",
    "    python src/train.py --mode ensemble --n_models 5\n",
    "\n",
    "【训练模式】:\n",
    "- basic: 基础训练\n",
    "- optimize: 超参数优化\n",
    "- ensemble: 集成模型\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "project_root = Path(__file__).parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.data import load_california_housing_data, prepare_advanced_features\n",
    "from src.model import AdvancedXGBoostClassifier, XGBoostHyperparameterOptimizer, XGBoostEnsemble\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"解析命令行参数\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='训练XGBoost高级模型')\n",
    "\n",
    "    # 训练模式\n",
    "    parser.add_argument('--mode', type=str, default='basic',\n",
    "                       choices=['basic', 'optimize', 'ensemble'],\n",
    "                       help='训练模式')\n",
    "\n",
    "    # 特征工程\n",
    "    parser.add_argument('--create_interactions', action='store_true', default=True,\n",
    "                       help='创建交互特征')\n",
    "    parser.add_argument('--create_polynomials', action='store_true', default=True,\n",
    "                       help='创建多项式特征')\n",
    "    parser.add_argument('--create_statistical', action='store_true', default=True,\n",
    "                       help='创建统计特征')\n",
    "    parser.add_argument('--feature_selection', action='store_true', default=True,\n",
    "                       help='特征选择')\n",
    "    parser.add_argument('--top_k_features', type=int, default=100,\n",
    "                       help='保留的特征数')\n",
    "\n",
    "    # 优化参数\n",
    "    parser.add_argument('--n_trials', type=int, default=50,\n",
    "                       help='优化试验次数')\n",
    "\n",
    "    # 集成参数\n",
    "    parser.add_argument('--n_models', type=int, default=5,\n",
    "                       help='集成模型数量')\n",
    "\n",
    "    # 保存路径\n",
    "    parser.add_argument('--model_dir', type=str, default='models',\n",
    "                       help='模型保存目录')\n",
    "    parser.add_argument('--result_dir', type=str, default='results',\n",
    "                       help='结果保存目录')\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def plot_feature_importance(importance_df, save_path):\n",
    "    \"\"\"绘制特征重要性\"\"\"\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # 取前20个特征\n",
    "    top_features = importance_df.head(20)\n",
    "\n",
    "    plt.barh(range(len(top_features)), top_features['importance'], color='steelblue', alpha=0.8)\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('重要性（Gain）', fontsize=12, fontweight='bold')\n",
    "    plt.title('Top 20 特征重要性', fontsize=14, fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(True, alpha=0.3, axis='x')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"✓ 特征重要性图已保存: {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_training_history(evals_result, save_path):\n",
    "    \"\"\"绘制训练历史\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # 训练集\n",
    "    if 'train' in evals_result:\n",
    "        metric_name = list(evals_result['train'].keys())[0]\n",
    "        train_scores = evals_result['train'][metric_name]\n",
    "        ax.plot(train_scores, label='训练集', linewidth=2)\n",
    "\n",
    "    # 验证集\n",
    "    if 'val' in evals_result:\n",
    "        metric_name = list(evals_result['val'].keys())[0]\n",
    "        val_scores = evals_result['val'][metric_name]\n",
    "        ax.plot(val_scores, label='验证集', linewidth=2)\n",
    "\n",
    "    ax.set_xlabel('迭代次数', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel(metric_name.upper(), fontsize=12, fontweight='bold')\n",
    "    ax.set_title('训练历史', fontsize=14, fontweight='bold')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"✓ 训练历史图已保存: {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_optimization_history(history_df, save_path):\n",
    "    \"\"\"绘制优化历史\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # 优化过程\n",
    "    axes[0].plot(history_df['trial'], history_df['value'], marker='o', linewidth=2)\n",
    "    axes[0].set_xlabel('试验次数', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_ylabel('分数', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_title('优化过程', fontsize=14, fontweight='bold')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    # 最佳分数累积\n",
    "    best_scores = history_df['value'].cummax()\n",
    "    axes[1].plot(history_df['trial'], best_scores, marker='o', linewidth=2, color='green')\n",
    "    axes[1].set_xlabel('试验次数', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('最佳分数', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_title('最佳分数演化', fontsize=14, fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"✓ 优化历史图已保存: {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"主训练流程\"\"\"\n",
    "    args = parse_args()\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBoost高级技巧 - 模型训练\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\n训练配置:\")\n",
    "    print(f\"  训练模式: {args.mode}\")\n",
    "    print(f\"  特征工程: 交互={args.create_interactions}, 多项式={args.create_polynomials}, 统计={args.create_statistical}\")\n",
    "    print(f\"  特征选择: {args.feature_selection} (Top {args.top_k_features})\")\n",
    "\n",
    "    # 创建保存目录\n",
    "    project_dir = Path(__file__).parent.parent\n",
    "    model_dir = project_dir / args.model_dir\n",
    "    result_dir = project_dir / args.result_dir\n",
    "    model_dir.mkdir(exist_ok=True)\n",
    "    result_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # ============================================\n",
    "    # 1. 准备数据\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤1: 数据准备\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 加载数据\n",
    "    X, y, feature_names = load_california_housing_data()\n",
    "\n",
    "    # 转换为二分类任务\n",
    "    y_binary = (y > y.median()).astype(int)\n",
    "    print(f\"\\n转换为二分类任务:\")\n",
    "    print(f\"  类别0（低房价）: {np.sum(y_binary == 0)}\")\n",
    "    print(f\"  类别1（高房价）: {np.sum(y_binary == 1)}\")\n",
    "\n",
    "    # 高级特征工程\n",
    "    (X_train, y_train), (X_test, y_test), selected_features = \\\n",
    "        prepare_advanced_features(\n",
    "            X, y_binary,\n",
    "            task_type='classification',\n",
    "            create_interactions=args.create_interactions,\n",
    "            create_polynomials=args.create_polynomials,\n",
    "            create_statistical=args.create_statistical,\n",
    "            feature_selection=args.feature_selection,\n",
    "            top_k_features=args.top_k_features\n",
    "        )\n",
    "\n",
    "    # 进一步划分验证集\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_train\n",
    "    )\n",
    "\n",
    "    print(f\"\\n最终数据划分:\")\n",
    "    print(f\"  训练集: {X_train.shape}\")\n",
    "    print(f\"  验证集: {X_val.shape}\")\n",
    "    print(f\"  测试集: {X_test.shape}\")\n",
    "\n",
    "    # 保存特征名称\n",
    "    features_path = model_dir / 'selected_features.pkl'\n",
    "    with open(features_path, 'wb') as f:\n",
    "        pickle.dump(selected_features, f)\n",
    "\n",
    "    # ============================================\n",
    "    # 2. 训练模型\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤2: 训练模型\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    if args.mode == 'basic':\n",
    "        # ============================================\n",
    "        # 基础训练\n",
    "        # ============================================\n",
    "        print(\"\\n基础XGBoost训练...\")\n",
    "\n",
    "        model = AdvancedXGBoostClassifier()\n",
    "        evals_result = model.fit(\n",
    "            X_train.values, y_train.values,\n",
    "            X_val.values, y_val.values,\n",
    "            early_stopping_rounds=50,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        # 保存模型\n",
    "        model_path = model_dir / 'xgboost_basic_model.json'\n",
    "        model.save_model(model_path)\n",
    "\n",
    "        # 绘制训练历史\n",
    "        history_path = result_dir / 'training_history.png'\n",
    "        plot_training_history(evals_result, history_path)\n",
    "\n",
    "        # 特征重要性\n",
    "        importance = model.get_feature_importance(selected_features, top_n=20)\n",
    "        if importance is not None:\n",
    "            importance_path = result_dir / 'feature_importance.png'\n",
    "            plot_feature_importance(importance, importance_path)\n",
    "\n",
    "            # 保存重要性数据\n",
    "            importance.to_csv(result_dir / 'feature_importance.csv', index=False)\n",
    "\n",
    "    elif args.mode == 'optimize':\n",
    "        # ============================================\n",
    "        # 超参数优化\n",
    "        # ============================================\n",
    "        print(f\"\\n超参数优化（{args.n_trials}次试验）...\")\n",
    "\n",
    "        optimizer = XGBoostHyperparameterOptimizer(\n",
    "            task_type='classification',\n",
    "            n_trials=args.n_trials,\n",
    "            cv=5\n",
    "        )\n",
    "\n",
    "        best_params = optimizer.optimize(\n",
    "            X_train.values, y_train.values,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        # 保存最佳参数\n",
    "        params_path = model_dir / 'best_params.pkl'\n",
    "        with open(params_path, 'wb') as f:\n",
    "            pickle.dump(best_params, f)\n",
    "        print(f\"✓ 最佳参数已保存: {params_path}\")\n",
    "\n",
    "        # 使用最佳参数训练最终模型\n",
    "        print(\"\\n使用最佳参数训练最终模型...\")\n",
    "        model = AdvancedXGBoostClassifier(params=best_params)\n",
    "        evals_result = model.fit(\n",
    "            X_train.values, y_train.values,\n",
    "            X_val.values, y_val.values,\n",
    "            early_stopping_rounds=50,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        # 保存模型\n",
    "        model_path = model_dir / 'xgboost_optimized_model.json'\n",
    "        model.save_model(model_path)\n",
    "\n",
    "        # 绘制优化历史\n",
    "        history = optimizer.get_optimization_history()\n",
    "        opt_history_path = result_dir / 'optimization_history.png'\n",
    "        plot_optimization_history(history, opt_history_path)\n",
    "\n",
    "        # 保存优化历史\n",
    "        history.to_csv(result_dir / 'optimization_history.csv', index=False)\n",
    "\n",
    "    elif args.mode == 'ensemble':\n",
    "        # ============================================\n",
    "        # 集成模型\n",
    "        # ============================================\n",
    "        print(f\"\\n训练集成模型（{args.n_models}个基模型）...\")\n",
    "\n",
    "        ensemble = XGBoostEnsemble(\n",
    "            n_models=args.n_models,\n",
    "            ensemble_method='bagging'\n",
    "        )\n",
    "\n",
    "        ensemble.fit(\n",
    "            X_train.values, y_train.values,\n",
    "            X_val.values, y_val.values,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        # 保存集成模型\n",
    "        model_path = model_dir / 'xgboost_ensemble_model.pkl'\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(ensemble, f)\n",
    "        print(f\"✓ 集成模型已保存: {model_path}\")\n",
    "\n",
    "        model = ensemble\n",
    "\n",
    "    # ============================================\n",
    "    # 3. 评估模型\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤3: 评估模型\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "\n",
    "    # 验证集评估\n",
    "    y_val_pred = model.predict(X_val.values)\n",
    "    y_val_proba = model.predict_proba(X_val.values)[:, 1]\n",
    "\n",
    "    val_accuracy = accuracy_score(y_val.values, y_val_pred)\n",
    "    val_auc = roc_auc_score(y_val.values, y_val_proba)\n",
    "\n",
    "    print(f\"\\n验证集性能:\")\n",
    "    print(f\"  准确率: {val_accuracy:.4f}\")\n",
    "    print(f\"  AUC: {val_auc:.4f}\")\n",
    "\n",
    "    # 测试集评估\n",
    "    y_test_pred = model.predict(X_test.values)\n",
    "    y_test_proba = model.predict_proba(X_test.values)[:, 1]\n",
    "\n",
    "    test_accuracy = accuracy_score(y_test.values, y_test_pred)\n",
    "    test_auc = roc_auc_score(y_test.values, y_test_proba)\n",
    "\n",
    "    print(f\"\\n测试集性能:\")\n",
    "    print(f\"  准确率: {test_accuracy:.4f}\")\n",
    "    print(f\"  AUC: {test_auc:.4f}\")\n",
    "\n",
    "    # 分类报告\n",
    "    report = classification_report(y_test.values, y_test_pred, target_names=['低房价', '高房价'])\n",
    "    print(f\"\\n分类报告:\")\n",
    "    print(report)\n",
    "\n",
    "    # ============================================\n",
    "    # 4. 保存结果\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤4: 保存结果\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    results_path = result_dir / 'training_results.txt'\n",
    "    with open(results_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(\"XGBoost高级技巧 - 训练结果\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "\n",
    "        f.write(f\"训练模式: {args.mode}\\n\\n\")\n",
    "\n",
    "        f.write(\"验证集性能:\\n\")\n",
    "        f.write(f\"  准确率: {val_accuracy:.4f}\\n\")\n",
    "        f.write(f\"  AUC: {val_auc:.4f}\\n\\n\")\n",
    "\n",
    "        f.write(\"测试集性能:\\n\")\n",
    "        f.write(f\"  准确率: {test_accuracy:.4f}\\n\")\n",
    "        f.write(f\"  AUC: {test_auc:.4f}\\n\\n\")\n",
    "\n",
    "        f.write(\"分类报告:\\n\")\n",
    "        f.write(report)\n",
    "\n",
    "    print(f\"✓ 训练结果已保存: {results_path}\")\n",
    "\n",
    "    # ============================================\n",
    "    # 总结\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"训练总结\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"✓ 模型已保存: {model_path}\")\n",
    "    print(f\"✓ 特征名称已保存: {features_path}\")\n",
    "    print(f\"✓ 测试集准确率: {test_accuracy:.4f}\")\n",
    "    print(f\"✓ 测试集AUC: {test_auc:.4f}\")\n",
    "    print(f\"\\n使用以下命令进行评估:\")\n",
    "    print(f\"  python src/evaluate.py --model_path {model_path} --features_path {features_path}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 设置随机种子\n",
    "    np.random.seed(42)\n",
    "\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
