{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b992775",
   "metadata": {},
   "source": [
    "# 模型评估脚本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d561b3",
   "metadata": {},
   "source": [
    "\n",
    "使用方法:\n",
    "    python src/evaluate.py --model_path models/xgboost_tuned_model.pkl --processor_path models/xgboost_tuned_processor.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951e5cca",
   "metadata": {},
   "source": [
    "## 评估诊断\n",
    "- 载入模型与 processor, 重新构建特征后计算预测概率。\n",
    "- 绘制混淆矩阵、类别粒度的 Precision/Recall/F1 柱状图, 并输出 `classification_report`。\n",
    "- `plot_probability_distribution` 对每个类别展示正确/错误预测概率分布, `analyze_errors` 记录最自信的错误示例。\n",
    "\n",
    "> **核心提示**: 多分类分析重点在 class-wise 指标, Notebook 允许随时调整 `num_examples` 观察最脆弱的类别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee97b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook路径自适应处理\n",
    "import pathlib as _nb_pathlib\n",
    "def _nb_resolve_file_path():\n",
    "    if '__file__' not in globals():\n",
    "        _cwd = _nb_pathlib.Path.cwd().resolve()\n",
    "        for _candidate in (_cwd, *_cwd.parents):\n",
    "            _potential = _candidate / '09-practical-projects/01_机器学习基础项目/02_Otto分类挑战_XGBoost中级/src/evaluate.py'\n",
    "            if _potential.exists():\n",
    "                globals()['__file__'] = str(_potential)\n",
    "                return\n",
    "        globals()['__file__'] = str((_cwd / '09-practical-projects/01_机器学习基础项目/02_Otto分类挑战_XGBoost中级/src/evaluate.py').resolve())\n",
    "_nb_resolve_file_path()\n",
    "del _nb_pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecc96f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "模型评估脚本\n",
    "\n",
    "使用方法:\n",
    "    python src/evaluate.py --model_path models/xgboost_tuned_model.pkl --processor_path models/xgboost_tuned_processor.pkl\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pickle\n",
    "\n",
    "# 添加项目根目录到路径\n",
    "project_root = Path(__file__).parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.data import prepare_otto_data\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"解析命令行参数\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='评估Otto分类模型')\n",
    "\n",
    "    parser.add_argument('--model_path', type=str, required=True,\n",
    "                       help='模型文件路径')\n",
    "    parser.add_argument('--processor_path', type=str, required=True,\n",
    "                       help='数据处理器文件路径')\n",
    "    parser.add_argument('--data_path', type=str, default='data/train.csv',\n",
    "                       help='数据文件路径')\n",
    "    parser.add_argument('--result_dir', type=str, default='results',\n",
    "                       help='结果保存目录')\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, save_path=None):\n",
    "    \"\"\"绘制混淆矩阵\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names,\n",
    "                yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix', fontsize=14, pad=15)\n",
    "    plt.ylabel('True Label', fontsize=12)\n",
    "    plt.xlabel('Predicted Label', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"✓ 混淆矩阵已保存: {save_path}\")\n",
    "\n",
    "    return cm\n",
    "\n",
    "\n",
    "def plot_class_performance(y_true, y_pred, class_names, save_path=None):\n",
    "    \"\"\"绘制各类别性能\"\"\"\n",
    "    from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "\n",
    "    for i in range(len(class_names)):\n",
    "        y_true_binary = (y_true == i).astype(int)\n",
    "        y_pred_binary = (y_pred == i).astype(int)\n",
    "\n",
    "        precisions.append(precision_score(y_true_binary, y_pred_binary, zero_division=0))\n",
    "        recalls.append(recall_score(y_true_binary, y_pred_binary, zero_division=0))\n",
    "        f1s.append(f1_score(y_true_binary, y_pred_binary, zero_division=0))\n",
    "\n",
    "    x = np.arange(len(class_names))\n",
    "    width = 0.25\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    ax.bar(x - width, precisions, width, label='Precision', alpha=0.8)\n",
    "    ax.bar(x, recalls, width, label='Recall', alpha=0.8)\n",
    "    ax.bar(x + width, f1s, width, label='F1-Score', alpha=0.8)\n",
    "\n",
    "    ax.set_xlabel('Class', fontsize=12)\n",
    "    ax.set_ylabel('Score', fontsize=12)\n",
    "    ax.set_title('Performance by Class', fontsize=14)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(class_names, rotation=45)\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"✓ 类别性能图已保存: {save_path}\")\n",
    "\n",
    "\n",
    "def plot_probability_distribution(y_proba, y_true, save_path=None):\n",
    "    \"\"\"绘制预测概率分布\"\"\"\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(9):\n",
    "        ax = axes[i]\n",
    "\n",
    "        # 正确预测的概率\n",
    "        correct_mask = (y_true == i)\n",
    "        correct_probs = y_proba[correct_mask, i]\n",
    "\n",
    "        # 错误预测的概率\n",
    "        incorrect_mask = (y_true != i)\n",
    "        incorrect_probs = y_proba[incorrect_mask, i]\n",
    "\n",
    "        ax.hist(correct_probs, bins=30, alpha=0.6, label='Correct', color='green')\n",
    "        ax.hist(incorrect_probs, bins=30, alpha=0.6, label='Incorrect', color='red')\n",
    "\n",
    "        ax.set_xlabel('Probability', fontsize=10)\n",
    "        ax.set_ylabel('Count', fontsize=10)\n",
    "        ax.set_title(f'Class {i+1}', fontsize=11)\n",
    "        ax.legend()\n",
    "        ax.grid(alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"✓ 概率分布图已保存: {save_path}\")\n",
    "\n",
    "\n",
    "def analyze_errors(X_test, y_test, y_pred, y_proba, processor, num_examples=10):\n",
    "    \"\"\"分析错误样本\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"错误样本分析\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 找出错误样本\n",
    "    error_indices = np.where(y_pred != y_test)[0]\n",
    "    print(f\"\\n错误样本数量: {len(error_indices)} / {len(y_test)} ({len(error_indices)/len(y_test)*100:.2f}%)\")\n",
    "\n",
    "    if len(error_indices) == 0:\n",
    "        print(\"没有错误样本！\")\n",
    "        return\n",
    "\n",
    "    # 按置信度排序错误样本\n",
    "    error_confidence = np.max(y_proba[error_indices], axis=1)\n",
    "    sorted_indices = error_indices[np.argsort(-error_confidence)]\n",
    "\n",
    "    # 显示最自信的错误样本\n",
    "    print(f\"\\n最自信的 {min(num_examples, len(sorted_indices))} 个错误样本:\")\n",
    "    for i, idx in enumerate(sorted_indices[:num_examples]):\n",
    "        true_label = processor.inverse_transform_labels([y_test[idx]])[0]\n",
    "        pred_label = processor.inverse_transform_labels([y_pred[idx]])[0]\n",
    "        confidence = y_proba[idx].max()\n",
    "        pred_class = y_proba[idx].argmax()\n",
    "\n",
    "        print(f\"\\n错误样本 {i+1}:\")\n",
    "        print(f\"  真实标签: {true_label}\")\n",
    "        print(f\"  预测标签: {pred_label}\")\n",
    "        print(f\"  预测置信度: {confidence:.4f}\")\n",
    "        print(f\"  预测概率分布: {y_proba[idx]}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    # 解析参数\n",
    "    args = parse_args()\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(\"Otto分类 - 模型评估\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\n模型路径: {args.model_path}\")\n",
    "    print(f\"数据处理器路径: {args.processor_path}\")\n",
    "\n",
    "    # 创建结果目录\n",
    "    project_dir = Path(__file__).parent.parent\n",
    "    result_dir = project_dir / args.result_dir\n",
    "    result_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # ============================================\n",
    "    # 步骤1: 加载数据处理器\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤1: 加载数据处理器\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    with open(args.processor_path, 'rb') as f:\n",
    "        processor_data = pickle.load(f)\n",
    "\n",
    "    print(f\"✓ 数据处理器已加载\")\n",
    "\n",
    "    # ============================================\n",
    "    # 步骤2: 准备数据\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤2: 准备数据\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    try:\n",
    "        (X_train, y_train), (X_val, y_val), (X_test, y_test), processor = prepare_otto_data(\n",
    "            data_path=args.data_path\n",
    "        )\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\n✗ 数据文件不存在: {e}\")\n",
    "        return\n",
    "\n",
    "    # ============================================\n",
    "    # 步骤3: 加载模型\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤3: 加载模型\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    with open(args.model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    print(f\"✓ 模型已加载\")\n",
    "\n",
    "    # ============================================\n",
    "    # 步骤4: 预测\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤4: 模型预测\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    print(\"\\n预测测试集...\")\n",
    "\n",
    "    # 根据模型类型选择预测方法\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_pred_proba = model.predict_proba(X_test)\n",
    "        y_pred = model.predict(X_test)\n",
    "    else:\n",
    "        # LightGBM模型\n",
    "        y_pred_proba = model.predict(X_test)\n",
    "        y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "    # ============================================\n",
    "    # 步骤5: 计算评估指标\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤5: 计算评估指标\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    logloss = log_loss(y_test, y_pred_proba)\n",
    "\n",
    "    print(f\"\\n测试集性能:\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  Log Loss: {logloss:.4f}\")\n",
    "\n",
    "    # 详细分类报告\n",
    "    class_names = processor.label_encoder.classes_\n",
    "    print(f\"\\n分类报告:\")\n",
    "    print(classification_report(y_test, y_pred,\n",
    "                               target_names=class_names,\n",
    "                               digits=4))\n",
    "\n",
    "    # ============================================\n",
    "    # 步骤6: 绘制混淆矩阵\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤6: 绘制混淆矩阵\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    model_name = Path(args.model_path).stem\n",
    "    cm_path = result_dir / f'{model_name}_confusion_matrix.png'\n",
    "    cm = plot_confusion_matrix(y_test, y_pred, class_names, cm_path)\n",
    "\n",
    "    # ============================================\n",
    "    # 步骤7: 绘制类别性能\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤7: 绘制类别性能\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    perf_path = result_dir / f'{model_name}_class_performance.png'\n",
    "    plot_class_performance(y_test, y_pred, class_names, perf_path)\n",
    "\n",
    "    # ============================================\n",
    "    # 步骤8: 绘制概率分布\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤8: 绘制概率分布\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    prob_path = result_dir / f'{model_name}_probability_distribution.png'\n",
    "    plot_probability_distribution(y_pred_proba, y_test, prob_path)\n",
    "\n",
    "    # ============================================\n",
    "    # 步骤9: 错误分析\n",
    "    # ============================================\n",
    "    analyze_errors(X_test, y_test, y_pred, y_pred_proba, processor, num_examples=10)\n",
    "\n",
    "    # ============================================\n",
    "    # 总结\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"评估完成！\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    print(f\"\\n生成的文件:\")\n",
    "    print(f\"  1. 混淆矩阵: {cm_path}\")\n",
    "    print(f\"  2. 类别性能图: {perf_path}\")\n",
    "    print(f\"  3. 概率分布图: {prob_path}\")\n",
    "\n",
    "    print(f\"\\n模型性能总结:\")\n",
    "    print(f\"  准确率: {accuracy:.2%}\")\n",
    "    print(f\"  Log Loss: {logloss:.4f}\")\n",
    "\n",
    "    if logloss < 0.5:\n",
    "        print(f\"\\n  ✓✓ 模型性能优秀！\")\n",
    "    elif logloss < 0.6:\n",
    "        print(f\"\\n  ✓ 模型性能良好\")\n",
    "    else:\n",
    "        print(f\"\\n  ⚠ 模型性能有待提升\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
