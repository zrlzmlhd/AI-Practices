{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f40c699e",
   "metadata": {},
   "source": [
    "# Otto分类模型训练脚本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19fabc0",
   "metadata": {},
   "source": [
    "\n",
    "使用方法:\n",
    "    python src/train.py --model_type xgboost_basic\n",
    "    python src/train.py --model_type xgboost_tuned\n",
    "    python src/train.py --model_type lightgbm\n",
    "    python src/train.py --model_type catboost\n",
    "    python src/train.py --model_type stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b598f0e7",
   "metadata": {},
   "source": [
    "## 训练流水线\n",
    "1. 交互式配置 `model_type`、是否构建高级特征等参数, 并打印到输出。\n",
    "2. 调用 `prepare_otto_data` 获得 train/val/test 与 processor, Notebook 中示例如何保存处理器以便推理阶段重用。\n",
    "3. 根据模型类型实例化对应分类器, 通过早停或自定义训练逻辑完成拟合。\n",
    "4. 统一汇报训练/验证/测试 Accuracy 与 LogLoss, 其中 XGBoost 模型还附带特征重要性 CSV/图表。\n",
    "5. 将模型与结果写入 `models/` 与 `results/`, Notebook 中提供可视化建议。\n",
    "\n",
    "> **调参建议**: 建议先运行 tuned 版建立基线, 再尝试 advanced 或 stacking 模式, 便于在 Notebook 中观察收益。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de26fc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook路径自适应处理\n",
    "import pathlib as _nb_pathlib\n",
    "def _nb_resolve_file_path():\n",
    "    if '__file__' not in globals():\n",
    "        _cwd = _nb_pathlib.Path.cwd().resolve()\n",
    "        for _candidate in (_cwd, *_cwd.parents):\n",
    "            _potential = _candidate / '09-practical-projects/01_机器学习基础项目/02_Otto分类挑战_XGBoost中级/src/train.py'\n",
    "            if _potential.exists():\n",
    "                globals()['__file__'] = str(_potential)\n",
    "                return\n",
    "        globals()['__file__'] = str((_cwd / '09-practical-projects/01_机器学习基础项目/02_Otto分类挑战_XGBoost中级/src/train.py').resolve())\n",
    "_nb_resolve_file_path()\n",
    "del _nb_pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ee4912",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Otto分类模型训练脚本\n",
    "\n",
    "使用方法:\n",
    "    python src/train.py --model_type xgboost_basic\n",
    "    python src/train.py --model_type xgboost_tuned\n",
    "    python src/train.py --model_type lightgbm\n",
    "    python src/train.py --model_type catboost\n",
    "    python src/train.py --model_type stacking\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# 添加项目根目录到路径\n",
    "project_root = Path(__file__).parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.data import prepare_otto_data\n",
    "from src.model import (\n",
    "    OttoXGBoostClassifier,\n",
    "    OttoLightGBMClassifier,\n",
    "    OttoCatBoostClassifier,\n",
    "    OttoStackingEnsemble\n",
    ")\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"解析命令行参数\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='训练Otto分类模型')\n",
    "\n",
    "    # 模型参数\n",
    "    parser.add_argument('--model_type', type=str, default='xgboost_tuned',\n",
    "                       choices=['xgboost_basic', 'xgboost_tuned', 'xgboost_advanced',\n",
    "                               'lightgbm', 'catboost', 'stacking'],\n",
    "                       help='模型类型')\n",
    "\n",
    "    # 数据参数\n",
    "    parser.add_argument('--data_path', type=str, default='data/train.csv',\n",
    "                       help='数据文件路径')\n",
    "    parser.add_argument('--create_features', action='store_true',\n",
    "                       help='是否创建工程特征')\n",
    "\n",
    "    # 训练参数\n",
    "    parser.add_argument('--early_stopping_rounds', type=int, default=50,\n",
    "                       help='早停轮数')\n",
    "\n",
    "    # 其他参数\n",
    "    parser.add_argument('--random_state', type=int, default=42,\n",
    "                       help='随机种子')\n",
    "    parser.add_argument('--model_dir', type=str, default='models',\n",
    "                       help='模型保存目录')\n",
    "    parser.add_argument('--result_dir', type=str, default='results',\n",
    "                       help='结果保存目录')\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    # 解析参数\n",
    "    args = parse_args()\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(\"Otto分类 - 模型训练\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\n配置:\")\n",
    "    for arg, value in vars(args).items():\n",
    "        print(f\"  {arg}: {value}\")\n",
    "\n",
    "    # 设置随机种子\n",
    "    np.random.seed(args.random_state)\n",
    "\n",
    "    # 创建保存目录\n",
    "    project_dir = Path(__file__).parent.parent\n",
    "    model_dir = project_dir / args.model_dir\n",
    "    result_dir = project_dir / args.result_dir\n",
    "    model_dir.mkdir(exist_ok=True)\n",
    "    result_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # ============================================\n",
    "    # 步骤1: 准备数据\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤1: 准备数据\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    try:\n",
    "        (X_train, y_train), (X_val, y_val), (X_test, y_test), processor = prepare_otto_data(\n",
    "            data_path=args.data_path,\n",
    "            create_features=args.create_features,\n",
    "            random_state=args.random_state\n",
    "        )\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"\\n✗ 数据文件不存在: {e}\")\n",
    "        print(\"\\n请先下载数据:\")\n",
    "        print(\"  cd data\")\n",
    "        print(\"  python download_data.py\")\n",
    "        return\n",
    "\n",
    "    # 保存数据处理器\n",
    "    processor_path = model_dir / f'{args.model_type}_processor.pkl'\n",
    "    processor.save_processor(processor_path)\n",
    "\n",
    "    # ============================================\n",
    "    # 步骤2: 创建模型\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤2: 创建模型\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    n_classes = len(np.unique(y_train))\n",
    "\n",
    "    if args.model_type.startswith('xgboost'):\n",
    "        model_variant = args.model_type.split('_')[1]  # basic/tuned/advanced\n",
    "        classifier = OttoXGBoostClassifier(n_classes, model_type=model_variant)\n",
    "        print(f\"创建XGBoost模型 ({model_variant})\")\n",
    "\n",
    "    elif args.model_type == 'lightgbm':\n",
    "        classifier = OttoLightGBMClassifier(n_classes)\n",
    "        print(\"创建LightGBM模型\")\n",
    "\n",
    "    elif args.model_type == 'catboost':\n",
    "        classifier = OttoCatBoostClassifier(n_classes)\n",
    "        print(\"创建CatBoost模型\")\n",
    "\n",
    "    elif args.model_type == 'stacking':\n",
    "        classifier = OttoStackingEnsemble(n_classes)\n",
    "        print(\"创建Stacking集成模型\")\n",
    "\n",
    "    # ============================================\n",
    "    # 步骤3: 训练模型\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤3: 训练模型\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    print(f\"\\n开始训练...\")\n",
    "\n",
    "    if args.model_type == 'stacking':\n",
    "        # Stacking需要特殊的训练流程\n",
    "        classifier.train(X_train, y_train, X_val, y_val)\n",
    "    else:\n",
    "        # 单模型训练\n",
    "        if args.model_type.startswith('xgboost'):\n",
    "            classifier.train(\n",
    "                X_train, y_train,\n",
    "                X_val, y_val,\n",
    "                early_stopping_rounds=args.early_stopping_rounds,\n",
    "                verbose=True\n",
    "            )\n",
    "        elif args.model_type == 'lightgbm':\n",
    "            classifier.train(\n",
    "                X_train, y_train,\n",
    "                X_val, y_val,\n",
    "                early_stopping_rounds=args.early_stopping_rounds\n",
    "            )\n",
    "        elif args.model_type == 'catboost':\n",
    "            classifier.train(\n",
    "                X_train, y_train,\n",
    "                X_val, y_val,\n",
    "                early_stopping_rounds=args.early_stopping_rounds\n",
    "            )\n",
    "\n",
    "    # ============================================\n",
    "    # 步骤4: 评估模型\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤4: 评估模型\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 训练集评估\n",
    "    train_metrics = classifier.evaluate(X_train, y_train)\n",
    "    print(f\"\\n训练集性能:\")\n",
    "    print(f\"  Accuracy: {train_metrics['accuracy']:.4f}\")\n",
    "    print(f\"  Log Loss: {train_metrics['log_loss']:.4f}\")\n",
    "\n",
    "    # 验证集评估\n",
    "    val_metrics = classifier.evaluate(X_val, y_val)\n",
    "    print(f\"\\n验证集性能:\")\n",
    "    print(f\"  Accuracy: {val_metrics['accuracy']:.4f}\")\n",
    "    print(f\"  Log Loss: {val_metrics['log_loss']:.4f}\")\n",
    "\n",
    "    # 测试集评估\n",
    "    test_metrics = classifier.evaluate(X_test, y_test)\n",
    "    print(f\"\\n测试集性能:\")\n",
    "    print(f\"  Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "    print(f\"  Log Loss: {test_metrics['log_loss']:.4f}\")\n",
    "\n",
    "    # ============================================\n",
    "    # 步骤5: 特征重要性（仅XGBoost）\n",
    "    # ============================================\n",
    "    if args.model_type.startswith('xgboost'):\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"步骤5: 特征重要性分析\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "        importance_df = classifier.get_feature_importance(top_n=20)\n",
    "        print(f\"\\nTop 20 重要特征:\")\n",
    "        print(importance_df.to_string(index=False))\n",
    "\n",
    "        # 保存特征重要性\n",
    "        importance_path = result_dir / f'{args.model_type}_feature_importance.csv'\n",
    "        importance_df.to_csv(importance_path, index=False)\n",
    "        print(f\"\\n✓ 特征重要性已保存: {importance_path}\")\n",
    "\n",
    "    # ============================================\n",
    "    # 步骤6: 保存结果\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤6: 保存结果\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 保存模型\n",
    "    model_path = model_dir / f'{args.model_type}_model.pkl'\n",
    "    classifier.save_model(model_path)\n",
    "\n",
    "    # 保存评估结果\n",
    "    results = {\n",
    "        'model_type': args.model_type,\n",
    "        'n_classes': n_classes,\n",
    "        'n_features': X_train.shape[1],\n",
    "        'train_accuracy': train_metrics['accuracy'],\n",
    "        'train_log_loss': train_metrics['log_loss'],\n",
    "        'val_accuracy': val_metrics['accuracy'],\n",
    "        'val_log_loss': val_metrics['log_loss'],\n",
    "        'test_accuracy': test_metrics['accuracy'],\n",
    "        'test_log_loss': test_metrics['log_loss'],\n",
    "    }\n",
    "\n",
    "    results_path = result_dir / f'{args.model_type}_results.txt'\n",
    "    with open(results_path, 'w') as f:\n",
    "        for key, value in results.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "    print(f\"✓ 评估结果已保存: {results_path}\")\n",
    "\n",
    "    # ============================================\n",
    "    # 步骤7: 示例预测\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤7: 示例预测\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 随机选择几个测试样本\n",
    "    num_examples = 5\n",
    "    indices = np.random.choice(len(X_test), num_examples, replace=False)\n",
    "\n",
    "    print(f\"\\n随机选择 {num_examples} 个测试样本:\")\n",
    "    for i, idx in enumerate(indices):\n",
    "        x = X_test[idx:idx+1]\n",
    "        y_true = y_test[idx]\n",
    "        y_pred = classifier.predict(x)[0]\n",
    "        y_proba = classifier.predict_proba(x)[0]\n",
    "\n",
    "        # 转换回原始标签\n",
    "        true_label = processor.inverse_transform_labels([y_true])[0]\n",
    "        pred_label = processor.inverse_transform_labels([y_pred])[0]\n",
    "\n",
    "        print(f\"\\n样本 {i+1}:\")\n",
    "        print(f\"  真实标签: {true_label}\")\n",
    "        print(f\"  预测标签: {pred_label}\")\n",
    "        print(f\"  预测概率: {y_proba}\")\n",
    "        print(f\"  最高概率: {y_proba.max():.4f}\")\n",
    "        print(f\"  预测{'正确' if y_pred == y_true else '错误'}\")\n",
    "\n",
    "    # ============================================\n",
    "    # 总结\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"训练完成！\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\n模型保存路径: {model_path}\")\n",
    "    print(f\"数据处理器保存路径: {processor_path}\")\n",
    "    print(f\"\\n测试集性能:\")\n",
    "    print(f\"  Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "    print(f\"  Log Loss: {test_metrics['log_loss']:.4f}\")\n",
    "\n",
    "    # 给出建议\n",
    "    print(f\"\\n下一步:\")\n",
    "    print(f\"  1. 查看评估结果: {results_path}\")\n",
    "    print(f\"  2. 评估模型: python src/evaluate.py --model_path {model_path} --processor_path {processor_path}\")\n",
    "    print(f\"  3. 尝试其他模型:\")\n",
    "    print(f\"     python src/train.py --model_type lightgbm\")\n",
    "    print(f\"     python src/train.py --model_type catboost\")\n",
    "    print(f\"     python src/train.py --model_type stacking\")\n",
    "\n",
    "    # 性能分析\n",
    "    print(f\"\\n性能分析:\")\n",
    "    if test_metrics['log_loss'] < 0.5:\n",
    "        print(f\"  ✓✓ Log Loss < 0.5，性能优秀！\")\n",
    "    elif test_metrics['log_loss'] < 0.6:\n",
    "        print(f\"  ✓ Log Loss < 0.6，性能良好\")\n",
    "        print(f\"     可以尝试:\")\n",
    "        print(f\"     - 使用Stacking集成\")\n",
    "        print(f\"     - 创建更多特征 (--create_features)\")\n",
    "        print(f\"     - 调整超参数\")\n",
    "    else:\n",
    "        print(f\"  ⚠ Log Loss较高，建议:\")\n",
    "        print(f\"    - 检查数据质量\")\n",
    "        print(f\"    - 创建工程特征\")\n",
    "        print(f\"    - 使用更复杂的模型\")\n",
    "        print(f\"    - 尝试模型集成\")\n",
    "\n",
    "    # 过拟合检查\n",
    "    if train_metrics['log_loss'] < val_metrics['log_loss'] * 0.7:\n",
    "        print(f\"\\n  ⚠ 检测到过拟合，建议:\")\n",
    "        print(f\"    - 增加正则化\")\n",
    "        print(f\"    - 减少模型复杂度\")\n",
    "        print(f\"    - 使用更多训练数据\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
