{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c056ea7",
   "metadata": {},
   "source": [
    "# SVM文本分类训练脚本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274d04a4",
   "metadata": {},
   "source": [
    "\n",
    "使用方法:\n",
    "    python src/train.py --kernel linear --feature_method tfidf\n",
    "    python src/train.py --kernel rbf --tune_hyperparams\n",
    "    python src/train.py --ensemble --categories alt.atheism comp.graphics\n",
    "\n",
    "【训练模式】:\n",
    "- 单模型训练\n",
    "- 超参数调优\n",
    "- 集成模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0ec64e",
   "metadata": {},
   "source": [
    "## Notebook 训练模式\n",
    "1. 通过参数单元选择数据源、特征提取方式与 SVM 核函数。\n",
    "2. 可选择单模型训练、超参数调优或集成模式, 并在 Notebook 中即时查看训练日志。\n",
    "3. 训练完成后绘制混淆矩阵、特征重要性和分类报告热力图, 同时保存模型/特征提取器。\n",
    "\n",
    "> **实践提示**: 建议先跑线性核 + TF-IDF 作为基线, 再切换 RBF/Word2Vec, Notebook 方便逐步比较。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aecd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook路径自适应处理\n",
    "import pathlib as _nb_pathlib\n",
    "def _nb_resolve_file_path():\n",
    "    if '__file__' not in globals():\n",
    "        _cwd = _nb_pathlib.Path.cwd().resolve()\n",
    "        for _candidate in (_cwd, *_cwd.parents):\n",
    "            _potential = _candidate / '09-practical-projects/01_机器学习基础项目/03_SVM文本分类_中级/src/train.py'\n",
    "            if _potential.exists():\n",
    "                globals()['__file__'] = str(_potential)\n",
    "                return\n",
    "        globals()['__file__'] = str((_cwd / '09-practical-projects/01_机器学习基础项目/03_SVM文本分类_中级/src/train.py').resolve())\n",
    "_nb_resolve_file_path()\n",
    "del _nb_pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc95797f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SVM文本分类训练脚本\n",
    "\n",
    "使用方法:\n",
    "    python src/train.py --kernel linear --feature_method tfidf\n",
    "    python src/train.py --kernel rbf --tune_hyperparams\n",
    "    python src/train.py --ensemble --categories alt.atheism comp.graphics\n",
    "\n",
    "【训练模式】:\n",
    "- 单模型训练\n",
    "- 超参数调优\n",
    "- 集成模型训练\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "project_root = Path(__file__).parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.data import prepare_text_classification_data\n",
    "from src.model import SVMTextClassifier, SVMHyperparameterTuner, SVMEnsembleClassifier\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"解析命令行参数\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='训练SVM文本分类模型')\n",
    "\n",
    "    # 数据参数\n",
    "    parser.add_argument('--data_source', type=str, default='20newsgroups',\n",
    "                       help='数据源')\n",
    "    parser.add_argument('--categories', type=str, nargs='+', default=None,\n",
    "                       help='类别列表（None表示全部）')\n",
    "    parser.add_argument('--feature_method', type=str, default='tfidf',\n",
    "                       choices=['tfidf', 'count', 'word2vec'],\n",
    "                       help='特征提取方法')\n",
    "    parser.add_argument('--max_features', type=int, default=5000,\n",
    "                       help='最大特征数')\n",
    "    parser.add_argument('--preprocess', action='store_true', default=True,\n",
    "                       help='是否预处理文本')\n",
    "\n",
    "    # 模型参数\n",
    "    parser.add_argument('--kernel', type=str, default='linear',\n",
    "                       choices=['linear', 'rbf', 'poly'],\n",
    "                       help='SVM核函数')\n",
    "    parser.add_argument('--C', type=float, default=1.0,\n",
    "                       help='正则化参数')\n",
    "    parser.add_argument('--gamma', type=str, default='scale',\n",
    "                       help='RBF核参数')\n",
    "\n",
    "    # 训练模式\n",
    "    parser.add_argument('--tune_hyperparams', action='store_true',\n",
    "                       help='是否进行超参数调优')\n",
    "    parser.add_argument('--search_method', type=str, default='grid',\n",
    "                       choices=['grid', 'random'],\n",
    "                       help='超参数搜索方法')\n",
    "    parser.add_argument('--ensemble', action='store_true',\n",
    "                       help='是否使用集成模型')\n",
    "\n",
    "    # 保存路径\n",
    "    parser.add_argument('--model_dir', type=str, default='models',\n",
    "                       help='模型保存目录')\n",
    "    parser.add_argument('--result_dir', type=str, default='results',\n",
    "                       help='结果保存目录')\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, label_names, save_path):\n",
    "    \"\"\"\n",
    "    绘制混淆矩阵\n",
    "\n",
    "    【是什么】：展示分类结果的混淆情况\n",
    "    【如何解读】：\n",
    "        - 对角线：正确分类的样本\n",
    "        - 非对角线：错误分类的样本\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 10))\n",
    "\n",
    "    # 归一化\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # 绘制热力图\n",
    "    sns.heatmap(\n",
    "        cm_normalized,\n",
    "        annot=True,\n",
    "        fmt='.2f',\n",
    "        cmap='Blues',\n",
    "        xticklabels=label_names,\n",
    "        yticklabels=label_names,\n",
    "        cbar_kws={'label': '比例'}\n",
    "    )\n",
    "\n",
    "    plt.xlabel('预测类别', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('真实类别', fontsize=12, fontweight='bold')\n",
    "    plt.title('混淆矩阵（归一化）', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"✓ 混淆矩阵已保存: {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_feature_importance(importance_dict, label_names, save_path, top_n=15):\n",
    "    \"\"\"\n",
    "    绘制特征重要性\n",
    "\n",
    "    【是什么】：展示对分类最重要的词\n",
    "    【解释】：权重绝对值越大，词越重要\n",
    "    \"\"\"\n",
    "    n_classes = len(importance_dict)\n",
    "    fig, axes = plt.subplots(1, min(n_classes, 3), figsize=(18, 6))\n",
    "\n",
    "    if n_classes == 1:\n",
    "        axes = [axes]\n",
    "    elif n_classes == 2:\n",
    "        axes = axes\n",
    "\n",
    "    for idx, (class_key, features) in enumerate(list(importance_dict.items())[:3]):\n",
    "        if idx >= len(axes):\n",
    "            break\n",
    "\n",
    "        # 提取特征和权重\n",
    "        words = [f[0] for f in features[:top_n]]\n",
    "        weights = [f[1] for f in features[:top_n]]\n",
    "\n",
    "        # 颜色（正权重蓝色，负权重红色）\n",
    "        colors = ['blue' if w > 0 else 'red' for w in weights]\n",
    "\n",
    "        # 绘制条形图\n",
    "        axes[idx].barh(range(len(words)), weights, color=colors, alpha=0.7)\n",
    "        axes[idx].set_yticks(range(len(words)))\n",
    "        axes[idx].set_yticklabels(words)\n",
    "        axes[idx].set_xlabel('权重', fontsize=10)\n",
    "        axes[idx].set_title(f'{label_names[idx] if idx < len(label_names) else class_key}\\n重要特征',\n",
    "                           fontsize=12, fontweight='bold')\n",
    "        axes[idx].grid(True, alpha=0.3, axis='x')\n",
    "        axes[idx].invert_yaxis()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"✓ 特征重要性已保存: {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_classification_report(report, label_names, save_path):\n",
    "    \"\"\"\n",
    "    绘制分类报告\n",
    "\n",
    "    【指标说明】：\n",
    "    - Precision（精确率）：预测为正的样本中真正为正的比例\n",
    "    - Recall（召回率）：真正为正的样本中被预测为正的比例\n",
    "    - F1-score：精确率和召回率的调和平均\n",
    "    \"\"\"\n",
    "    # 提取每个类别的指标\n",
    "    metrics = ['precision', 'recall', 'f1-score']\n",
    "    data = []\n",
    "\n",
    "    for label in label_names:\n",
    "        if label in report:\n",
    "            data.append([\n",
    "                report[label]['precision'],\n",
    "                report[label]['recall'],\n",
    "                report[label]['f1-score']\n",
    "            ])\n",
    "\n",
    "    data = np.array(data)\n",
    "\n",
    "    # 绘制热力图\n",
    "    fig, ax = plt.subplots(figsize=(10, max(6, len(label_names) * 0.4)))\n",
    "\n",
    "    im = ax.imshow(data, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)\n",
    "\n",
    "    # 设置刻度\n",
    "    ax.set_xticks(range(len(metrics)))\n",
    "    ax.set_yticks(range(len(label_names)))\n",
    "    ax.set_xticklabels(metrics)\n",
    "    ax.set_yticklabels(label_names)\n",
    "\n",
    "    # 添加数值标签\n",
    "    for i in range(len(label_names)):\n",
    "        for j in range(len(metrics)):\n",
    "            text = ax.text(j, i, f'{data[i, j]:.3f}',\n",
    "                          ha=\"center\", va=\"center\", color=\"black\", fontsize=9)\n",
    "\n",
    "    ax.set_title('分类报告', fontsize=14, fontweight='bold')\n",
    "    plt.colorbar(im, ax=ax, label='分数')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"✓ 分类报告已保存: {save_path}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"主训练流程\"\"\"\n",
    "    args = parse_args()\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(\"SVM文本分类 - 模型训练\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\n训练配置:\")\n",
    "    print(f\"  数据源: {args.data_source}\")\n",
    "    print(f\"  类别: {args.categories if args.categories else '全部'}\")\n",
    "    print(f\"  特征方法: {args.feature_method}\")\n",
    "    print(f\"  最大特征数: {args.max_features}\")\n",
    "    print(f\"  核函数: {args.kernel}\")\n",
    "    print(f\"  超参数调优: {args.tune_hyperparams}\")\n",
    "    print(f\"  集成模型: {args.ensemble}\")\n",
    "\n",
    "    # 创建保存目录\n",
    "    project_dir = Path(__file__).parent.parent\n",
    "    model_dir = project_dir / args.model_dir\n",
    "    result_dir = project_dir / args.result_dir\n",
    "    model_dir.mkdir(exist_ok=True)\n",
    "    result_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # ============================================\n",
    "    # 1. 准备数据\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤1: 数据准备\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    try:\n",
    "        (X_train, y_train), (X_test, y_test), feature_extractor, label_names = \\\n",
    "            prepare_text_classification_data(\n",
    "                data_source=args.data_source,\n",
    "                feature_method=args.feature_method,\n",
    "                max_features=args.max_features,\n",
    "                categories=args.categories,\n",
    "                preprocess=args.preprocess\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ 数据准备失败: {e}\")\n",
    "        return\n",
    "\n",
    "    # 保存特征提取器\n",
    "    extractor_path = model_dir / f'{args.feature_method}_extractor.pkl'\n",
    "    with open(extractor_path, 'wb') as f:\n",
    "        pickle.dump(feature_extractor, f)\n",
    "    print(f\"\\n✓ 特征提取器已保存: {extractor_path}\")\n",
    "\n",
    "    # 保存标签名称\n",
    "    labels_path = model_dir / 'label_names.pkl'\n",
    "    with open(labels_path, 'wb') as f:\n",
    "        pickle.dump(label_names, f)\n",
    "\n",
    "    # ============================================\n",
    "    # 2. 训练模型\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤2: 训练模型\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    if args.ensemble:\n",
    "        # ============================================\n",
    "        # 集成模型\n",
    "        # ============================================\n",
    "        print(\"\\n训练集成模型...\")\n",
    "        model = SVMEnsembleClassifier(ensemble_method='voting')\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        model_path = model_dir / 'svm_ensemble_model.pkl'\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "    elif args.tune_hyperparams:\n",
    "        # ============================================\n",
    "        # 超参数调优\n",
    "        # ============================================\n",
    "        tuner = SVMHyperparameterTuner(\n",
    "            kernel=args.kernel,\n",
    "            search_method=args.search_method,\n",
    "            cv=5\n",
    "        )\n",
    "\n",
    "        best_model, best_params = tuner.tune(X_train, y_train)\n",
    "\n",
    "        # 保存最佳模型\n",
    "        model_path = model_dir / f'svm_{args.kernel}_tuned_model.pkl'\n",
    "        with open(model_path, 'wb') as f:\n",
    "            pickle.dump(best_model, f)\n",
    "\n",
    "        # 保存调优结果\n",
    "        tuning_results_path = result_dir / 'hyperparameter_tuning_results.csv'\n",
    "        tuner.search_results.to_csv(tuning_results_path, index=False)\n",
    "        print(f\"✓ 调优结果已保存: {tuning_results_path}\")\n",
    "\n",
    "        # 包装为SVMTextClassifier以便评估\n",
    "        classifier = SVMTextClassifier(kernel=args.kernel)\n",
    "        classifier.model = best_model\n",
    "        model = classifier\n",
    "\n",
    "    else:\n",
    "        # ============================================\n",
    "        # 单模型训练\n",
    "        # ============================================\n",
    "        model = SVMTextClassifier(\n",
    "            kernel=args.kernel,\n",
    "            C=args.C,\n",
    "            gamma=args.gamma\n",
    "        )\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        model_path = model_dir / f'svm_{args.kernel}_model.pkl'\n",
    "        model.save_model(model_path)\n",
    "\n",
    "    # ============================================\n",
    "    # 3. 评估模型\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤3: 评估模型\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    results = model.evaluate(X_test, y_test, label_names)\n",
    "\n",
    "    print(f\"\\n测试集准确率: {results['accuracy']:.4f}\")\n",
    "    print(\"\\n分类报告:\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    report = results['classification_report']\n",
    "    for label in label_names:\n",
    "        if label in report:\n",
    "            print(f\"\\n{label}:\")\n",
    "            print(f\"  Precision: {report[label]['precision']:.4f}\")\n",
    "            print(f\"  Recall: {report[label]['recall']:.4f}\")\n",
    "            print(f\"  F1-score: {report[label]['f1-score']:.4f}\")\n",
    "\n",
    "    print(f\"\\n宏平均:\")\n",
    "    print(f\"  Precision: {report['macro avg']['precision']:.4f}\")\n",
    "    print(f\"  Recall: {report['macro avg']['recall']:.4f}\")\n",
    "    print(f\"  F1-score: {report['macro avg']['f1-score']:.4f}\")\n",
    "\n",
    "    # ============================================\n",
    "    # 4. 可视化结果\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤4: 可视化结果\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 混淆矩阵\n",
    "    cm_path = result_dir / 'confusion_matrix.png'\n",
    "    plot_confusion_matrix(results['confusion_matrix'], label_names, cm_path)\n",
    "\n",
    "    # 分类报告\n",
    "    report_path = result_dir / 'classification_report.png'\n",
    "    plot_classification_report(report, label_names, report_path)\n",
    "\n",
    "    # 特征重要性（仅线性核）\n",
    "    if args.kernel == 'linear' and not args.ensemble:\n",
    "        feature_names = feature_extractor.get_feature_names()\n",
    "        if feature_names is not None:\n",
    "            importance = model.get_feature_importance(feature_names, top_n=20)\n",
    "            if importance:\n",
    "                importance_path = result_dir / 'feature_importance.png'\n",
    "                plot_feature_importance(importance, label_names, importance_path)\n",
    "\n",
    "    # ============================================\n",
    "    # 5. 保存结果\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤5: 保存结果\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 保存评估结果\n",
    "    results_path = result_dir / 'evaluation_results.txt'\n",
    "    with open(results_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(\"SVM文本分类 - 评估结果\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "\n",
    "        f.write(f\"测试集准确率: {results['accuracy']:.4f}\\n\\n\")\n",
    "\n",
    "        f.write(\"分类报告:\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        for label in label_names:\n",
    "            if label in report:\n",
    "                f.write(f\"\\n{label}:\\n\")\n",
    "                f.write(f\"  Precision: {report[label]['precision']:.4f}\\n\")\n",
    "                f.write(f\"  Recall: {report[label]['recall']:.4f}\\n\")\n",
    "                f.write(f\"  F1-score: {report[label]['f1-score']:.4f}\\n\")\n",
    "                f.write(f\"  Support: {report[label]['support']}\\n\")\n",
    "\n",
    "        f.write(f\"\\n宏平均:\\n\")\n",
    "        f.write(f\"  Precision: {report['macro avg']['precision']:.4f}\\n\")\n",
    "        f.write(f\"  Recall: {report['macro avg']['recall']:.4f}\\n\")\n",
    "        f.write(f\"  F1-score: {report['macro avg']['f1-score']:.4f}\\n\")\n",
    "\n",
    "    print(f\"✓ 评估结果已保存: {results_path}\")\n",
    "\n",
    "    # ============================================\n",
    "    # 总结\n",
    "    # ============================================\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"训练总结\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"✓ 模型已保存: {model_path}\")\n",
    "    print(f\"✓ 特征提取器已保存: {extractor_path}\")\n",
    "    print(f\"✓ 测试集准确率: {results['accuracy']:.4f}\")\n",
    "    print(f\"\\n使用以下命令进行评估:\")\n",
    "    print(f\"  python src/evaluate.py --model_path {model_path} --extractor_path {extractor_path}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 设置随机种子\n",
    "    np.random.seed(42)\n",
    "\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
