{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ace4e58",
   "metadata": {},
   "source": [
    "# XGBoost模型定义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f381e6",
   "metadata": {},
   "source": [
    "\n",
    "本模块包含详细的XGBoost模型实现，每个参数都有详细的注释说明：\n",
    "1. 这个参数是什么\n",
    "2. 这个参数做什么\n",
    "3. 为什么选择这个值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d453c3d",
   "metadata": {},
   "source": [
    "## 核心算法说明\n",
    "- Notebook 还原 `TitanicXGBoostClassifier` 的 basic/tuned/advanced 三种配置, 并保留每个超参数的用途解释。\n",
    "- 通过 `create_basic_model`/`create_tuned_model`/`create_advanced_model` 展示如何针对不同需求权衡树深度、学习率、采样和正则化。\n",
    "- 训练、预测、评估、特征重要性等方法完整保留, 方便在交互式环境中即时观察 Accuracy/AUC 与重要特征。\n",
    "\n",
    "> **模型思路**: 以梯度提升树为核心, 借助早停与正则化控制过拟合, Notebook 额外提醒在何时选择各个配置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d618dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook路径自适应处理\n",
    "import pathlib as _nb_pathlib\n",
    "def _nb_resolve_file_path():\n",
    "    if '__file__' not in globals():\n",
    "        _cwd = _nb_pathlib.Path.cwd().resolve()\n",
    "        for _candidate in (_cwd, *_cwd.parents):\n",
    "            _potential = _candidate / '09-practical-projects/01_机器学习基础项目/01_Titanic生存预测_XGBoost入门/src/model.py'\n",
    "            if _potential.exists():\n",
    "                globals()['__file__'] = str(_potential)\n",
    "                return\n",
    "        globals()['__file__'] = str((_cwd / '09-practical-projects/01_机器学习基础项目/01_Titanic生存预测_XGBoost入门/src/model.py').resolve())\n",
    "_nb_resolve_file_path()\n",
    "del _nb_pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7124000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "XGBoost模型定义\n",
    "\n",
    "本模块包含详细的XGBoost模型实现，每个参数都有详细的注释说明：\n",
    "1. 这个参数是什么\n",
    "2. 这个参数做什么\n",
    "3. 为什么选择这个值\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "import joblib\n",
    "\n",
    "# 添加项目根目录到路径\n",
    "project_root = Path(__file__).parent.parent.parent.parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from utils.common import set_seed\n",
    "\n",
    "\n",
    "class TitanicXGBoostClassifier:\n",
    "    \"\"\"\n",
    "    Titanic生存预测XGBoost分类器\n",
    "\n",
    "    支持三种模型配置：\n",
    "    1. basic: 基础XGBoost（默认参数）\n",
    "    2. tuned: 调优后的XGBoost\n",
    "    3. advanced: 高级XGBoost（更多正则化）\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_type='basic', random_state=42):\n",
    "        \"\"\"\n",
    "        初始化分类器\n",
    "\n",
    "        Args:\n",
    "            model_type: 模型类型 ['basic', 'tuned', 'advanced']\n",
    "            random_state: 随机种子\n",
    "        \"\"\"\n",
    "        self.model_type = model_type\n",
    "        self.random_state = random_state\n",
    "        self.model = None\n",
    "        self.feature_names = None\n",
    "        self.feature_importance = None\n",
    "\n",
    "        set_seed(random_state)\n",
    "\n",
    "    def create_basic_model(self):\n",
    "        \"\"\"\n",
    "        创建基础XGBoost模型（使用默认参数）\n",
    "\n",
    "        适用场景：\n",
    "        - 快速原型验证\n",
    "        - 建立基线模型\n",
    "        - 数据量较小\n",
    "\n",
    "        Returns:\n",
    "            XGBoost分类器\n",
    "        \"\"\"\n",
    "        # ============================================\n",
    "        # 基础XGBoost模型\n",
    "        # ============================================\n",
    "        # 使用较少的参数，快速训练\n",
    "\n",
    "        model = xgb.XGBClassifier(\n",
    "            # ============================================\n",
    "            # 树的参数\n",
    "            # ============================================\n",
    "\n",
    "            # max_depth: 树的最大深度\n",
    "            # 【是什么】：决策树可以生长的最大层数\n",
    "            # 【做什么】：控制树的复杂度\n",
    "            # 【为什么=3】：\n",
    "            #   - Titanic数据集较小（~900样本）\n",
    "            #   - 浅树防止过拟合\n",
    "            #   - 3层足够捕获主要的特征交互\n",
    "            #   - 如果是大数据集，可以用6-10\n",
    "            max_depth=3,\n",
    "\n",
    "            # ============================================\n",
    "            # 提升参数\n",
    "            # ============================================\n",
    "\n",
    "            # learning_rate: 学习率（也叫eta）\n",
    "            # 【是什么】：每棵树的贡献权重\n",
    "            # 【做什么】：控制模型学习速度\n",
    "            # 【为什么=0.1】：\n",
    "            #   - 默认值0.3太大，容易过拟合\n",
    "            #   - 0.1是常用的稳定值\n",
    "            #   - 较小的学习率需要更多树（n_estimators）\n",
    "            #   - 学习率和树的数量需要平衡\n",
    "            learning_rate=0.1,\n",
    "\n",
    "            # n_estimators: 树的数量\n",
    "            # 【是什么】：要训练多少棵树\n",
    "            # 【做什么】：更多的树可以学习更复杂的模式\n",
    "            # 【为什么=100】：\n",
    "            #   - 配合learning_rate=0.1\n",
    "            #   - 100棵树对小数据集足够\n",
    "            #   - 使用early_stopping可以自动找到最佳数量\n",
    "            n_estimators=100,\n",
    "\n",
    "            # ============================================\n",
    "            # 其他参数\n",
    "            # ============================================\n",
    "\n",
    "            # objective: 目标函数\n",
    "            # 【是什么】：要优化的损失函数\n",
    "            # 【做什么】：定义模型的学习目标\n",
    "            # 【为什么='binary:logistic'】：\n",
    "            #   - 二分类问题（生存/遇难）\n",
    "            #   - 输出概率值（0-1之间）\n",
    "            objective='binary:logistic',\n",
    "\n",
    "            # eval_metric: 评估指标\n",
    "            # 【是什么】：用于评估模型性能的指标\n",
    "            # 【做什么】：在训练过程中监控模型表现\n",
    "            # 【为什么='logloss'】：\n",
    "            #   - 对数损失，适合概率预测\n",
    "            #   - 也可以用'auc'（ROC曲线下面积）\n",
    "            eval_metric='logloss',\n",
    "\n",
    "            # random_state: 随机种子\n",
    "            # 【是什么】：控制随机性的种子\n",
    "            # 【做什么】：保证结果可复现\n",
    "            random_state=self.random_state,\n",
    "\n",
    "            # use_label_encoder: 是否使用标签编码器\n",
    "            # 【为什么=False】：避免警告，我们已经手动处理了标签\n",
    "            use_label_encoder=False\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def create_tuned_model(self):\n",
    "        \"\"\"\n",
    "        创建调优后的XGBoost模型\n",
    "\n",
    "        适用场景：\n",
    "        - 追求更高准确率\n",
    "        - 有足够的训练时间\n",
    "        - 需要防止过拟合\n",
    "\n",
    "        Returns:\n",
    "            XGBoost分类器\n",
    "        \"\"\"\n",
    "        model = xgb.XGBClassifier(\n",
    "            # ============================================\n",
    "            # 树的参数（更精细的控制）\n",
    "            # ============================================\n",
    "\n",
    "            # max_depth: 稍微增加深度\n",
    "            # 【为什么=4】：比基础模型深一层，捕获更复杂的交互\n",
    "            max_depth=4,\n",
    "\n",
    "            # min_child_weight: 最小叶子权重\n",
    "            # 【是什么】：叶子节点所需的最小样本权重和\n",
    "            # 【做什么】：控制叶子节点的最小样本数\n",
    "            # 【为什么=1】：\n",
    "            #   - 允许较小的叶子节点\n",
    "            #   - 可以学习更细致的模式\n",
    "            #   - 如果过拟合，可以增加到3-5\n",
    "            min_child_weight=1,\n",
    "\n",
    "            # gamma: 分裂所需的最小损失减少\n",
    "            # 【是什么】：节点分裂所需的最小增益\n",
    "            # 【做什么】：控制树的生长（正则化）\n",
    "            # 【为什么=0.1】：\n",
    "            #   - 轻微的正则化\n",
    "            #   - 防止过度分裂\n",
    "            #   - 0表示不限制，0.1-0.2是常用值\n",
    "            gamma=0.1,\n",
    "\n",
    "            # ============================================\n",
    "            # 提升参数\n",
    "            # ============================================\n",
    "\n",
    "            learning_rate=0.05,  # 降低学习率，更稳定\n",
    "            n_estimators=200,    # 增加树的数量，配合较小的学习率\n",
    "\n",
    "            # ============================================\n",
    "            # 采样参数（防止过拟合）\n",
    "            # ============================================\n",
    "\n",
    "            # subsample: 行采样比例\n",
    "            # 【是什么】：每棵树使用多少比例的样本\n",
    "            # 【做什么】：随机采样，增加模型多样性\n",
    "            # 【为什么=0.8】：\n",
    "            #   - 使用80%的样本训练每棵树\n",
    "            #   - 类似于随机森林的bagging\n",
    "            #   - 防止过拟合，提高泛化能力\n",
    "            #   - 0.5-1.0都是常用值\n",
    "            subsample=0.8,\n",
    "\n",
    "            # colsample_bytree: 列采样比例\n",
    "            # 【是什么】：每棵树使用多少比例的特征\n",
    "            # 【做什么】：随机选择特征，增加多样性\n",
    "            # 【为什么=0.8】：\n",
    "            #   - 使用80%的特征训练每棵树\n",
    "            #   - 防止某些特征过度主导\n",
    "            #   - 提高模型鲁棒性\n",
    "            colsample_bytree=0.8,\n",
    "\n",
    "            # ============================================\n",
    "            # 正则化参数\n",
    "            # ============================================\n",
    "\n",
    "            # reg_alpha: L1正则化\n",
    "            # 【是什么】：权重的L1范数惩罚\n",
    "            # 【做什么】：使某些权重变为0（特征选择）\n",
    "            # 【为什么=0.1】：\n",
    "            #   - 轻微的L1正则化\n",
    "            #   - 可以自动进行特征选择\n",
    "            #   - 产生稀疏解\n",
    "            reg_alpha=0.1,\n",
    "\n",
    "            # reg_lambda: L2正则化\n",
    "            # 【是什么】：权重的L2范数惩罚\n",
    "            # 【做什么】：使权重变小（平滑）\n",
    "            # 【为什么=1】：\n",
    "            #   - XGBoost默认值\n",
    "            #   - 防止权重过大\n",
    "            #   - 提高模型稳定性\n",
    "            reg_lambda=1,\n",
    "\n",
    "            # ============================================\n",
    "            # 其他参数\n",
    "            # ============================================\n",
    "\n",
    "            objective='binary:logistic',\n",
    "            eval_metric='logloss',\n",
    "            random_state=self.random_state,\n",
    "            use_label_encoder=False\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def create_advanced_model(self):\n",
    "        \"\"\"\n",
    "        创建高级XGBoost模型（更强的正则化）\n",
    "\n",
    "        适用场景：\n",
    "        - 数据量很小，容易过拟合\n",
    "        - 需要最好的泛化能力\n",
    "        - 可以接受较长的训练时间\n",
    "\n",
    "        Returns:\n",
    "            XGBoost分类器\n",
    "        \"\"\"\n",
    "        model = xgb.XGBClassifier(\n",
    "            # 树的参数：更保守\n",
    "            max_depth=3,              # 浅树\n",
    "            min_child_weight=3,       # 更大的最小叶子权重\n",
    "            gamma=0.2,                # 更强的分裂限制\n",
    "\n",
    "            # 提升参数：更慢更稳\n",
    "            learning_rate=0.01,       # 很小的学习率\n",
    "            n_estimators=500,         # 很多树来补偿小学习率\n",
    "\n",
    "            # 采样参数：更多随机性\n",
    "            subsample=0.7,            # 只用70%的样本\n",
    "            colsample_bytree=0.7,     # 只用70%的特征\n",
    "\n",
    "            # 正则化参数：更强\n",
    "            reg_alpha=0.5,            # 更强的L1正则化\n",
    "            reg_lambda=2,             # 更强的L2正则化\n",
    "\n",
    "            objective='binary:logistic',\n",
    "            eval_metric='logloss',\n",
    "            random_state=self.random_state,\n",
    "            use_label_encoder=False\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def create_model(self):\n",
    "        \"\"\"\n",
    "        根据model_type创建对应的模型\n",
    "\n",
    "        Returns:\n",
    "            XGBoost分类器\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"创建模型: {self.model_type}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        if self.model_type == 'basic':\n",
    "            model = self.create_basic_model()\n",
    "        elif self.model_type == 'tuned':\n",
    "            model = self.create_tuned_model()\n",
    "        elif self.model_type == 'advanced':\n",
    "            model = self.create_advanced_model()\n",
    "        else:\n",
    "            raise ValueError(f\"不支持的模型类型: {self.model_type}\")\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self, X_train, y_train, X_val=None, y_val=None,\n",
    "              early_stopping_rounds=10, verbose=True):\n",
    "        \"\"\"\n",
    "        训练模型\n",
    "\n",
    "        Args:\n",
    "            X_train: 训练数据\n",
    "            y_train: 训练标签\n",
    "            X_val: 验证数据\n",
    "            y_val: 验证标签\n",
    "            early_stopping_rounds: 早停轮数\n",
    "            verbose: 是否显示训练过程\n",
    "\n",
    "        Returns:\n",
    "            训练历史\n",
    "        \"\"\"\n",
    "        print(f\"\\n开始训练模型...\")\n",
    "        print(f\"训练样本数: {len(X_train)}\")\n",
    "\n",
    "        # 保存特征名\n",
    "        if isinstance(X_train, pd.DataFrame):\n",
    "            self.feature_names = X_train.columns.tolist()\n",
    "\n",
    "        # 创建模型\n",
    "        self.model = self.create_model()\n",
    "\n",
    "        # 打印模型参数\n",
    "        print(f\"\\n模型参数:\")\n",
    "        params = self.model.get_params()\n",
    "        for key in ['max_depth', 'learning_rate', 'n_estimators',\n",
    "                   'subsample', 'colsample_bytree', 'reg_alpha', 'reg_lambda']:\n",
    "            if key in params:\n",
    "                print(f\"  {key}: {params[key]}\")\n",
    "\n",
    "        # 准备验证集\n",
    "        eval_set = []\n",
    "        if X_val is not None and y_val is not None:\n",
    "            eval_set = [(X_val, y_val)]\n",
    "            print(f\"验证样本数: {len(X_val)}\")\n",
    "\n",
    "        # 训练模型\n",
    "        print(f\"\\n开始训练...\")\n",
    "        self.model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=eval_set,\n",
    "            early_stopping_rounds=early_stopping_rounds if eval_set else None,\n",
    "            verbose=verbose\n",
    "        )\n",
    "\n",
    "        # 获取特征重要性\n",
    "        self.feature_importance = self.model.feature_importances_\n",
    "\n",
    "        print(\"\\n✓ 模型训练完成！\")\n",
    "\n",
    "        # 如果使用了early stopping，显示最佳迭代\n",
    "        if hasattr(self.model, 'best_iteration'):\n",
    "            print(f\"最佳迭代: {self.model.best_iteration}\")\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        预测类别\n",
    "\n",
    "        Args:\n",
    "            X: 输入数据\n",
    "\n",
    "        Returns:\n",
    "            预测类别\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"模型未训练，请先调用train()方法\")\n",
    "\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        预测概率\n",
    "\n",
    "        Args:\n",
    "            X: 输入数据\n",
    "\n",
    "        Returns:\n",
    "            预测概率\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"模型未训练，请先调用train()方法\")\n",
    "\n",
    "        return self.model.predict_proba(X)\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        \"\"\"\n",
    "        评估模型\n",
    "\n",
    "        Args:\n",
    "            X: 测试数据\n",
    "            y: 测试标签\n",
    "\n",
    "        Returns:\n",
    "            评估指标字典\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"模型未训练，请先调用train()方法\")\n",
    "\n",
    "        # 预测\n",
    "        y_pred = self.predict(X)\n",
    "        y_pred_proba = self.predict_proba(X)[:, 1]\n",
    "\n",
    "        # 计算指标\n",
    "        accuracy = accuracy_score(y, y_pred)\n",
    "        auc = roc_auc_score(y, y_pred_proba)\n",
    "\n",
    "        return {\n",
    "            'accuracy': accuracy,\n",
    "            'auc': auc\n",
    "        }\n",
    "\n",
    "    def get_feature_importance(self, top_n=None):\n",
    "        \"\"\"\n",
    "        获取特征重要性\n",
    "\n",
    "        Args:\n",
    "            top_n: 返回前N个重要特征\n",
    "\n",
    "        Returns:\n",
    "            特征重要性DataFrame\n",
    "        \"\"\"\n",
    "        if self.feature_importance is None:\n",
    "            raise ValueError(\"模型未训练，请先调用train()方法\")\n",
    "\n",
    "        # 创建DataFrame\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': self.feature_names,\n",
    "            'importance': self.feature_importance\n",
    "        })\n",
    "\n",
    "        # 排序\n",
    "        importance_df = importance_df.sort_values('importance', ascending=False)\n",
    "\n",
    "        # 返回前N个\n",
    "        if top_n is not None:\n",
    "            importance_df = importance_df.head(top_n)\n",
    "\n",
    "        return importance_df\n",
    "\n",
    "    def save_model(self, filepath):\n",
    "        \"\"\"\n",
    "        保存模型\n",
    "\n",
    "        Args:\n",
    "            filepath: 保存路径\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"模型未训练，无法保存\")\n",
    "\n",
    "        filepath = Path(filepath)\n",
    "        filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # 保存模型和元数据\n",
    "        model_data = {\n",
    "            'model': self.model,\n",
    "            'feature_names': self.feature_names,\n",
    "            'feature_importance': self.feature_importance,\n",
    "            'model_type': self.model_type\n",
    "        }\n",
    "\n",
    "        joblib.dump(model_data, filepath)\n",
    "        print(f\"✓ 模型已保存: {filepath}\")\n",
    "\n",
    "    def load_model(self, filepath):\n",
    "        \"\"\"\n",
    "        加载模型\n",
    "\n",
    "        Args:\n",
    "            filepath: 模型路径\n",
    "        \"\"\"\n",
    "        filepath = Path(filepath)\n",
    "        if not filepath.exists():\n",
    "            raise FileNotFoundError(f\"模型文件不存在: {filepath}\")\n",
    "\n",
    "        # 加载模型和元数据\n",
    "        model_data = joblib.load(filepath)\n",
    "\n",
    "        self.model = model_data['model']\n",
    "        self.feature_names = model_data['feature_names']\n",
    "        self.feature_importance = model_data['feature_importance']\n",
    "        self.model_type = model_data['model_type']\n",
    "\n",
    "        print(f\"✓ 模型已加载: {filepath}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \"\"\"\n",
    "    测试模型创建\n",
    "    \"\"\"\n",
    "    print(\"=\"*60)\n",
    "    print(\"XGBoost模型测试\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 测试三种模型\n",
    "    for model_type in ['basic', 'tuned', 'advanced']:\n",
    "        print(f\"\\n\\n{'='*60}\")\n",
    "        print(f\"测试模型: {model_type}\")\n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "        classifier = TitanicXGBoostClassifier(model_type=model_type)\n",
    "        model = classifier.create_model()\n",
    "\n",
    "        print(f\"\\n✓ {model_type} 模型创建成功！\")\n",
    "        print(f\"模型参数:\")\n",
    "        params = model.get_params()\n",
    "        for key, value in params.items():\n",
    "            if not key.startswith('_'):\n",
    "                print(f\"  {key}: {value}\")\n",
    "\n",
    "    print(\"\\n\\n✓ 所有模型测试完成！\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
