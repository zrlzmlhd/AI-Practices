{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2029951",
   "metadata": {},
   "source": [
    "# MNIST模型定义"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4968bf96",
   "metadata": {},
   "source": [
    "## Notebook运行提示\n",
    "- 代码已拆分为多个小单元, 按顺序运行即可在每一步观察输出与中间变量。\n",
    "- 涉及 `Path(__file__)` 或相对路径的脚本会自动注入 `__file__` 解析逻辑, Notebook 环境下也能引用原项目资源。\n",
    "- 可在每个单元下追加说明或参数试验记录, 以跟踪核心算法和数据处理步骤。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15f365f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Notebook路径自适应处理\n",
    "import pathlib as _nb_pathlib\n",
    "def _nb_resolve_file_path():\n",
    "    if '__file__' not in globals():\n",
    "        _cwd = _nb_pathlib.Path.cwd().resolve()\n",
    "        for _candidate in (_cwd, *_cwd.parents):\n",
    "            _potential = _candidate / '09-practical-projects/02_计算机视觉项目/01_MNIST手写数字识别_CNN入门/src/model.py'\n",
    "            if _potential.exists():\n",
    "                globals()['__file__'] = str(_potential)\n",
    "                return\n",
    "        globals()['__file__'] = str((_cwd / '09-practical-projects/02_计算机视觉项目/01_MNIST手写数字识别_CNN入门/src/model.py').resolve())\n",
    "_nb_resolve_file_path()\n",
    "del _nb_pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9269612",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# 添加项目根目录到路径\n",
    "project_root = Path(__file__).parent.parent.parent.parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from utils.common import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fbc563",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MNISTPredictor:\n",
    "    \"\"\"MNIST手写数字识别预测器\"\"\"\n",
    "\n",
    "    def __init__(self, model_type='simple_cnn', random_state=42):\n",
    "        \"\"\"\n",
    "        初始化预测器\n",
    "\n",
    "        Args:\n",
    "            model_type: 模型类型\n",
    "            random_state: 随机种子\n",
    "        \"\"\"\n",
    "        self.model_type = model_type\n",
    "        self.random_state = random_state\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "\n",
    "        set_seed(random_state)\n",
    "\n",
    "    def create_simple_cnn(self, input_shape=(28, 28, 1), num_classes=10):\n",
    "        \"\"\"\n",
    "        创建简单的CNN模型\n",
    "\n",
    "        Args:\n",
    "            input_shape: 输入形状\n",
    "            num_classes: 类别数\n",
    "\n",
    "        Returns:\n",
    "            Keras模型\n",
    "        \"\"\"\n",
    "        model = models.Sequential([\n",
    "            # 第一个卷积块\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "            # 第二个卷积块\n",
    "            layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "            # 全连接层\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(num_classes, activation='softmax')\n",
    "        ], name='simple_cnn')\n",
    "\n",
    "        return model\n",
    "\n",
    "    def create_improved_cnn(self, input_shape=(28, 28, 1), num_classes=10):\n",
    "        \"\"\"\n",
    "        创建改进的CNN模型（使用批标准化）\n",
    "\n",
    "        Args:\n",
    "            input_shape: 输入形状\n",
    "            num_classes: 类别数\n",
    "\n",
    "        Returns:\n",
    "            Keras模型\n",
    "        \"\"\"\n",
    "        model = models.Sequential([\n",
    "            # 第一个卷积块\n",
    "            layers.Conv2D(32, (3, 3), padding='same', input_shape=input_shape),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu'),\n",
    "            layers.Conv2D(32, (3, 3), padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu'),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Dropout(0.25),\n",
    "\n",
    "            # 第二个卷积块\n",
    "            layers.Conv2D(64, (3, 3), padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu'),\n",
    "            layers.Conv2D(64, (3, 3), padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu'),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Dropout(0.25),\n",
    "\n",
    "            # 全连接层\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(256),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu'),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(num_classes, activation='softmax')\n",
    "        ], name='improved_cnn')\n",
    "\n",
    "        return model\n",
    "\n",
    "    def create_deep_cnn(self, input_shape=(28, 28, 1), num_classes=10):\n",
    "        \"\"\"\n",
    "        创建深度CNN模型\n",
    "\n",
    "        Args:\n",
    "            input_shape: 输入形状\n",
    "            num_classes: 类别数\n",
    "\n",
    "        Returns:\n",
    "            Keras模型\n",
    "        \"\"\"\n",
    "        model = models.Sequential([\n",
    "            # 第一个卷积块\n",
    "            layers.Conv2D(32, (3, 3), padding='same', input_shape=input_shape),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu'),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "            # 第二个卷积块\n",
    "            layers.Conv2D(64, (3, 3), padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu'),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "            # 第三个卷积块\n",
    "            layers.Conv2D(128, (3, 3), padding='same'),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Activation('relu'),\n",
    "\n",
    "            # 全局平均池化\n",
    "            layers.GlobalAveragePooling2D(),\n",
    "\n",
    "            # 全连接层\n",
    "            layers.Dense(256, activation='relu'),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(num_classes, activation='softmax')\n",
    "        ], name='deep_cnn')\n",
    "\n",
    "        return model\n",
    "\n",
    "    def create_model(self, input_shape=(28, 28, 1), num_classes=10):\n",
    "        \"\"\"\n",
    "        创建模型\n",
    "\n",
    "        Args:\n",
    "            input_shape: 输入形状\n",
    "            num_classes: 类别数\n",
    "\n",
    "        Returns:\n",
    "            Keras模型\n",
    "        \"\"\"\n",
    "        if self.model_type == 'simple_cnn':\n",
    "            model = self.create_simple_cnn(input_shape, num_classes)\n",
    "        elif self.model_type == 'improved_cnn':\n",
    "            model = self.create_improved_cnn(input_shape, num_classes)\n",
    "        elif self.model_type == 'deep_cnn':\n",
    "            model = self.create_deep_cnn(input_shape, num_classes)\n",
    "        else:\n",
    "            raise ValueError(f\"不支持的模型类型: {self.model_type}\")\n",
    "\n",
    "        return model\n",
    "\n",
    "    def compile_model(self, model, learning_rate=0.001):\n",
    "        \"\"\"\n",
    "        编译模型\n",
    "\n",
    "        Args:\n",
    "            model: Keras模型\n",
    "            learning_rate: 学习率\n",
    "        \"\"\"\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def train(self, X_train, y_train, X_val=None, y_val=None,\n",
    "              epochs=20, batch_size=128, callbacks=None):\n",
    "        \"\"\"\n",
    "        训练模型\n",
    "\n",
    "        Args:\n",
    "            X_train: 训练数据\n",
    "            y_train: 训练标签\n",
    "            X_val: 验证数据\n",
    "            y_val: 验证标签\n",
    "            epochs: 训练轮数\n",
    "            batch_size: 批大小\n",
    "            callbacks: 回调函数列表\n",
    "\n",
    "        Returns:\n",
    "            训练历史\n",
    "        \"\"\"\n",
    "        print(f\"\\n开始训练模型: {self.model_type}\")\n",
    "        print(f\"训练样本数: {len(X_train)}\")\n",
    "        print(f\"输入形状: {X_train.shape[1:]}\")\n",
    "\n",
    "        # 创建模型\n",
    "        self.model = self.create_model(input_shape=X_train.shape[1:])\n",
    "        self.model = self.compile_model(self.model)\n",
    "\n",
    "        # 打印模型结构\n",
    "        print(\"\\n模型结构:\")\n",
    "        self.model.summary()\n",
    "\n",
    "        # 验证数据\n",
    "        validation_data = None\n",
    "        if X_val is not None and y_val is not None:\n",
    "            validation_data = (X_val, y_val)\n",
    "\n",
    "        # 训练模型\n",
    "        self.history = self.model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=validation_data,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=callbacks,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        print(\"\\n✓ 模型训练完成\")\n",
    "\n",
    "        return self.history\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        预测\n",
    "\n",
    "        Args:\n",
    "            X: 输入数据\n",
    "\n",
    "        Returns:\n",
    "            预测结果\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"模型未训练，请先调用train()方法\")\n",
    "\n",
    "        # 确保输入形状正确\n",
    "        if len(X.shape) == 2:\n",
    "            X = X.reshape(-1, 28, 28, 1)\n",
    "        elif len(X.shape) == 3:\n",
    "            X = X.reshape(-1, 28, 28, 1)\n",
    "\n",
    "        predictions = self.model.predict(X)\n",
    "        return np.argmax(predictions, axis=1)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        预测概率\n",
    "\n",
    "        Args:\n",
    "            X: 输入数据\n",
    "\n",
    "        Returns:\n",
    "            预测概率\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"模型未训练，请先调用train()方法\")\n",
    "\n",
    "        # 确保输入形状正确\n",
    "        if len(X.shape) == 2:\n",
    "            X = X.reshape(-1, 28, 28, 1)\n",
    "        elif len(X.shape) == 3:\n",
    "            X = X.reshape(-1, 28, 28, 1)\n",
    "\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        \"\"\"\n",
    "        评估模型\n",
    "\n",
    "        Args:\n",
    "            X: 测试数据\n",
    "            y: 测试标签\n",
    "\n",
    "        Returns:\n",
    "            dict: 评估指标\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"模型未训练，请先调用train()方法\")\n",
    "\n",
    "        loss, accuracy = self.model.evaluate(X, y, verbose=0)\n",
    "\n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'accuracy': accuracy\n",
    "        }\n",
    "\n",
    "    def save_model(self, filepath):\n",
    "        \"\"\"\n",
    "        保存模型\n",
    "\n",
    "        Args:\n",
    "            filepath: 保存路径\n",
    "        \"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"模型未训练，无法保存\")\n",
    "\n",
    "        filepath = Path(filepath)\n",
    "        filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.model.save(filepath)\n",
    "        print(f\"✓ 模型已保存: {filepath}\")\n",
    "\n",
    "    def load_model(self, filepath):\n",
    "        \"\"\"\n",
    "        加载模型\n",
    "\n",
    "        Args:\n",
    "            filepath: 模型路径\n",
    "        \"\"\"\n",
    "        filepath = Path(filepath)\n",
    "        if not filepath.exists():\n",
    "            raise FileNotFoundError(f\"模型文件不存在: {filepath}\")\n",
    "\n",
    "        self.model = keras.models.load_model(filepath)\n",
    "        print(f\"✓ 模型已加载: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1b0057",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_callbacks(model_path, patience=5):\n",
    "    \"\"\"\n",
    "    获取训练回调函数\n",
    "\n",
    "    Args:\n",
    "        model_path: 模型保存路径\n",
    "        patience: 早停耐心值\n",
    "\n",
    "    Returns:\n",
    "        回调函数列表\n",
    "    \"\"\"\n",
    "    callbacks = [\n",
    "        # 早停\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=patience,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "\n",
    "        # 保存最佳模型\n",
    "        ModelCheckpoint(\n",
    "            filepath=model_path,\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "\n",
    "        # 学习率调度\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=3,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba19c0e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    from data import load_mnist_data\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "    print(\"MNIST模型测试\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # 加载数据\n",
    "    (X_train, y_train), (X_test, y_test) = load_mnist_data()\n",
    "\n",
    "    # 使用小样本测试\n",
    "    X_train_small = X_train[:1000]\n",
    "    y_train_small = y_train[:1000]\n",
    "    X_test_small = X_test[:200]\n",
    "    y_test_small = y_test[:200]\n",
    "\n",
    "    # 创建并训练模型\n",
    "    predictor = MNISTPredictor(model_type='simple_cnn')\n",
    "    predictor.train(\n",
    "        X_train_small, y_train_small,\n",
    "        X_test_small, y_test_small,\n",
    "        epochs=3,\n",
    "        batch_size=32\n",
    "    )\n",
    "\n",
    "    # 评估\n",
    "    metrics = predictor.evaluate(X_test_small, y_test_small)\n",
    "    print(f\"\\n测试集性能:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "    print(\"\\n✓ 模型测试完成！\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
