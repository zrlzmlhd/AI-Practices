{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b4cb36c",
   "metadata": {},
   "source": [
    "# 模型训练脚本"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a88fd1",
   "metadata": {},
   "source": [
    "使用方法:\n",
    "    python src/train.py --model_type simple_lstm --epochs 10\n",
    "    python src/train.py --model_type bilstm --epochs 20\n",
    "    python src/train.py --model_type stacked_lstm --epochs 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7002ba62",
   "metadata": {},
   "source": [
    "## Notebook运行提示\n",
    "- 代码已拆分为多个小单元, 按顺序运行即可在每一步观察输出与中间变量。\n",
    "- 涉及 `Path(__file__)` 或相对路径的脚本会自动注入 `__file__` 解析逻辑, Notebook 环境下也能引用原项目资源。\n",
    "- 可在每个单元下追加说明或参数试验记录, 以跟踪核心算法和数据处理步骤。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35863c43",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Notebook路径自适应处理\n",
    "import pathlib as _nb_pathlib\n",
    "def _nb_resolve_file_path():\n",
    "    if '__file__' not in globals():\n",
    "        _cwd = _nb_pathlib.Path.cwd().resolve()\n",
    "        for _candidate in (_cwd, *_cwd.parents):\n",
    "            _potential = _candidate / '09-practical-projects/03_自然语言处理项目/01_情感分析_LSTM入门/src/train.py'\n",
    "            if _potential.exists():\n",
    "                globals()['__file__'] = str(_potential)\n",
    "                return\n",
    "        globals()['__file__'] = str((_cwd / '09-practical-projects/03_自然语言处理项目/01_情感分析_LSTM入门/src/train.py').resolve())\n",
    "_nb_resolve_file_path()\n",
    "del _nb_pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0f0c16",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 添加项目根目录到路径\n",
    "project_root = Path(__file__).parent.parent.parent.parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from data import load_imdb_data\n",
    "from model import LSTMSentimentAnalyzer, get_callbacks\n",
    "from utils.visualization import plot_training_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9010d5f7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"解析命令行参数\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='训练LSTM情感分析模型')\n",
    "\n",
    "    # 模型参数\n",
    "    parser.add_argument('--model_type', type=str, default='simple_lstm',\n",
    "                       choices=['simple_lstm', 'bilstm', 'stacked_lstm'],\n",
    "                       help='模型类型')\n",
    "    parser.add_argument('--max_words', type=int, default=10000,\n",
    "                       help='词汇表大小')\n",
    "    parser.add_argument('--max_len', type=int, default=200,\n",
    "                       help='序列最大长度')\n",
    "\n",
    "    # 训练参数\n",
    "    parser.add_argument('--epochs', type=int, default=10,\n",
    "                       help='训练轮数')\n",
    "    parser.add_argument('--batch_size', type=int, default=32,\n",
    "                       help='批大小')\n",
    "    parser.add_argument('--learning_rate', type=float, default=0.001,\n",
    "                       help='学习率')\n",
    "\n",
    "    # 其他参数\n",
    "    parser.add_argument('--test_size', type=float, default=0.2,\n",
    "                       help='验证集比例')\n",
    "    parser.add_argument('--random_state', type=int, default=42,\n",
    "                       help='随机种子')\n",
    "    parser.add_argument('--patience', type=int, default=5,\n",
    "                       help='早停耐心值')\n",
    "\n",
    "    # 保存路径\n",
    "    parser.add_argument('--model_dir', type=str, default='models',\n",
    "                       help='模型保存目录')\n",
    "    parser.add_argument('--result_dir', type=str, default='results',\n",
    "                       help='结果保存目录')\n",
    "\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5f4a6f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"主函数\"\"\"\n",
    "    # 解析参数\n",
    "    args = parse_args()\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(\"LSTM情感分析 - 模型训练\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\n配置:\")\n",
    "    for arg, value in vars(args).items():\n",
    "        print(f\"  {arg}: {value}\")\n",
    "\n",
    "    # 创建保存目录\n",
    "    project_dir = Path(__file__).parent.parent\n",
    "    model_dir = project_dir / args.model_dir\n",
    "    result_dir = project_dir / args.result_dir\n",
    "    model_dir.mkdir(exist_ok=True)\n",
    "    result_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # 加载数据\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤1: 加载数据\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = load_imdb_data(\n",
    "        max_words=args.max_words,\n",
    "        max_len=args.max_len,\n",
    "        test_size=args.test_size,\n",
    "        random_state=args.random_state\n",
    "    )\n",
    "\n",
    "    # 创建模型\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤2: 创建模型\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    analyzer = LSTMSentimentAnalyzer(\n",
    "        model_type=args.model_type,\n",
    "        max_words=args.max_words,\n",
    "        max_len=args.max_len,\n",
    "        random_state=args.random_state\n",
    "    )\n",
    "\n",
    "    # 设置回调函数\n",
    "    model_path = model_dir / f'{args.model_type}_best.h5'\n",
    "    callbacks = get_callbacks(model_path, patience=args.patience)\n",
    "\n",
    "    # 训练模型\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤3: 训练模型\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    history = analyzer.train(\n",
    "        X_train, y_train,\n",
    "        X_val, y_val,\n",
    "        epochs=args.epochs,\n",
    "        batch_size=args.batch_size,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    # 评估模型\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤4: 评估模型\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # 训练集评估\n",
    "    train_metrics = analyzer.evaluate(X_train, y_train)\n",
    "    print(f\"\\n训练集性能:\")\n",
    "    print(f\"  Loss: {train_metrics['loss']:.4f}\")\n",
    "    print(f\"  Accuracy: {train_metrics['accuracy']:.4f}\")\n",
    "\n",
    "    # 验证集评估\n",
    "    val_metrics = analyzer.evaluate(X_val, y_val)\n",
    "    print(f\"\\n验证集性能:\")\n",
    "    print(f\"  Loss: {val_metrics['loss']:.4f}\")\n",
    "    print(f\"  Accuracy: {val_metrics['accuracy']:.4f}\")\n",
    "\n",
    "    # 测试集评估\n",
    "    test_metrics = analyzer.evaluate(X_test, y_test)\n",
    "    print(f\"\\n测试集性能:\")\n",
    "    print(f\"  Loss: {test_metrics['loss']:.4f}\")\n",
    "    print(f\"  Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "\n",
    "    # 保存模型\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤5: 保存模型\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    final_model_path = model_dir / f'{args.model_type}_final.h5'\n",
    "    analyzer.save_model(final_model_path)\n",
    "\n",
    "    # 绘制训练曲线\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"步骤6: 绘制训练曲线\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    fig = plot_training_history(history.history)\n",
    "    fig_path = result_dir / f'{args.model_type}_training_history.png'\n",
    "    fig.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"✓ 训练曲线已保存: {fig_path}\")\n",
    "\n",
    "    # 保存训练历史\n",
    "    history_path = result_dir / f'{args.model_type}_history.npz'\n",
    "    np.savez(history_path, **history.history)\n",
    "    print(f\"✓ 训练历史已保存: {history_path}\")\n",
    "\n",
    "    # 保存评估结果\n",
    "    results = {\n",
    "        'model_type': args.model_type,\n",
    "        'train_loss': train_metrics['loss'],\n",
    "        'train_accuracy': train_metrics['accuracy'],\n",
    "        'val_loss': val_metrics['loss'],\n",
    "        'val_accuracy': val_metrics['accuracy'],\n",
    "        'test_loss': test_metrics['loss'],\n",
    "        'test_accuracy': test_metrics['accuracy'],\n",
    "    }\n",
    "\n",
    "    results_path = result_dir / f'{args.model_type}_results.txt'\n",
    "    with open(results_path, 'w') as f:\n",
    "        for key, value in results.items():\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "    print(f\"✓ 评估结果已保存: {results_path}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"训练完成！\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\n最佳模型: {model_path}\")\n",
    "    print(f\"最终模型: {final_model_path}\")\n",
    "    print(f\"训练曲线: {fig_path}\")\n",
    "    print(f\"\\n测试集准确率: {test_metrics['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0574a78",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
