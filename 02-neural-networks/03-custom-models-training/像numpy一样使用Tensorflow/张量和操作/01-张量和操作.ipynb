{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5974a54df9e67e24",
   "metadata": {},
   "source": [
    "# TensorFlow张量与基本操作\n",
    "\n",
    "本notebook详细介绍TensorFlow中张量(Tensor)的核心概念与基本操作。张量是TensorFlow的基础数据结构，理解张量操作对于后续的模型构建和自定义训练至关重要。\n",
    "\n",
    "## 学习目标\n",
    "1. 掌握tf.constant创建张量的方法\n",
    "2. 理解张量的shape、dtype等核心属性\n",
    "3. 熟练使用张量索引与切片操作\n",
    "4. 掌握常用的张量数学运算\n",
    "5. 了解张量的广播机制"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup_env",
   "metadata": {},
   "source": [
    "## 1. 环境设置与版本检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import_tf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 设置随机种子以保证结果可复现\n",
    "RANDOM_SEED = 42\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"TensorFlow版本: {tf.__version__}\")\n",
    "print(f\"NumPy版本: {np.__version__}\")\n",
    "\n",
    "# 检查GPU可用性\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"可用GPU数量: {len(gpus)}\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"  - {gpu.name}\")\n",
    "else:\n",
    "    print(\"未检测到GPU，将使用CPU进行计算\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create_tensor_title",
   "metadata": {},
   "source": [
    "## 2. 使用tf.constant创建张量\n",
    "\n",
    "tf.constant是创建不可变张量的主要方法。一旦创建，张量的值不可修改。\n",
    "\n",
    "**核心参数:**\n",
    "- `value`: 张量的值，可以是Python标量、列表或NumPy数组\n",
    "- `dtype`: 数据类型，如tf.float32、tf.int32等\n",
    "- `shape`: 张量形状（可选，用于reshape）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1f84d4d06c52cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个2x3的整型矩阵\n",
    "matrix = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"矩阵内容:\")\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scalar_vector_tensor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建不同维度的张量\n",
    "\n",
    "# 标量(0维张量)\n",
    "scalar = tf.constant(3.14)\n",
    "print(f\"标量: {scalar}, 维度: {scalar.ndim}\")\n",
    "\n",
    "# 向量(1维张量)\n",
    "vector = tf.constant([1, 2, 3, 4, 5])\n",
    "print(f\"向量: {vector}, 维度: {vector.ndim}\")\n",
    "\n",
    "# 矩阵(2维张量)\n",
    "matrix = tf.constant([[1, 2], [3, 4], [5, 6]])\n",
    "print(f\"矩阵:\\n{matrix}, 维度: {matrix.ndim}\")\n",
    "\n",
    "# 3维张量(常用于批量图像数据: batch x height x width)\n",
    "tensor_3d = tf.constant([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "print(f\"3维张量:\\n{tensor_3d}, 维度: {tensor_3d.ndim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dtype_examples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定数据类型创建张量\n",
    "# TensorFlow默认整数为int32，浮点数为float32\n",
    "\n",
    "float32_tensor = tf.constant([1.0, 2.0, 3.0])  # 默认float32\n",
    "float64_tensor = tf.constant([1.0, 2.0, 3.0], dtype=tf.float64)\n",
    "int64_tensor = tf.constant([1, 2, 3], dtype=tf.int64)\n",
    "bool_tensor = tf.constant([True, False, True])\n",
    "string_tensor = tf.constant([\"hello\", \"tensorflow\"])\n",
    "\n",
    "print(f\"float32张量: dtype={float32_tensor.dtype}\")\n",
    "print(f\"float64张量: dtype={float64_tensor.dtype}\")\n",
    "print(f\"int64张量: dtype={int64_tensor.dtype}\")\n",
    "print(f\"布尔张量: dtype={bool_tensor.dtype}\")\n",
    "print(f\"字符串张量: dtype={string_tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tensor_attrs_title",
   "metadata": {},
   "source": [
    "## 3. 张量的核心属性\n",
    "\n",
    "每个张量都有以下重要属性:\n",
    "- `shape`: 张量的形状，表示每个维度的大小\n",
    "- `dtype`: 数据类型\n",
    "- `ndim`: 维度数量（秩/rank）\n",
    "- `device`: 张量所在的设备（CPU/GPU）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d174c94669d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看张量的核心属性\n",
    "sample_tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "print(f\"形状(shape): {sample_tensor.shape}\")\n",
    "print(f\"数据类型(dtype): {sample_tensor.dtype}\")\n",
    "print(f\"维度数(ndim/rank): {sample_tensor.ndim}\")\n",
    "print(f\"总元素数: {tf.size(sample_tensor).numpy()}\")\n",
    "print(f\"所在设备: {sample_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indexing_title",
   "metadata": {},
   "source": [
    "## 4. 张量索引与切片\n",
    "\n",
    "TensorFlow的索引语法与NumPy完全一致，支持:\n",
    "- 基本索引: `tensor[i]`\n",
    "- 切片: `tensor[start:end:step]`\n",
    "- 多维索引: `tensor[i, j]`\n",
    "- 负索引: `tensor[-1]`表示最后一个元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06d17abe3f15510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建示例矩阵\n",
    "matrix = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(f\"原始矩阵:\\n{matrix}\\n\")\n",
    "\n",
    "# 基本索引\n",
    "print(f\"第一行: {matrix[0]}\")\n",
    "print(f\"最后一行: {matrix[-1]}\")\n",
    "print(f\"元素[1,2]: {matrix[1, 2]}\\n\")\n",
    "\n",
    "# 切片操作\n",
    "print(f\"所有行，第2列之后:\\n{matrix[:, 1:]}\\n\")\n",
    "print(f\"前两行，前两列:\\n{matrix[:2, :2]}\\n\")\n",
    "print(f\"隔行取数:\\n{matrix[::2, :]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "math_ops_title",
   "metadata": {},
   "source": [
    "## 5. 张量数学运算\n",
    "\n",
    "TensorFlow支持丰富的数学运算，可通过运算符或函数调用实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c0237161d84851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本算术运算\n",
    "a = tf.constant([[1, 2], [3, 4]], dtype=tf.float32)\n",
    "b = tf.constant([[5, 6], [7, 8]], dtype=tf.float32)\n",
    "\n",
    "print(f\"张量a:\\n{a}\")\n",
    "print(f\"张量b:\\n{b}\\n\")\n",
    "\n",
    "# 加减乘除\n",
    "print(f\"a + b:\\n{a + b}\\n\")\n",
    "print(f\"a - b:\\n{a - b}\\n\")\n",
    "print(f\"a * b (逐元素乘法):\\n{a * b}\\n\")\n",
    "print(f\"a / b (逐元素除法):\\n{a / b}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fac09c98e0060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数学函数\n",
    "x = tf.constant([1.0, 4.0, 9.0, 16.0])\n",
    "\n",
    "print(f\"原始张量: {x}\")\n",
    "print(f\"平方 tf.square: {tf.square(x)}\")\n",
    "print(f\"平方根 tf.sqrt: {tf.sqrt(x)}\")\n",
    "print(f\"指数 tf.exp: {tf.exp(tf.constant([0.0, 1.0, 2.0]))}\")\n",
    "print(f\"对数 tf.math.log: {tf.math.log(tf.constant([1.0, 2.718, 7.389]))}\")\n",
    "print(f\"绝对值 tf.abs: {tf.abs(tf.constant([-1.0, 2.0, -3.0]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9469d4eca609f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 矩阵运算\n",
    "m1 = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "m2 = tf.constant([[7, 8], [9, 10], [11, 12]])\n",
    "\n",
    "print(f\"矩阵m1 (2x3):\\n{m1}\\n\")\n",
    "print(f\"矩阵m2 (3x2):\\n{m2}\\n\")\n",
    "\n",
    "# 矩阵乘法 - 使用@运算符（推荐）或tf.matmul\n",
    "product = m1 @ m2  # 等价于 tf.matmul(m1, m2)\n",
    "print(f\"矩阵乘法 m1 @ m2 (2x2):\\n{product}\\n\")\n",
    "\n",
    "# 矩阵转置\n",
    "print(f\"m1的转置:\\n{tf.transpose(m1)}\\n\")\n",
    "\n",
    "# 矩阵与自身转置的乘积\n",
    "m = tf.constant([[1, 2, 3], [4, 5, 6]], dtype=tf.float32)\n",
    "print(f\"m @ m^T:\\n{m @ tf.transpose(m)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduce_ops_title",
   "metadata": {},
   "source": [
    "## 6. 聚合运算\n",
    "\n",
    "聚合运算用于沿指定轴计算统计量，在神经网络的损失计算、特征归一化等场景中广泛使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduce_ops",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 聚合运算示例\n",
    "tensor = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "print(f\"原始张量:\\n{tensor}\\n\")\n",
    "\n",
    "# 全局聚合\n",
    "print(f\"总和: {tf.reduce_sum(tensor).numpy()}\")\n",
    "print(f\"均值: {tf.reduce_mean(tensor).numpy()}\")\n",
    "print(f\"最大值: {tf.reduce_max(tensor).numpy()}\")\n",
    "print(f\"最小值: {tf.reduce_min(tensor).numpy()}\")\n",
    "print(f\"标准差: {tf.math.reduce_std(tensor).numpy():.4f}\\n\")\n",
    "\n",
    "# 沿指定轴聚合\n",
    "print(f\"沿axis=0求和(按列): {tf.reduce_sum(tensor, axis=0)}\")\n",
    "print(f\"沿axis=1求和(按行): {tf.reduce_sum(tensor, axis=1)}\")\n",
    "print(f\"沿axis=1求均值: {tf.reduce_mean(tensor, axis=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadcast_title",
   "metadata": {},
   "source": [
    "## 7. 广播机制\n",
    "\n",
    "广播(Broadcasting)是一种自动扩展张量形状以匹配运算需求的机制。当两个张量形状不同但兼容时，TensorFlow会自动广播较小的张量。\n",
    "\n",
    "**广播规则:**\n",
    "1. 从右向左比较维度\n",
    "2. 如果维度相等或其中一个为1，则兼容\n",
    "3. 较小的维度会被扩展以匹配较大的维度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadcast_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 广播示例\n",
    "\n",
    "# 标量与矩阵\n",
    "matrix = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "scalar = tf.constant(10)\n",
    "print(f\"矩阵 + 标量:\\n{matrix + scalar}\\n\")\n",
    "\n",
    "# 向量与矩阵\n",
    "row_vector = tf.constant([[1, 2, 3]])  # shape: (1, 3)\n",
    "print(f\"矩阵 shape: {matrix.shape}\")\n",
    "print(f\"行向量 shape: {row_vector.shape}\")\n",
    "print(f\"矩阵 + 行向量 (广播):\\n{matrix + row_vector}\\n\")\n",
    "\n",
    "col_vector = tf.constant([[10], [20]])  # shape: (2, 1)\n",
    "print(f\"列向量 shape: {col_vector.shape}\")\n",
    "print(f\"矩阵 + 列向量 (广播):\\n{matrix + col_vector}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reshape_title",
   "metadata": {},
   "source": [
    "## 8. 张量形状变换\n",
    "\n",
    "形状变换是深度学习中的常见操作，用于调整数据以适配网络层的输入要求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reshape_ops",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 形状变换操作\n",
    "tensor = tf.constant([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    "print(f\"原始张量: {tensor}\")\n",
    "print(f\"原始形状: {tensor.shape}\\n\")\n",
    "\n",
    "# reshape: 改变形状但保持元素总数不变\n",
    "reshaped_2x6 = tf.reshape(tensor, (2, 6))\n",
    "reshaped_3x4 = tf.reshape(tensor, (3, 4))\n",
    "reshaped_2x2x3 = tf.reshape(tensor, (2, 2, 3))\n",
    "\n",
    "print(f\"reshape为(2,6):\\n{reshaped_2x6}\\n\")\n",
    "print(f\"reshape为(3,4):\\n{reshaped_3x4}\\n\")\n",
    "print(f\"reshape为(2,2,3):\\n{reshaped_2x2x3}\\n\")\n",
    "\n",
    "# 使用-1自动推断维度\n",
    "auto_reshape = tf.reshape(tensor, (3, -1))  # -1表示自动计算\n",
    "print(f\"reshape为(3,-1)，自动推断为{auto_reshape.shape}:\\n{auto_reshape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expand_squeeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增加和删除维度\n",
    "tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "print(f\"原始形状: {tensor.shape}\")\n",
    "\n",
    "# expand_dims: 增加维度\n",
    "expanded_0 = tf.expand_dims(tensor, axis=0)\n",
    "expanded_1 = tf.expand_dims(tensor, axis=1)\n",
    "expanded_2 = tf.expand_dims(tensor, axis=2)\n",
    "\n",
    "print(f\"axis=0增加维度后: {expanded_0.shape}\")\n",
    "print(f\"axis=1增加维度后: {expanded_1.shape}\")\n",
    "print(f\"axis=2增加维度后: {expanded_2.shape}\\n\")\n",
    "\n",
    "# squeeze: 删除大小为1的维度\n",
    "tensor_with_1 = tf.constant([[[1, 2, 3]]])  # shape: (1, 1, 3)\n",
    "squeezed = tf.squeeze(tensor_with_1)\n",
    "print(f\"squeeze前: {tensor_with_1.shape}\")\n",
    "print(f\"squeeze后: {squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special_tensors_title",
   "metadata": {},
   "source": [
    "## 9. 特殊张量的创建\n",
    "\n",
    "TensorFlow提供了多种创建特殊张量的方法，常用于权重初始化、掩码创建等场景。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "special_tensors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全零张量\n",
    "zeros = tf.zeros((3, 4))\n",
    "print(f\"全零张量:\\n{zeros}\\n\")\n",
    "\n",
    "# 全一张量\n",
    "ones = tf.ones((2, 3))\n",
    "print(f\"全一张量:\\n{ones}\\n\")\n",
    "\n",
    "# 填充特定值\n",
    "filled = tf.fill((2, 3), 7.0)\n",
    "print(f\"填充7.0的张量:\\n{filled}\\n\")\n",
    "\n",
    "# 单位矩阵\n",
    "identity = tf.eye(4)\n",
    "print(f\"4x4单位矩阵:\\n{identity}\\n\")\n",
    "\n",
    "# 随机张量\n",
    "normal_random = tf.random.normal((3, 3), mean=0.0, stddev=1.0)\n",
    "uniform_random = tf.random.uniform((3, 3), minval=0, maxval=10)\n",
    "print(f\"正态分布随机张量:\\n{normal_random}\\n\")\n",
    "print(f\"均匀分布随机张量:\\n{uniform_random}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concat_stack_title",
   "metadata": {},
   "source": [
    "## 10. 张量拼接与分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concat_stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 张量拼接\n",
    "t1 = tf.constant([[1, 2], [3, 4]])\n",
    "t2 = tf.constant([[5, 6], [7, 8]])\n",
    "\n",
    "# concat: 沿现有维度拼接\n",
    "concat_axis0 = tf.concat([t1, t2], axis=0)\n",
    "concat_axis1 = tf.concat([t1, t2], axis=1)\n",
    "\n",
    "print(f\"t1:\\n{t1}\")\n",
    "print(f\"t2:\\n{t2}\\n\")\n",
    "print(f\"沿axis=0拼接:\\n{concat_axis0}\\n\")\n",
    "print(f\"沿axis=1拼接:\\n{concat_axis1}\\n\")\n",
    "\n",
    "# stack: 创建新维度进行堆叠\n",
    "stacked = tf.stack([t1, t2], axis=0)\n",
    "print(f\"stack堆叠 (创建新维度):\\n形状: {stacked.shape}\\n{stacked}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split_ops",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 张量分割\n",
    "tensor = tf.constant([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
    "print(f\"原始张量:\\n{tensor}\\n\")\n",
    "\n",
    "# split: 均匀分割\n",
    "splits = tf.split(tensor, num_or_size_splits=2, axis=1)\n",
    "print(f\"沿axis=1均分为2份:\")\n",
    "for i, s in enumerate(splits):\n",
    "    print(f\"  第{i+1}份:\\n{s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_title",
   "metadata": {},
   "source": [
    "## 知识点总结\n",
    "\n",
    "| 操作类型 | 常用函数 | 说明 |\n",
    "|---------|---------|------|\n",
    "| 创建张量 | `tf.constant`, `tf.zeros`, `tf.ones`, `tf.fill` | 创建不可变张量 |\n",
    "| 属性查看 | `shape`, `dtype`, `ndim` | 获取张量元信息 |\n",
    "| 数学运算 | `+`, `-`, `*`, `/`, `@`, `tf.matmul` | 基本算术与矩阵运算 |\n",
    "| 聚合运算 | `tf.reduce_sum`, `tf.reduce_mean`, `tf.reduce_max` | 沿轴计算统计量 |\n",
    "| 形状变换 | `tf.reshape`, `tf.expand_dims`, `tf.squeeze` | 改变张量形状 |\n",
    "| 拼接分割 | `tf.concat`, `tf.stack`, `tf.split` | 组合或分解张量 |\n",
    "\n",
    "**关键要点:**\n",
    "1. TensorFlow张量操作语法与NumPy高度一致，降低学习成本\n",
    "2. 张量是不可变的，所有操作都会返回新张量\n",
    "3. 广播机制自动处理形状不匹配的运算\n",
    "4. TensorFlow默认使用float32以优化GPU性能"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
