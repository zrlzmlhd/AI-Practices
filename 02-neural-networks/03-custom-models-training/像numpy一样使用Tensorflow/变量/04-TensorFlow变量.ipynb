{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "920f265f30667a40",
   "metadata": {},
   "source": [
    "# TensorFlow变量（tf.Variable）\n",
    "\n",
    "在TensorFlow中，`tf.Variable`是存储可变状态的核心数据结构。所有模型参数（权重和偏置）都是`tf.Variable`对象。本notebook深入讲解变量的创建、操作和在模型训练中的作用。\n",
    "\n",
    "## 学习目标\n",
    "1. 理解tf.Variable与tf.constant的区别\n",
    "2. 掌握变量的创建和初始化方法\n",
    "3. 学会变量的原地修改操作\n",
    "4. 理解变量在梯度计算中的作用\n",
    "5. 掌握变量的作用域和命名"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "env_setup",
   "metadata": {},
   "source": [
    "## 1. 环境设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import_libs",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 设置随机种子\n",
    "RANDOM_SEED = 42\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"TensorFlow版本: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable_vs_constant_title",
   "metadata": {},
   "source": [
    "## 2. tf.Variable vs tf.constant\n",
    "\n",
    "| 特性 | tf.constant | tf.Variable |\n",
    "|-----|------------|-------------|\n",
    "| 可变性 | 不可变 | 可变 |\n",
    "| 用途 | 固定数据、超参数 | 模型权重、可学习参数 |\n",
    "| 梯度追踪 | 需显式指定 | 默认被追踪 |\n",
    "| 内存 | 可被优化释放 | 持久存储 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.Variable基本创建\n",
    "\n",
    "# 创建一个2x3的变量\n",
    "var = tf.Variable([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"变量内容:\")\n",
    "print(var)\n",
    "print(f\"\\n类型: {type(var)}\")\n",
    "print(f\"形状: {var.shape}\")\n",
    "print(f\"数据类型: {var.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable_vs_constant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.Variable与tf.constant的核心区别\n",
    "\n",
    "# constant: 不可变\n",
    "const = tf.constant([1, 2, 3])\n",
    "print(f\"常量: {const}\")\n",
    "\n",
    "# variable: 可变\n",
    "var = tf.Variable([1, 2, 3])\n",
    "print(f\"变量(初始): {var}\")\n",
    "\n",
    "# 修改变量值\n",
    "var.assign([4, 5, 6])\n",
    "print(f\"变量(修改后): {var}\")\n",
    "\n",
    "# 尝试修改常量会报错\n",
    "# const.assign([4, 5, 6])  # AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'assign'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create_variable_title",
   "metadata": {},
   "source": [
    "## 3. 变量的创建方式\n",
    "\n",
    "### 3.1 基本创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_variable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从不同数据源创建变量\n",
    "\n",
    "# 从Python列表\n",
    "var_from_list = tf.Variable([1.0, 2.0, 3.0])\n",
    "print(f\"从列表创建: {var_from_list}\")\n",
    "\n",
    "# 从NumPy数组\n",
    "np_array = np.array([[1, 2], [3, 4]], dtype=np.float32)\n",
    "var_from_numpy = tf.Variable(np_array)\n",
    "print(f\"从NumPy创建: {var_from_numpy}\")\n",
    "\n",
    "# 从tf.constant\n",
    "const = tf.constant([[5, 6], [7, 8]], dtype=tf.float32)\n",
    "var_from_const = tf.Variable(const)\n",
    "print(f\"从常量创建: {var_from_const}\")\n",
    "\n",
    "# 从另一个变量\n",
    "var_copy = tf.Variable(var_from_list)\n",
    "print(f\"从变量复制: {var_copy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable_attrs_title",
   "metadata": {},
   "source": [
    "### 3.2 指定数据类型和名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable_attrs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定dtype和name\n",
    "\n",
    "# 指定数据类型\n",
    "var_f64 = tf.Variable([1.0, 2.0], dtype=tf.float64)\n",
    "print(f\"float64变量: {var_f64.dtype}\")\n",
    "\n",
    "# 指定名称（用于调试和TensorBoard）\n",
    "weights = tf.Variable(\n",
    "    tf.random.normal([3, 2]),\n",
    "    name=\"layer1_weights\",\n",
    "    dtype=tf.float32\n",
    ")\n",
    "print(f\"\\n命名变量: {weights.name}\")\n",
    "print(f\"权重形状: {weights.shape}\")\n",
    "print(f\"权重值:\\n{weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trainable_title",
   "metadata": {},
   "source": [
    "### 3.3 trainable参数\n",
    "\n",
    "`trainable`参数决定变量是否参与梯度计算和优化器更新。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trainable_param",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainable参数演示\n",
    "\n",
    "# 可训练变量（默认）\n",
    "trainable_var = tf.Variable([1.0, 2.0, 3.0], trainable=True)\n",
    "print(f\"可训练变量: trainable={trainable_var.trainable}\")\n",
    "\n",
    "# 不可训练变量（如批归一化的移动平均）\n",
    "non_trainable_var = tf.Variable([1.0, 2.0, 3.0], trainable=False)\n",
    "print(f\"不可训练变量: trainable={non_trainable_var.trainable}\")\n",
    "\n",
    "# 在梯度计算中的区别\n",
    "with tf.GradientTape() as tape:\n",
    "    y1 = trainable_var * 2\n",
    "    y2 = non_trainable_var * 2\n",
    "\n",
    "grad1 = tape.gradient(y1, trainable_var)\n",
    "print(f\"\\n可训练变量的梯度: {grad1}\")\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y2 = non_trainable_var * 2\n",
    "grad2 = tape.gradient(y2, non_trainable_var)\n",
    "print(f\"不可训练变量的梯度: {grad2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modify_variable_title",
   "metadata": {},
   "source": [
    "## 4. 变量的修改操作\n",
    "\n",
    "变量支持多种原地修改方法，这些操作不会创建新的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modify_variable",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 变量修改方法\n",
    "\n",
    "var = tf.Variable([1.0, 2.0, 3.0, 4.0])\n",
    "print(f\"初始值: {var.numpy()}\")\n",
    "\n",
    "# assign: 完全替换\n",
    "var.assign([5.0, 6.0, 7.0, 8.0])\n",
    "print(f\"assign后: {var.numpy()}\")\n",
    "\n",
    "# assign_add: 原地加法\n",
    "var.assign_add([1.0, 1.0, 1.0, 1.0])\n",
    "print(f\"assign_add后: {var.numpy()}\")\n",
    "\n",
    "# assign_sub: 原地减法\n",
    "var.assign_sub([2.0, 2.0, 2.0, 2.0])\n",
    "print(f\"assign_sub后: {var.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scatter_update",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 部分更新操作\n",
    "\n",
    "var = tf.Variable([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=tf.float32)\n",
    "print(f\"初始值:\\n{var.numpy()}\\n\")\n",
    "\n",
    "# 使用索引修改单个元素\n",
    "var[0, 0].assign(100.0)\n",
    "print(f\"修改[0,0]后:\\n{var.numpy()}\\n\")\n",
    "\n",
    "# 使用切片修改多个元素\n",
    "var[1, :].assign([40.0, 50.0, 60.0])\n",
    "print(f\"修改第2行后:\\n{var.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gradient_title",
   "metadata": {},
   "source": [
    "## 5. 变量与梯度计算\n",
    "\n",
    "`tf.Variable`是深度学习训练的核心，因为`tf.GradientTape`默认追踪所有`tf.Variable`的操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gradient_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 梯度计算示例\n",
    "\n",
    "# 定义可训练参数\n",
    "w = tf.Variable(2.0)\n",
    "b = tf.Variable(1.0)\n",
    "\n",
    "# 输入数据\n",
    "x = tf.constant(3.0)\n",
    "y_true = tf.constant(7.0)  # 真实标签\n",
    "\n",
    "# 前向传播和损失计算\n",
    "with tf.GradientTape() as tape:\n",
    "    y_pred = w * x + b\n",
    "    loss = tf.square(y_pred - y_true)\n",
    "\n",
    "print(f\"输入 x: {x.numpy()}\")\n",
    "print(f\"预测值: {y_pred.numpy()}\")\n",
    "print(f\"真实值: {y_true.numpy()}\")\n",
    "print(f\"损失: {loss.numpy()}\")\n",
    "\n",
    "# 计算梯度\n",
    "gradients = tape.gradient(loss, [w, b])\n",
    "print(f\"\\ndL/dw: {gradients[0].numpy()}\")\n",
    "print(f\"dL/db: {gradients[1].numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "training_step",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟一次训练步骤\n",
    "\n",
    "# 参数初始化\n",
    "w = tf.Variable(2.0)\n",
    "b = tf.Variable(1.0)\n",
    "learning_rate = 0.01\n",
    "\n",
    "# 训练数据\n",
    "x = tf.constant(3.0)\n",
    "y_true = tf.constant(7.0)\n",
    "\n",
    "print(f\"训练前: w={w.numpy()}, b={b.numpy()}\")\n",
    "\n",
    "# 训练步骤\n",
    "for step in range(5):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = w * x + b\n",
    "        loss = tf.square(y_pred - y_true)\n",
    "    \n",
    "    gradients = tape.gradient(loss, [w, b])\n",
    "    \n",
    "    # 手动更新参数\n",
    "    w.assign_sub(learning_rate * gradients[0])\n",
    "    b.assign_sub(learning_rate * gradients[1])\n",
    "    \n",
    "    print(f\"Step {step+1}: loss={loss.numpy():.4f}, w={w.numpy():.4f}, b={b.numpy():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_variables_title",
   "metadata": {},
   "source": [
    "## 6. 在Keras模型中的变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "keras_variables",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras层自动管理变量\n",
    "\n",
    "# 创建简单模型\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(4, activation='relu', input_shape=(3,)),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "# 构建模型\n",
    "model.build()\n",
    "\n",
    "# 查看所有变量\n",
    "print(\"模型所有变量:\")\n",
    "for var in model.variables:\n",
    "    print(f\"  {var.name}: shape={var.shape}, trainable={var.trainable}\")\n",
    "\n",
    "print(f\"\\n可训练变量数量: {len(model.trainable_variables)}\")\n",
    "print(f\"不可训练变量数量: {len(model.non_trainable_variables)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "custom_layer_variables",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义层中的变量管理\n",
    "\n",
    "class CustomDense(tf.keras.layers.Layer):\n",
    "    \"\"\"自定义全连接层，展示变量创建\"\"\"\n",
    "    \n",
    "    def __init__(self, units, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # 创建可训练权重\n",
    "        self.kernel = self.add_weight(\n",
    "            name='kernel',\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer='glorot_uniform',\n",
    "            trainable=True\n",
    "        )\n",
    "        # 创建可训练偏置\n",
    "        self.bias = self.add_weight(\n",
    "            name='bias',\n",
    "            shape=(self.units,),\n",
    "            initializer='zeros',\n",
    "            trainable=True\n",
    "        )\n",
    "        # 创建不可训练的计数器\n",
    "        self.call_count = self.add_weight(\n",
    "            name='call_count',\n",
    "            shape=(),\n",
    "            initializer='zeros',\n",
    "            trainable=False\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        self.call_count.assign_add(1.0)\n",
    "        return tf.matmul(inputs, self.kernel) + self.bias\n",
    "\n",
    "# 测试自定义层\n",
    "layer = CustomDense(5)\n",
    "output = layer(tf.random.normal([2, 3]))\n",
    "\n",
    "print(\"自定义层变量:\")\n",
    "for var in layer.variables:\n",
    "    print(f\"  {var.name}: trainable={var.trainable}\")\n",
    "\n",
    "# 多次调用后检查计数器\n",
    "_ = layer(tf.random.normal([2, 3]))\n",
    "_ = layer(tf.random.normal([2, 3]))\n",
    "print(f\"\\n层被调用次数: {layer.call_count.numpy():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "device_placement_title",
   "metadata": {},
   "source": [
    "## 7. 变量的设备放置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "device_placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看变量所在设备\n",
    "\n",
    "var = tf.Variable([1.0, 2.0, 3.0])\n",
    "print(f\"变量设备: {var.device}\")\n",
    "\n",
    "# 在特定设备上创建变量\n",
    "with tf.device('/CPU:0'):\n",
    "    cpu_var = tf.Variable([1.0, 2.0], name='cpu_var')\n",
    "    print(f\"CPU变量设备: {cpu_var.device}\")\n",
    "\n",
    "# 如果有GPU\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    with tf.device('/GPU:0'):\n",
    "        gpu_var = tf.Variable([1.0, 2.0], name='gpu_var')\n",
    "        print(f\"GPU变量设备: {gpu_var.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checkpoint_title",
   "metadata": {},
   "source": [
    "## 8. 变量的保存和加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checkpoint_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "# 使用tf.train.Checkpoint保存变量\n",
    "\n",
    "# 创建变量\n",
    "w = tf.Variable([1.0, 2.0, 3.0], name='weights')\n",
    "b = tf.Variable([0.0], name='bias')\n",
    "\n",
    "print(f\"保存前: w={w.numpy()}, b={b.numpy()}\")\n",
    "\n",
    "# 创建检查点\n",
    "checkpoint = tf.train.Checkpoint(weights=w, bias=b)\n",
    "\n",
    "# 保存到临时目录\n",
    "with tempfile.TemporaryDirectory() as tmpdir:\n",
    "    save_path = checkpoint.save(os.path.join(tmpdir, 'ckpt'))\n",
    "    print(f\"保存路径: {save_path}\")\n",
    "    \n",
    "    # 修改变量值\n",
    "    w.assign([10.0, 20.0, 30.0])\n",
    "    b.assign([5.0])\n",
    "    print(f\"修改后: w={w.numpy()}, b={b.numpy()}\")\n",
    "    \n",
    "    # 恢复变量\n",
    "    checkpoint.restore(save_path)\n",
    "    print(f\"恢复后: w={w.numpy()}, b={b.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "best_practices_title",
   "metadata": {},
   "source": [
    "## 9. 最佳实践"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "best_practices",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最佳实践示例\n",
    "\n",
    "# 1. 使用有意义的名称\n",
    "def create_layer_variables(input_dim, output_dim, layer_name):\n",
    "    \"\"\"创建带有清晰命名的层变量\"\"\"\n",
    "    weights = tf.Variable(\n",
    "        tf.random.normal([input_dim, output_dim], stddev=0.1),\n",
    "        name=f'{layer_name}/weights'\n",
    "    )\n",
    "    bias = tf.Variable(\n",
    "        tf.zeros([output_dim]),\n",
    "        name=f'{layer_name}/bias'\n",
    "    )\n",
    "    return weights, bias\n",
    "\n",
    "w1, b1 = create_layer_variables(10, 5, 'hidden_layer')\n",
    "print(f\"权重名称: {w1.name}\")\n",
    "print(f\"偏置名称: {b1.name}\")\n",
    "\n",
    "# 2. 使用适当的初始化\n",
    "print(\"\\n常用初始化方法:\")\n",
    "print(f\"Xavier/Glorot: {tf.keras.initializers.GlorotUniform()(shape=(2, 2))}\")\n",
    "print(f\"He: {tf.keras.initializers.HeNormal()(shape=(2, 2))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_section",
   "metadata": {},
   "source": [
    "## 知识点总结\n",
    "\n",
    "### 变量操作速查表\n",
    "\n",
    "| 操作 | 方法 | 说明 |\n",
    "|-----|------|------|\n",
    "| 创建变量 | `tf.Variable(initial_value)` | 初始值必须提供 |\n",
    "| 完全赋值 | `var.assign(value)` | 替换所有值 |\n",
    "| 原地加法 | `var.assign_add(value)` | var += value |\n",
    "| 原地减法 | `var.assign_sub(value)` | var -= value |\n",
    "| 索引修改 | `var[i].assign(value)` | 修改特定位置 |\n",
    "| 读取值 | `var.numpy()` | 转换为NumPy数组 |\n",
    "\n",
    "### 关键要点\n",
    "\n",
    "1. **tf.Variable是可变的，tf.constant是不可变的**\n",
    "2. **trainable参数控制是否参与梯度计算**\n",
    "3. **tf.GradientTape默认追踪所有tf.Variable**\n",
    "4. **使用assign系列方法进行原地修改**\n",
    "5. **Keras层使用add_weight自动管理变量**\n",
    "6. **使用tf.train.Checkpoint保存和恢复变量**\n",
    "7. **为变量命名有助于调试和TensorBoard可视化**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
