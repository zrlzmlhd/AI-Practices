{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd5898abd45a761",
   "metadata": {},
   "source": [
    "# TensorFlow张量与NumPy互操作\n",
    "\n",
    "TensorFlow与NumPy的紧密集成是其设计的核心特性之一。本notebook详细探讨两者之间的数据转换、互操作注意事项及性能影响。\n",
    "\n",
    "## 学习目标\n",
    "1. 掌握TensorFlow张量与NumPy数组的双向转换\n",
    "2. 理解默认数据类型差异及其影响\n",
    "3. 了解数据转换的性能开销\n",
    "4. 掌握在实际项目中的最佳实践"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "env_setup",
   "metadata": {},
   "source": [
    "## 1. 环境设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import_libs",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# 设置随机种子\n",
    "RANDOM_SEED = 42\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"TensorFlow版本: {tf.__version__}\")\n",
    "print(f\"NumPy版本: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conversion_title",
   "metadata": {},
   "source": [
    "## 2. 数据类型转换基础\n",
    "\n",
    "### 2.1 NumPy数组转TensorFlow张量\n",
    "\n",
    "使用`tf.constant()`或`tf.convert_to_tensor()`将NumPy数组转换为TensorFlow张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c393bd2a262e1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy数组转TensorFlow张量\n",
    "np_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(f\"NumPy数组:\\n{np_array}\")\n",
    "print(f\"NumPy dtype: {np_array.dtype}\\n\")\n",
    "\n",
    "# 方法1: 使用tf.constant\n",
    "tensor_from_constant = tf.constant(np_array)\n",
    "print(f\"tf.constant转换结果: {tensor_from_constant}\")\n",
    "\n",
    "# 方法2: 使用tf.convert_to_tensor\n",
    "tensor_from_convert = tf.convert_to_tensor(np_array)\n",
    "print(f\"tf.convert_to_tensor转换结果: {tensor_from_convert}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tensor_to_numpy_title",
   "metadata": {},
   "source": [
    "### 2.2 TensorFlow张量转NumPy数组\n",
    "\n",
    "使用`.numpy()`方法或`np.array()`函数将张量转换回NumPy数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tensor_to_numpy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow张量转NumPy数组\n",
    "tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "print(f\"TensorFlow张量:\\n{tensor}\\n\")\n",
    "\n",
    "# 方法1: 使用.numpy()方法（推荐）\n",
    "np_from_numpy_method = tensor.numpy()\n",
    "print(f\".numpy()方法结果:\\n{np_from_numpy_method}\")\n",
    "print(f\"类型: {type(np_from_numpy_method)}\\n\")\n",
    "\n",
    "# 方法2: 使用np.array()\n",
    "np_from_array = np.array(tensor)\n",
    "print(f\"np.array()结果:\\n{np_from_array}\")\n",
    "print(f\"类型: {type(np_from_array)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dtype_diff_title",
   "metadata": {},
   "source": [
    "## 3. 默认数据类型差异\n",
    "\n",
    "**关键差异:**\n",
    "- NumPy默认浮点类型: `float64` (双精度)\n",
    "- TensorFlow默认浮点类型: `float32` (单精度)\n",
    "\n",
    "这一差异源于GPU计算优化——`float32`在GPU上的计算速度通常是`float64`的2-8倍，且对于大多数深度学习任务，单精度已经足够。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b318b2da5555e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 默认数据类型对比\n",
    "\n",
    "# NumPy默认float64\n",
    "np_float_array = np.array([1.0, 2.0, 3.0])\n",
    "print(f\"NumPy默认浮点类型: {np_float_array.dtype}\")\n",
    "\n",
    "# TensorFlow默认float32\n",
    "tf_float_tensor = tf.constant([1.0, 2.0, 3.0])\n",
    "print(f\"TensorFlow默认浮点类型: {tf_float_tensor.dtype}\\n\")\n",
    "\n",
    "# 整数类型对比\n",
    "np_int_array = np.array([1, 2, 3])\n",
    "tf_int_tensor = tf.constant([1, 2, 3])\n",
    "print(f\"NumPy默认整数类型: {np_int_array.dtype}\")\n",
    "print(f\"TensorFlow默认整数类型: {tf_int_tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dtype_convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保持数据类型一致的最佳实践\n",
    "\n",
    "# 方法1: NumPy创建时指定float32\n",
    "np_array_f32 = np.array([1.0, 2.0, 3.0], dtype=np.float32)\n",
    "tensor_f32 = tf.constant(np_array_f32)\n",
    "print(f\"指定NumPy为float32后转换: {tensor_f32.dtype}\")\n",
    "\n",
    "# 方法2: TensorFlow转换时指定dtype\n",
    "np_array_f64 = np.array([1.0, 2.0, 3.0])  # 默认float64\n",
    "tensor_converted = tf.constant(np_array_f64, dtype=tf.float32)\n",
    "print(f\"转换时指定dtype: {tensor_converted.dtype}\")\n",
    "\n",
    "# 方法3: 使用tf.cast进行类型转换\n",
    "tensor_f64 = tf.constant([1.0, 2.0, 3.0], dtype=tf.float64)\n",
    "tensor_casted = tf.cast(tensor_f64, dtype=tf.float32)\n",
    "print(f\"使用tf.cast转换: {tensor_casted.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mixed_ops_title",
   "metadata": {},
   "source": [
    "## 4. 混合运算\n",
    "\n",
    "TensorFlow操作可以直接接受NumPy数组作为输入，框架会自动进行转换。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mixed_operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 混合运算示例\n",
    "\n",
    "np_array = np.array([[1, 2], [3, 4]], dtype=np.float32)\n",
    "tf_tensor = tf.constant([[5, 6], [7, 8]], dtype=tf.float32)\n",
    "\n",
    "# TensorFlow操作直接接受NumPy数组\n",
    "result_add = tf.add(np_array, tf_tensor)\n",
    "print(f\"tf.add(NumPy, Tensor):\\n{result_add}\\n\")\n",
    "\n",
    "# 运算符也支持混合运算\n",
    "result_mul = np_array * tf_tensor\n",
    "print(f\"NumPy * Tensor:\\n{result_mul}\\n\")\n",
    "\n",
    "# 矩阵乘法\n",
    "result_matmul = tf.matmul(np_array, tf_tensor)\n",
    "print(f\"tf.matmul(NumPy, Tensor):\\n{result_matmul}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "memory_sharing_title",
   "metadata": {},
   "source": [
    "## 5. 内存共享与数据复制\n",
    "\n",
    "理解数据转换时的内存行为对于优化性能至关重要。\n",
    "\n",
    "**核心规则:**\n",
    "- CPU上的张量与NumPy数组可能共享内存\n",
    "- GPU上的张量转换为NumPy时必须复制数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "memory_behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 内存共享验证\n",
    "\n",
    "# 创建NumPy数组\n",
    "np_original = np.array([1, 2, 3, 4], dtype=np.float32)\n",
    "print(f\"原始NumPy数组: {np_original}\")\n",
    "\n",
    "# 转换为张量（CPU上可能共享内存）\n",
    "tensor = tf.constant(np_original)\n",
    "\n",
    "# 张量转回NumPy\n",
    "np_converted = tensor.numpy()\n",
    "print(f\"转换后的NumPy数组: {np_converted}\")\n",
    "\n",
    "# 检查是否共享内存（仅在CPU上可能为True）\n",
    "print(f\"\\n内存地址比较:\")\n",
    "print(f\"原始数组地址: {np_original.__array_interface__['data'][0]}\")\n",
    "print(f\"转换数组地址: {np_converted.__array_interface__['data'][0]}\")\n",
    "print(f\"是否共享内存: {np.shares_memory(np_original, np_converted)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "performance_title",
   "metadata": {},
   "source": [
    "## 6. 性能考量\n",
    "\n",
    "频繁的类型转换会带来显著的性能开销，特别是在GPU训练场景中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "performance_test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 性能测试: 转换开销\n",
    "\n",
    "# 创建大型数组\n",
    "large_np_array = np.random.randn(1000, 1000).astype(np.float32)\n",
    "\n",
    "# 测试NumPy到TensorFlow的转换时间\n",
    "n_iterations = 100\n",
    "\n",
    "start_time = time.time()\n",
    "for _ in range(n_iterations):\n",
    "    tensor = tf.constant(large_np_array)\n",
    "elapsed_np_to_tf = time.time() - start_time\n",
    "\n",
    "print(f\"NumPy -> TensorFlow ({n_iterations}次): {elapsed_np_to_tf:.4f}秒\")\n",
    "print(f\"平均每次: {elapsed_np_to_tf/n_iterations*1000:.2f}毫秒\\n\")\n",
    "\n",
    "# 测试TensorFlow到NumPy的转换时间\n",
    "tensor = tf.constant(large_np_array)\n",
    "\n",
    "start_time = time.time()\n",
    "for _ in range(n_iterations):\n",
    "    np_array = tensor.numpy()\n",
    "elapsed_tf_to_np = time.time() - start_time\n",
    "\n",
    "print(f\"TensorFlow -> NumPy ({n_iterations}次): {elapsed_tf_to_np:.4f}秒\")\n",
    "print(f\"平均每次: {elapsed_tf_to_np/n_iterations*1000:.2f}毫秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "best_practices_title",
   "metadata": {},
   "source": [
    "## 7. 最佳实践\n",
    "\n",
    "### 7.1 数据预处理阶段的建议"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "best_practice_preprocess",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最佳实践: 数据预处理\n",
    "\n",
    "# 反面示例: 每次循环都进行转换（低效）\n",
    "def inefficient_preprocessing(data_list):\n",
    "    results = []\n",
    "    for data in data_list:\n",
    "        # 每次迭代都进行转换，产生额外开销\n",
    "        tensor = tf.constant(data)\n",
    "        processed = tf.nn.relu(tensor)\n",
    "        results.append(processed.numpy())\n",
    "    return results\n",
    "\n",
    "# 正面示例: 批量处理（高效）\n",
    "def efficient_preprocessing(data_list):\n",
    "    # 一次性转换所有数据\n",
    "    batch_tensor = tf.constant(np.array(data_list))\n",
    "    # 批量处理\n",
    "    processed = tf.nn.relu(batch_tensor)\n",
    "    return processed.numpy()\n",
    "\n",
    "# 性能对比\n",
    "test_data = [np.random.randn(100, 100).astype(np.float32) for _ in range(50)]\n",
    "\n",
    "start = time.time()\n",
    "_ = inefficient_preprocessing(test_data)\n",
    "print(f\"低效方法耗时: {time.time() - start:.4f}秒\")\n",
    "\n",
    "start = time.time()\n",
    "_ = efficient_preprocessing(test_data)\n",
    "print(f\"高效方法耗时: {time.time() - start:.4f}秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "use_tf_data_title",
   "metadata": {},
   "source": [
    "### 7.2 使用tf.data构建数据管道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tf_data_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用tf.data构建高效数据管道\n",
    "\n",
    "# 模拟训练数据\n",
    "X_train = np.random.randn(1000, 10).astype(np.float32)\n",
    "y_train = np.random.randint(0, 2, size=(1000,)).astype(np.float32)\n",
    "\n",
    "# 创建tf.data.Dataset（推荐方式）\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "dataset = dataset.shuffle(buffer_size=1000)\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)  # 异步预取\n",
    "\n",
    "# 验证数据管道\n",
    "for batch_x, batch_y in dataset.take(1):\n",
    "    print(f\"批次X形状: {batch_x.shape}\")\n",
    "    print(f\"批次X类型: {batch_x.dtype}\")\n",
    "    print(f\"批次y形状: {batch_y.shape}\")\n",
    "    print(f\"批次y类型: {batch_y.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "avoid_mixing_title",
   "metadata": {},
   "source": [
    "### 7.3 避免在计算图中混用NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "avoid_mixing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在@tf.function中避免使用NumPy操作\n",
    "\n",
    "# 反面示例: 在tf.function中使用NumPy（会破坏图优化）\n",
    "@tf.function\n",
    "def bad_function(x):\n",
    "    # 下面这行会触发eager执行，破坏图优化\n",
    "    # numpy_result = np.square(x.numpy())  # 不要这样做！\n",
    "    pass\n",
    "\n",
    "# 正面示例: 完全使用TensorFlow操作\n",
    "@tf.function\n",
    "def good_function(x):\n",
    "    return tf.square(x)\n",
    "\n",
    "# 性能对比\n",
    "test_tensor = tf.random.normal((1000, 1000))\n",
    "\n",
    "# 预热\n",
    "_ = good_function(test_tensor)\n",
    "\n",
    "# 测试tf.function性能\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    _ = good_function(test_tensor)\n",
    "print(f\"tf.function计算耗时: {time.time() - start:.4f}秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interop_summary_title",
   "metadata": {},
   "source": [
    "## 8. 互操作性功能汇总"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interop_summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 常用互操作函数汇总\n",
    "\n",
    "np_array = np.array([1.0, 2.0, 3.0], dtype=np.float32)\n",
    "tf_tensor = tf.constant([4.0, 5.0, 6.0])\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"NumPy -> TensorFlow 转换方法\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"tf.constant(np_array): {tf.constant(np_array)}\")\n",
    "print(f\"tf.convert_to_tensor(np_array): {tf.convert_to_tensor(np_array)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"TensorFlow -> NumPy 转换方法\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"tensor.numpy(): {tf_tensor.numpy()}\")\n",
    "print(f\"np.array(tensor): {np.array(tf_tensor)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"类型转换\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"tf.cast(tensor, tf.float64): {tf.cast(tf_tensor, tf.float64)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary_section",
   "metadata": {},
   "source": [
    "## 知识点总结\n",
    "\n",
    "| 场景 | 推荐做法 | 原因 |\n",
    "|-----|---------|------|\n",
    "| 数据准备 | 使用`np.float32` | 与TensorFlow默认类型一致 |\n",
    "| 数据加载 | 使用`tf.data.Dataset` | 自动优化、异步预取 |\n",
    "| 模型计算 | 避免`.numpy()`调用 | 保持在GPU上计算 |\n",
    "| 结果提取 | 训练结束后再转换 | 减少数据传输 |\n",
    "\n",
    "**关键要点:**\n",
    "1. NumPy默认`float64`，TensorFlow默认`float32`，需注意类型统一\n",
    "2. 频繁的类型转换会带来性能开销，应批量处理\n",
    "3. 在`@tf.function`中应完全使用TensorFlow操作\n",
    "4. 优先使用`tf.data`管道而非手动转换\n",
    "5. GPU上的张量转NumPy需要数据复制，应避免在训练循环中使用"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
