{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# Keras 预处理层与自定义数据处理\n",
    "\n",
    "Keras 预处理层将数据转换逻辑封装为模型的一部分，确保训练和推理时的一致性。本教程深入讲解内置预处理层和自定义层的实现。\n",
    "\n",
    "## 核心知识点\n",
    "\n",
    "1. 自定义预处理层的设计与实现\n",
    "2. Keras 内置 Normalization、Rescaling 层\n",
    "3. 分类特征编码：StringLookup、CategoryEncoding、Embedding\n",
    "4. 预处理层与模型的集成策略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "# 固定随机种子\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"Keras: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4e5f6",
   "metadata": {},
   "source": [
    "## 1. 自定义预处理层\n",
    "\n",
    "### 1.1 为什么需要自定义层\n",
    "\n",
    "内置层覆盖常见场景，但特殊需求需要自定义实现：\n",
    "\n",
    "- 特定领域的归一化方法\n",
    "- 复杂的特征工程逻辑\n",
    "- 需要从数据中学习参数的转换\n",
    "\n",
    "### 1.2 自定义标准化层\n",
    "\n",
    "Z-score 标准化公式：\n",
    "\n",
    "$$z = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "其中 $\\mu$ 是均值，$\\sigma$ 是标准差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e5f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomStandardization(layers.Layer):\n",
    "    \"\"\"自定义 Z-score 标准化层\n",
    "    \n",
    "    将输入数据转换为均值为 0、标准差为 1 的分布。\n",
    "    支持通过 adapt() 方法从数据中学习统计量。\n",
    "    \n",
    "    Attributes:\n",
    "        epsilon: 防止除零的小常数\n",
    "        means_: 学习到的特征均值\n",
    "        stds_: 学习到的特征标准差\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, epsilon=1e-7, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "        self.means_ = None\n",
    "        self.stds_ = None\n",
    "    \n",
    "    def adapt(self, data):\n",
    "        \"\"\"从数据中学习均值和标准差\n",
    "        \n",
    "        Args:\n",
    "            data: 训练数据，numpy 数组或 tf.Tensor\n",
    "        \"\"\"\n",
    "        data = np.asarray(data, dtype=np.float32)\n",
    "        self.means_ = np.mean(data, axis=0, keepdims=True)\n",
    "        self.stds_ = np.std(data, axis=0, keepdims=True)\n",
    "        # 处理常数特征（标准差为 0）\n",
    "        self.stds_ = np.where(self.stds_ < self.epsilon, 1.0, self.stds_)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \"\"\"应用标准化转换\"\"\"\n",
    "        if self.means_ is None:\n",
    "            raise RuntimeError(\"层未初始化，请先调用 adapt()\")\n",
    "        inputs = tf.cast(inputs, tf.float32)\n",
    "        return (inputs - self.means_) / self.stds_\n",
    "    \n",
    "    def inverse_transform(self, normalized):\n",
    "        \"\"\"逆变换：将标准化数据还原到原始尺度\"\"\"\n",
    "        return normalized * self.stds_ + self.means_\n",
    "    \n",
    "    def get_config(self):\n",
    "        \"\"\"序列化配置\"\"\"\n",
    "        config = super().get_config()\n",
    "        config.update({\"epsilon\": self.epsilon})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试自定义标准化层\n",
    "# 构造不同尺度的特征\n",
    "test_data = np.array([\n",
    "    [100.0, 0.1, 50.0],\n",
    "    [120.0, 0.2, 60.0],\n",
    "    [80.0, 0.15, 40.0],\n",
    "    [110.0, 0.25, 55.0],\n",
    "    [90.0, 0.12, 45.0],\n",
    "], dtype=np.float32)\n",
    "\n",
    "print(\"原始数据:\")\n",
    "print(test_data)\n",
    "print(f\"\\n各特征均值: {test_data.mean(axis=0)}\")\n",
    "print(f\"各特征标准差: {test_data.std(axis=0)}\")\n",
    "\n",
    "# 创建并适配层\n",
    "standardizer = CustomStandardization()\n",
    "standardizer.adapt(test_data)\n",
    "\n",
    "# 应用标准化\n",
    "normalized = standardizer(test_data)\n",
    "print(f\"\\n标准化后均值: {normalized.numpy().mean(axis=0)}\")\n",
    "print(f\"标准化后标准差: {normalized.numpy().std(axis=0)}\")\n",
    "\n",
    "# 验证逆变换\n",
    "restored = standardizer.inverse_transform(normalized)\n",
    "print(f\"\\n逆变换误差: {np.abs(restored.numpy() - test_data).max():.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a7b8c9",
   "metadata": {},
   "source": [
    "### 1.3 自定义归一化层\n",
    "\n",
    "Min-Max 归一化公式：\n",
    "\n",
    "$$x_{norm} = \\frac{x - x_{min}}{x_{max} - x_{min}}$$\n",
    "\n",
    "将数据缩放到 [0, 1] 或指定范围。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomMinMaxNormalization(layers.Layer):\n",
    "    \"\"\"自定义 Min-Max 归一化层\n",
    "    \n",
    "    将数据缩放到指定范围，默认 [0, 1]。\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, feature_range=(0, 1), epsilon=1e-7, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.feature_range = feature_range\n",
    "        self.epsilon = epsilon\n",
    "        self.data_min_ = None\n",
    "        self.data_max_ = None\n",
    "    \n",
    "    def adapt(self, data):\n",
    "        \"\"\"从数据中学习最小值和最大值\"\"\"\n",
    "        data = np.asarray(data, dtype=np.float32)\n",
    "        self.data_min_ = np.min(data, axis=0, keepdims=True)\n",
    "        self.data_max_ = np.max(data, axis=0, keepdims=True)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \"\"\"应用归一化转换\"\"\"\n",
    "        if self.data_min_ is None:\n",
    "            raise RuntimeError(\"层未初始化，请先调用 adapt()\")\n",
    "        \n",
    "        inputs = tf.cast(inputs, tf.float32)\n",
    "        data_range = self.data_max_ - self.data_min_\n",
    "        # 处理常数特征\n",
    "        data_range = tf.where(data_range < self.epsilon, 1.0, data_range)\n",
    "        \n",
    "        # 缩放到 [0, 1]\n",
    "        scaled = (inputs - self.data_min_) / data_range\n",
    "        \n",
    "        # 转换到目标范围\n",
    "        min_val, max_val = self.feature_range\n",
    "        return scaled * (max_val - min_val) + min_val\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"feature_range\": self.feature_range,\n",
    "            \"epsilon\": self.epsilon,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试归一化层\n",
    "normalizer = CustomMinMaxNormalization()\n",
    "normalizer.adapt(test_data)\n",
    "\n",
    "normalized = normalizer(test_data)\n",
    "print(f\"归一化到 [0, 1]:\")\n",
    "print(f\"  范围: [{normalized.numpy().min():.4f}, {normalized.numpy().max():.4f}]\")\n",
    "\n",
    "# 测试自定义范围\n",
    "normalizer_custom = CustomMinMaxNormalization(feature_range=(-1, 1))\n",
    "normalizer_custom.adapt(test_data)\n",
    "normalized_custom = normalizer_custom(test_data)\n",
    "print(f\"\\n归一化到 [-1, 1]:\")\n",
    "print(f\"  范围: [{normalized_custom.numpy().min():.4f}, {normalized_custom.numpy().max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0e1f2",
   "metadata": {},
   "source": [
    "## 2. Keras 内置预处理层\n",
    "\n",
    "### 2.1 Normalization 层\n",
    "\n",
    "Keras 内置的 Z-score 标准化实现，功能完整且经过优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成不同尺度的特征数据\n",
    "np.random.seed(42)\n",
    "train_features = np.random.randn(1000, 5).astype(np.float32)\n",
    "train_features[:, 0] *= 100   # 特征 0: 大尺度\n",
    "train_features[:, 1] *= 0.01  # 特征 1: 小尺度\n",
    "train_features[:, 2] += 50    # 特征 2: 偏移\n",
    "\n",
    "print(\"原始特征统计:\")\n",
    "for i in range(5):\n",
    "    print(f\"  特征 {i}: 均值={train_features[:, i].mean():8.4f}, \"\n",
    "          f\"标准差={train_features[:, i].std():8.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 Keras Normalization 层\n",
    "keras_normalizer = layers.Normalization(axis=-1)\n",
    "keras_normalizer.adapt(train_features)\n",
    "\n",
    "# 查看学习到的参数\n",
    "print(\"学习到的均值:\")\n",
    "print(f\"  {keras_normalizer.mean.numpy().flatten()}\")\n",
    "print(\"\\n学习到的方差:\")\n",
    "print(f\"  {keras_normalizer.variance.numpy().flatten()}\")\n",
    "\n",
    "# 应用标准化\n",
    "normalized = keras_normalizer(train_features)\n",
    "print(\"\\n标准化后统计:\")\n",
    "for i in range(5):\n",
    "    col = normalized[:, i].numpy()\n",
    "    print(f\"  特征 {i}: 均值={col.mean():8.4f}, 标准差={col.std():8.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a3b4c5",
   "metadata": {},
   "source": [
    "### 2.2 Rescaling 层\n",
    "\n",
    "线性缩放层，常用于图像像素值归一化。\n",
    "\n",
    "公式：$y = x \\times scale + offset$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟图像数据 (0-255 像素值)\n",
    "fake_images = np.random.randint(0, 256, size=(4, 28, 28, 1)).astype(np.float32)\n",
    "print(f\"原始像素范围: [{fake_images.min()}, {fake_images.max()}]\")\n",
    "\n",
    "# 缩放到 [0, 1]\n",
    "rescaler_01 = layers.Rescaling(scale=1.0/255)\n",
    "scaled_01 = rescaler_01(fake_images)\n",
    "print(f\"缩放到 [0, 1]: [{scaled_01.numpy().min():.4f}, {scaled_01.numpy().max():.4f}]\")\n",
    "\n",
    "# 缩放到 [-1, 1]（常用于预训练模型）\n",
    "rescaler_11 = layers.Rescaling(scale=1.0/127.5, offset=-1)\n",
    "scaled_11 = rescaler_11(fake_images)\n",
    "print(f\"缩放到 [-1, 1]: [{scaled_11.numpy().min():.4f}, {scaled_11.numpy().max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5d6e7",
   "metadata": {},
   "source": [
    "## 3. 分类特征编码\n",
    "\n",
    "### 3.1 StringLookup：字符串索引化\n",
    "\n",
    "将字符串映射为整数索引，处理词汇表外（OOV）的输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义词汇表\n",
    "weather_vocab = [\"晴天\", \"多云\", \"阴天\", \"小雨\", \"大雨\", \"雪\"]\n",
    "\n",
    "# 创建查找层\n",
    "weather_lookup = layers.StringLookup(\n",
    "    vocabulary=weather_vocab,\n",
    "    output_mode=\"int\"\n",
    ")\n",
    "\n",
    "# 查看词汇表（索引 0 是 OOV）\n",
    "print(\"词汇表:\")\n",
    "for i, word in enumerate(weather_lookup.get_vocabulary()):\n",
    "    print(f\"  索引 {i}: {word}\")\n",
    "\n",
    "# 测试转换\n",
    "test_weather = tf.constant([\"晴天\", \"小雨\", \"未知天气\", \"多云\"])\n",
    "indices = weather_lookup(test_weather)\n",
    "\n",
    "print(f\"\\n输入: {[w.numpy().decode() for w in test_weather]}\")\n",
    "print(f\"索引: {indices.numpy()}\")\n",
    "print(\"注意: '未知天气' 被映射到索引 0 (OOV)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7f8a9",
   "metadata": {},
   "source": [
    "### 3.2 CategoryEncoding：类别编码\n",
    "\n",
    "将整数索引转换为独热编码或多热编码。\n",
    "\n",
    "**适用场景**：低基数分类特征（类别数 < 50）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建独热编码层\n",
    "# num_tokens = 词汇表大小 + 1 (OOV)\n",
    "category_encoder = layers.CategoryEncoding(\n",
    "    num_tokens=len(weather_vocab) + 1,\n",
    "    output_mode=\"one_hot\"\n",
    ")\n",
    "\n",
    "# 应用编码\n",
    "one_hot = category_encoder(indices)\n",
    "\n",
    "print(\"独热编码结果:\")\n",
    "for i, (weather, idx) in enumerate(zip(test_weather.numpy(), indices.numpy())):\n",
    "    print(f\"  {weather.decode()}: 索引={idx}, 编码={one_hot[i].numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a9b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 封装完整的字符串到独热编码流程\n",
    "def create_string_to_onehot(vocabulary):\n",
    "    \"\"\"创建字符串到独热编码的转换函数\n",
    "    \n",
    "    Args:\n",
    "        vocabulary: 类别词汇表\n",
    "        \n",
    "    Returns:\n",
    "        编码函数\n",
    "    \"\"\"\n",
    "    lookup = layers.StringLookup(vocabulary=vocabulary, output_mode=\"int\")\n",
    "    encoder = layers.CategoryEncoding(\n",
    "        num_tokens=len(vocabulary) + 1,\n",
    "        output_mode=\"one_hot\"\n",
    "    )\n",
    "    \n",
    "    def encode(inputs):\n",
    "        return encoder(lookup(inputs))\n",
    "    \n",
    "    return encode\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "color_encoder = create_string_to_onehot([\"红\", \"绿\", \"蓝\", \"黄\"])\n",
    "colors = tf.constant([\"红\", \"蓝\", \"白\"])  # \"白\" 是未知类别\n",
    "encoded = color_encoder(colors)\n",
    "\n",
    "print(\"颜色编码:\")\n",
    "for color, enc in zip(colors.numpy(), encoded.numpy()):\n",
    "    print(f\"  {color.decode()}: {enc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b0c1d2",
   "metadata": {},
   "source": [
    "### 3.3 Embedding 层：高基数特征\n",
    "\n",
    "当类别数量很大时（如用户 ID、商品 ID），独热编码产生高维稀疏向量。Embedding 层将离散索引映射到低维稠密向量。\n",
    "\n",
    "**优势**：\n",
    "- 参数高效：N 个类别只需 N × D 个参数（D 是嵌入维度）\n",
    "- 可学习相似性：相似类别的嵌入向量会在训练中趋近"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c1d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟用户 ID 场景\n",
    "NUM_USERS = 10000\n",
    "EMBEDDING_DIM = 16\n",
    "\n",
    "# 创建嵌入层\n",
    "user_embedding = layers.Embedding(\n",
    "    input_dim=NUM_USERS,\n",
    "    output_dim=EMBEDDING_DIM,\n",
    "    name=\"user_embedding\"\n",
    ")\n",
    "\n",
    "# 查询嵌入向量\n",
    "user_ids = tf.constant([0, 100, 5000, 9999])\n",
    "embeddings = user_embedding(user_ids)\n",
    "\n",
    "print(f\"输入用户 ID: {user_ids.numpy()}\")\n",
    "print(f\"嵌入向量形状: {embeddings.shape}\")\n",
    "print(f\"\\n用户 0 的嵌入向量:\")\n",
    "print(f\"  {embeddings[0].numpy()[:8]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数量对比\n",
    "print(\"10000 个类别的编码方式对比:\")\n",
    "print(f\"  独热编码: 0 参数，但输入维度为 10000\")\n",
    "print(f\"  Embedding (dim=16): {NUM_USERS * 16:,} 参数\")\n",
    "print(f\"  Embedding (dim=32): {NUM_USERS * 32:,} 参数\")\n",
    "print(f\"\\n嵌入层参数量 = 类别数 × 嵌入维度\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e3f4a5",
   "metadata": {},
   "source": [
    "## 4. 预处理层与模型集成\n",
    "\n",
    "### 4.1 集成的优势\n",
    "\n",
    "将预处理层放入模型：\n",
    "\n",
    "1. **一致性**：训练和推理使用相同的预处理逻辑\n",
    "2. **可移植性**：`model.save()` 会保存预处理参数\n",
    "3. **性能**：预处理可在 GPU 上执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f4a5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成模拟数据\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(500, 4).astype(np.float32)\n",
    "X[:, 0] *= 100  # 不同尺度\n",
    "X[:, 1] += 50\n",
    "y = (X[:, 0] * 0.5 + X[:, 1] * 0.3 + np.random.randn(500) * 10).astype(np.float32)\n",
    "\n",
    "print(f\"特征形状: {X.shape}\")\n",
    "print(f\"标签形状: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a5b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建并适配归一化层\n",
    "normalizer = layers.Normalization(axis=-1)\n",
    "normalizer.adapt(X)\n",
    "\n",
    "# 构建带预处理层的模型\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(4,), name=\"input\"),\n",
    "    normalizer,  # 预处理层\n",
    "    layers.Dense(32, activation=\"relu\"),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1),\n",
    "], name=\"model_with_preprocessing\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b6c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编译并训练（使用简化参数快速验证）\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X, y,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"\\n最终训练损失: {history.history['loss'][-1]:.4f}\")\n",
    "print(f\"最终验证损失: {history.history['val_loss'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推理时无需手动预处理\n",
    "test_input = np.array([[150.0, 60.0, 0.5, -0.5]], dtype=np.float32)\n",
    "print(f\"测试输入（原始尺度）: {test_input}\")\n",
    "\n",
    "# 模型内部自动应用归一化\n",
    "prediction = model.predict(test_input, verbose=0)\n",
    "print(f\"预测结果: {prediction[0, 0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d8e9f0",
   "metadata": {},
   "source": [
    "### 4.2 混合特征处理\n",
    "\n",
    "实际场景常需同时处理数值特征和分类特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e9f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mixed_feature_model(numeric_dim, category_vocab_sizes, embedding_dims):\n",
    "    \"\"\"构建混合特征处理模型\n",
    "    \n",
    "    Args:\n",
    "        numeric_dim: 数值特征维度\n",
    "        category_vocab_sizes: 各分类特征的词汇表大小\n",
    "        embedding_dims: 各分类特征的嵌入维度\n",
    "        \n",
    "    Returns:\n",
    "        Keras 模型\n",
    "    \"\"\"\n",
    "    # 数值输入\n",
    "    numeric_input = layers.Input(shape=(numeric_dim,), name=\"numeric\")\n",
    "    normalized_numeric = layers.Normalization(axis=-1)(numeric_input)\n",
    "    \n",
    "    # 分类输入和嵌入\n",
    "    category_inputs = []\n",
    "    category_embeddings = []\n",
    "    \n",
    "    for i, (vocab_size, emb_dim) in enumerate(zip(category_vocab_sizes, embedding_dims)):\n",
    "        cat_input = layers.Input(shape=(1,), dtype=\"int32\", name=f\"category_{i}\")\n",
    "        category_inputs.append(cat_input)\n",
    "        \n",
    "        embedding = layers.Embedding(vocab_size, emb_dim)(cat_input)\n",
    "        embedding = layers.Flatten()(embedding)\n",
    "        category_embeddings.append(embedding)\n",
    "    \n",
    "    # 拼接所有特征\n",
    "    all_features = layers.Concatenate()([normalized_numeric] + category_embeddings)\n",
    "    \n",
    "    # 全连接层\n",
    "    x = layers.Dense(64, activation=\"relu\")(all_features)\n",
    "    x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    \n",
    "    return keras.Model(\n",
    "        inputs=[numeric_input] + category_inputs,\n",
    "        outputs=output,\n",
    "        name=\"mixed_feature_model\"\n",
    "    )\n",
    "\n",
    "\n",
    "# 创建模型\n",
    "mixed_model = build_mixed_feature_model(\n",
    "    numeric_dim=5,\n",
    "    category_vocab_sizes=[100, 50],\n",
    "    embedding_dims=[8, 4]\n",
    ")\n",
    "\n",
    "mixed_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f0a1b2",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "### 预处理层对比\n",
    "\n",
    "| 层类型 | 用途 | 适用场景 |\n",
    "|--------|------|----------|\n",
    "| `Normalization` | Z-score 标准化 | 数值特征，不同尺度 |\n",
    "| `Rescaling` | 线性缩放 | 图像像素值 |\n",
    "| `StringLookup` | 字符串转索引 | 分类特征预处理 |\n",
    "| `CategoryEncoding` | 独热/多热编码 | 低基数分类特征 |\n",
    "| `Embedding` | 嵌入向量 | 高基数分类特征 |\n",
    "\n",
    "### 最佳实践\n",
    "\n",
    "1. **预处理集成**: 将预处理层放入模型，确保训练和推理一致\n",
    "2. **adapt 时机**: 仅使用训练数据调用 `adapt()`，避免数据泄露\n",
    "3. **特征选择**: 低基数用独热编码，高基数用嵌入\n",
    "4. **嵌入维度**: 经验法则 `dim = min(50, vocab_size // 2)`\n",
    "\n",
    "### 参考文档\n",
    "\n",
    "- [Keras 预处理层指南](https://keras.io/guides/preprocessing_layers/)\n",
    "- [结构化数据处理](https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
