{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T05:44:37.892515Z",
     "start_time": "2025-09-14T05:44:37.878562Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n使用预训练VGG16模型进行迁移学习\n\n迁移学习(Transfer Learning)是计算机视觉领域的核心技术:\n- 利用在大规模数据集(ImageNet)上预训练的模型\n- 将学到的通用特征迁移到新任务\n- 大幅减少训练时间和所需数据量\n\n本notebook将演示特征提取方法:\n1. 使用预训练VGG16作为特征提取器(冻结权重)\n2. 仅训练顶层的全连接分类器\n3. 对比从头训练的CNN模型\n\n技术要点:\n- VGG16在ImageNet上学到的特征具有很强的通用性\n- 底层学习边缘/纹理,顶层学习复杂模式\n- 特征提取速度快,训练成本低\n\n作者: [Your Name]\n日期: 2024-01\n\"\"\"\n\nimport os\nimport warnings\nfrom pathlib import Path\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# 环境配置\nwarnings.filterwarnings('ignore')\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\n# 设置随机种子确保可复现\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntf.random.set_seed(RANDOM_SEED)\n\nprint(f\"TensorFlow版本: {tf.__version__}\")\nprint(f\"GPU可用: {len(tf.config.list_physical_devices('GPU')) > 0}\")",
   "id": "1aac925ce0c8bb0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T05:44:38.757544Z",
     "start_time": "2025-09-14T05:44:37.924515Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n数据路径配置和超参数设置\n\"\"\"\n\n# 数据路径(使用相对路径)\nDATA_ROOT = Path(\"猫狗数据集/dataset\")\nTRAIN_DIR = DATA_ROOT / \"train\"\nVALIDATION_DIR = DATA_ROOT / \"validation\"\nTEST_DIR = DATA_ROOT / \"test\"\n\n# 图像参数(必须与VGG16要求一致)\nIMG_HEIGHT = 150\nIMG_WIDTH = 150\nIMG_CHANNELS = 3\n\n# 训练参数\nBATCH_SIZE = 20\nEPOCHS = 2  # 测试用,生产环境建议30+\nLEARNING_RATE = 2e-5  # 较小的学习率适合特征提取\n\n# VGG16权重文件路径\n# 可以设置为None让Keras自动下载,或指定本地文件\nVGG_WEIGHTS_PATH = 'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\n# 检查权重文件是否存在\nif VGG_WEIGHTS_PATH and Path(VGG_WEIGHTS_PATH).exists():\n    print(f\"✓ 使用本地VGG16权重: {VGG_WEIGHTS_PATH}\")\n    weights_source = VGG_WEIGHTS_PATH\nelif VGG_WEIGHTS_PATH:\n    print(f\"⚠️  本地权重文件不存在: {VGG_WEIGHTS_PATH}\")\n    print(\"将使用在线下载的权重\")\n    weights_source = 'imagenet'\nelse:\n    print(\"使用在线下载的ImageNet权重\")\n    weights_source = 'imagenet'\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"配置信息\")\nprint(\"=\" * 60)\nprint(f\"图像尺寸: {IMG_HEIGHT}x{IMG_WIDTH}x{IMG_CHANNELS}\")\nprint(f\"批次大小: {BATCH_SIZE}\")\nprint(f\"训练轮数: {EPOCHS} (注意: 测试配置)\")\nprint(f\"学习率: {LEARNING_RATE}\")\nprint(\"=\" * 60)",
   "id": "2bc02e6764200fb1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T05:44:38.804544Z",
     "start_time": "2025-09-14T05:44:38.774544Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n加载预训练的VGG16卷积基\n\nVGG16架构:\n- 13个卷积层 + 3个全连接层\n- 5个池化层将图像尺寸递减\n- 总参数约1.38亿个\n\n参数说明:\n- weights: 使用ImageNet预训练权重\n- include_top=False: 不包括顶层全连接层(我们将自定义分类器)\n- input_shape: 输入图像尺寸\n\n为什么不包括顶层?\n- ImageNet有1000个类别,我们只需要2个(猫/狗)\n- 自定义分类器更灵活,可根据任务调整\n\"\"\"\n\n# 加载VGG16卷积基(不包括全连接层)\nconv_base = VGG16(\n    weights=weights_source,\n    include_top=False,  # 不包括顶层分类器\n    input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n)\n\nprint(\"=\" * 60)\nprint(\"VGG16卷积基架构\")\nprint(\"=\" * 60)\nconv_base.summary()\nprint(\"=\" * 60)\n\n# 分析模型参数\ntotal_params = conv_base.count_params()\nprint(f\"\\n卷积基参数量: {total_params:,} ({total_params/1e6:.2f}M)\")\nprint(f\"输出形状: {conv_base.output_shape}\")\nprint(\"=\" * 60)",
   "id": "4bb6ed0b35f28cd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T05:44:38.866679Z",
     "start_time": "2025-09-14T05:44:38.851679Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n使用VGG16提取图像特征\n\n特征提取流程:\n1. 使用VGG16将图像转换为特征向量\n2. 将提取的特征保存到内存\n3. 后续用这些特征训练轻量级分类器\n\n优势:\n- 特征提取只需一次,节省训练时间\n- 可以使用更大的批次训练分类器\n- 适合计算资源受限的场景\n\n数据集样本数量配置\n\"\"\"\n\n# 数据集样本数量(根据实际数据调整)\nTRAIN_SAMPLES = 10000   # 训练集样本数\nVAL_SAMPLES = 2500      # 验证集样本数\nTEST_SAMPLES = 6200     # 测试集样本数\n\nprint(\"=\" * 60)\nprint(\"数据集规模\")\nprint(\"=\" * 60)\nprint(f\"训练样本数: {TRAIN_SAMPLES}\")\nprint(f\"验证样本数: {VAL_SAMPLES}\")\nprint(f\"测试样本数: {TEST_SAMPLES}\")\nprint(f\"总样本数: {TRAIN_SAMPLES + VAL_SAMPLES + TEST_SAMPLES}\")\nprint(\"=\" * 60)",
   "id": "4c825ca994745a87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T05:45:49.969023Z",
     "start_time": "2025-09-14T05:44:38.883679Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n定义特征提取函数并提取所有数据集的特征\n\n关键技术点:\n1. 使用ImageDataGenerator进行图像归一化\n2. 批量处理图像提高效率\n3. 使用conv_base.predict()提取特征\n4. 同时保存特征和标签\n\n注意:\n- 特征提取阶段不使用数据增强\n- VGG16输出的特征形状为(4, 4, 512)\n- 后续需要展平为1维向量用于全连接层\n\"\"\"\n\ndef extract_features(directory, sample_count, batch_size=20):\n    \"\"\"\n    使用VGG16卷积基提取图像特征\n    \n    Args:\n        directory: 图像目录路径\n        sample_count: 要提取的样本数量\n        batch_size: 批次大小\n        \n    Returns:\n        features: 提取的特征数组, shape=(sample_count, 4, 4, 512)\n        labels: 对应的标签数组, shape=(sample_count,)\n    \"\"\"\n    # 初始化特征和标签数组\n    features = np.zeros(shape=(sample_count, 4, 4, 512), dtype=np.float32)\n    labels = np.zeros(shape=(sample_count), dtype=np.float32)\n    \n    # 创建数据生成器(仅归一化)\n    datagen = ImageDataGenerator(rescale=1./255)\n    generator = datagen.flow_from_directory(\n        directory,\n        target_size=(IMG_HEIGHT, IMG_WIDTH),\n        batch_size=batch_size,\n        class_mode='binary',\n        shuffle=False  # 保持顺序以确保标签对应\n    )\n    \n    # 批量提取特征\n    print(f\"从 {Path(directory).name} 提取特征...\")\n    i = 0\n    for inputs_batch, labels_batch in generator:\n        # 使用VGG16提取特征\n        features_batch = conv_base.predict(inputs_batch, verbose=0)\n        \n        # 计算当前批次的实际大小和索引范围\n        batch_size_actual = inputs_batch.shape[0]\n        start_idx = i * batch_size\n        end_idx = start_idx + batch_size_actual\n        \n        # 保存特征和标签\n        features[start_idx:end_idx] = features_batch\n        labels[start_idx:end_idx] = labels_batch\n        \n        i += 1\n        \n        # 显示进度\n        if i % 50 == 0:\n            print(f\"  已处理: {min(end_idx, sample_count)}/{sample_count} 样本\")\n        \n        # 达到目标样本数则停止\n        if end_idx >= sample_count:\n            break\n    \n    print(f\"✓ 完成! 提取了 {sample_count} 个样本的特征\\n\")\n    return features, labels\n\n# 提取所有数据集的特征\nprint(\"=\" * 60)\nprint(\"开始提取特征\")\nprint(\"=\" * 60)\nprint(\"这可能需要几分钟时间,请耐心等待...\\n\")\n\ntrain_features, train_labels = extract_features(str(TRAIN_DIR), TRAIN_SAMPLES, BATCH_SIZE)\nvalidation_features, validation_labels = extract_features(str(VALIDATION_DIR), VAL_SAMPLES, BATCH_SIZE)\ntest_features, test_labels = extract_features(str(TEST_DIR), TEST_SAMPLES, BATCH_SIZE)\n\nprint(\"=\" * 60)\nprint(\"特征提取完成\")\nprint(\"=\" * 60)\nprint(f\"训练特征形状: {train_features.shape}\")\nprint(f\"验证特征形状: {validation_features.shape}\")\nprint(f\"测试特征形状: {test_features.shape}\")\nprint(\"=\" * 60)",
   "id": "9e41bf1a269ca44c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T05:45:50.016151Z",
     "start_time": "2025-09-14T05:45:50.001148Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n展平特征向量\n\n将4D特征张量展平为2D:\n- 输入形状: (samples, 4, 4, 512)\n- 输出形状: (samples, 8192)\n\n为什么需要展平?\n- 全连接层只接受1D输入\n- 4*4*512 = 8192维特征向量\n\"\"\"\n\n# 展平特征\ntrain_features_flat = np.reshape(train_features, (TRAIN_SAMPLES, 4 * 4 * 512))\nvalidation_features_flat = np.reshape(validation_features, (VAL_SAMPLES, 4 * 4 * 512))\ntest_features_flat = np.reshape(test_features, (TEST_SAMPLES, 4 * 4 * 512))\n\nprint(\"=\" * 60)\nprint(\"特征展平\")\nprint(\"=\" * 60)\nprint(f\"训练特征: {train_features.shape} → {train_features_flat.shape}\")\nprint(f\"验证特征: {validation_features.shape} → {validation_features_flat.shape}\")\nprint(f\"测试特征: {test_features.shape} → {test_features_flat.shape}\")\nprint(f\"\\n每个样本的特征维度: {train_features_flat.shape[1]:,}\")\nprint(\"=\" * 60)",
   "id": "80f6f23cc6b64149",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T05:46:04.523212Z",
     "start_time": "2025-09-14T05:45:50.032659Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n构建并训练全连接分类器\n\n网络结构:\n- 输入: 8192维特征向量(来自VGG16)\n- 隐藏层: 256个神经元 + ReLU激活\n- Dropout: 0.5比例(防止过拟合)\n- 输出层: 1个神经元 + Sigmoid激活(二分类)\n\n训练策略:\n- 使用较小学习率(2e-5)\n- 添加EarlyStopping避免过拟合\n- 监控验证损失,patience=3\n\"\"\"\n\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# 构建分类器模型\nclassifier = models.Sequential(name='VGG16_Classifier')\nclassifier.add(layers.Dense(\n    256, \n    activation='relu', \n    input_dim=4*4*512,  # 输入维度必须与特征维度匹配\n    name='fc1'\n))\nclassifier.add(layers.Dropout(0.5, name='dropout'))\nclassifier.add(layers.Dense(1, activation='sigmoid', name='output'))\n\n# 编译模型\nclassifier.compile(\n    optimizer=optimizers.RMSprop(learning_rate=LEARNING_RATE),\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\nprint(\"=\" * 60)\nprint(\"分类器架构\")\nprint(\"=\" * 60)\nclassifier.summary()\nprint(\"=\" * 60)\n\n# 配置早停回调\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    patience=3,\n    restore_best_weights=True,  # 恢复最佳权重\n    verbose=1\n)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"开始训练分类器\")\nprint(\"=\" * 60)\nprint(f\"训练样本: {len(train_features_flat)}\")\nprint(f\"验证样本: {len(validation_features_flat)}\")\nprint(f\"批次大小: 32\")\nprint(f\"最大轮数: {EPOCHS}\")\nprint(f\"早停策略: 验证损失3轮无改善则停止\")\nprint(\"=\" * 60 + \"\\n\")\n\n# 训练分类器\nhistory = classifier.fit(\n    train_features_flat, \n    train_labels,\n    epochs=EPOCHS,\n    batch_size=32,\n    validation_data=(validation_features_flat, validation_labels),\n    callbacks=[early_stopping],\n    verbose=1\n)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"训练完成\")\nprint(\"=\" * 60)\n\n# 显示最终结果\nfinal_train_acc = history.history['accuracy'][-1]\nfinal_val_acc = history.history['val_accuracy'][-1]\nfinal_train_loss = history.history['loss'][-1]\nfinal_val_loss = history.history['val_loss'][-1]\n\nprint(f\"\\n最终结果:\")\nprint(f\"  训练准确率: {final_train_acc:.4f}\")\nprint(f\"  验证准确率: {final_val_acc:.4f}\")\nprint(f\"  训练损失: {final_train_loss:.4f}\")\nprint(f\"  验证损失: {final_val_loss:.4f}\")\nprint(\"=\" * 60)",
   "id": "5f1e7be860cbdc46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T05:46:05.104022Z",
     "start_time": "2025-09-14T05:46:04.540214Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n可视化训练过程\n\n展示准确率和损失的变化趋势,评估模型性能\n\"\"\"\n\nimport matplotlib.pyplot as plt\n\n# 提取训练历史\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(1, len(acc) + 1)\n\n# 创建图表\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\n# 绘制准确率\nax1.plot(epochs_range, acc, 'bo-', label='训练准确率', linewidth=2, markersize=8)\nax1.plot(epochs_range, val_acc, 'rs-', label='验证准确率', linewidth=2, markersize=8)\nax1.set_title('训练和验证准确率 (VGG16特征提取)', fontsize=14, fontweight='bold')\nax1.set_xlabel('Epoch', fontsize=12)\nax1.set_ylabel('准确率', fontsize=12)\nax1.legend(fontsize=11)\nax1.grid(True, alpha=0.3)\n\n# 绘制损失\nax2.plot(epochs_range, loss, 'bo-', label='训练损失', linewidth=2, markersize=8)\nax2.plot(epochs_range, val_loss, 'rs-', label='验证损失', linewidth=2, markersize=8)\nax2.set_title('训练和验证损失 (VGG16特征提取)', fontsize=14, fontweight='bold')\nax2.set_xlabel('Epoch', fontsize=12)\nax2.set_ylabel('损失', fontsize=12)\nax2.legend(fontsize=11)\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# 性能分析\nprint(\"\\n\" + \"=\" * 60)\nprint(\"性能分析\")\nprint(\"=\" * 60)\nprint(f\"验证准确率: {val_acc[-1]:.4f}\")\nprint(f\"训练轮数: {len(acc)}\")\n\nif val_acc[-1] > 0.9:\n    print(\"\\n✓ 优秀! 使用预训练特征获得了很好的效果\")\n    print(\"  VGG16学到的特征在新任务上泛化良好\")\nelif val_acc[-1] > 0.85:\n    print(\"\\n✓ 良好! 特征提取方法有效\")\nelse:\n    print(\"\\n⚠️  性能有提升空间,可以考虑:\")\n    print(\"  - 增加训练轮数\")\n    print(\"  - 调整分类器架构\")\n    print(\"  - 尝试模型微调(fine-tuning)\")\nprint(\"=\" * 60)",
   "id": "2750a5c48a63eb38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T05:46:05.246550Z",
     "start_time": "2025-09-14T05:46:05.199529Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n方法2: 端到端训练(冻结卷积基)\n\n与特征提取不同,这种方法:\n1. 将VGG16卷积基作为模型的一部分\n2. 冻结卷积基权重(不训练)\n3. 仅训练顶层分类器\n4. 使用数据生成器直接训练\n\n优势:\n- 可以使用数据增强\n- 内存占用更小(不需要保存所有特征)\n- 更适合大数据集\n\n对比特征提取法:\n- 特征提取: 先提取特征→再训练分类器(两阶段)\n- 端到端: 直接在原始图像上训练(一阶段)\n\"\"\"\n\n# 构建端到端模型\nmodel_frozen = models.Sequential(name='VGG16_Frozen_E2E')\nmodel_frozen.add(conv_base)  # 添加VGG16卷积基\nmodel_frozen.add(layers.Flatten(name='flatten'))\nmodel_frozen.add(layers.Dense(256, activation='relu', name='fc1'))\nmodel_frozen.add(layers.Dropout(0.5, name='dropout'))\nmodel_frozen.add(layers.Dense(1, activation='sigmoid', name='output'))\n\nprint(\"=\" * 60)\nprint(\"端到端模型架构 (冻结卷积基)\")\nprint(\"=\" * 60)\nmodel_frozen.summary()\nprint(\"=\" * 60)",
   "id": "a92af64ced8ff27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T05:46:05.278553Z",
     "start_time": "2025-09-14T05:46:05.263551Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n冻结卷积基权重\n\n为什么要冻结?\n- VGG16已在ImageNet上充分训练\n- 底层特征(边缘、纹理)具有通用性\n- 仅训练顶层分类器速度更快\n- 避免破坏预训练的特征\n\n如何冻结?\n- 设置conv_base.trainable = False\n- 冻结后的层不参与反向传播\n- 权重在训练过程中保持不变\n\"\"\"\n\n# 冻结卷积基的所有层\nconv_base.trainable = False\n\n# 验证冻结状态\nprint(\"=\" * 60)\nprint(\"模型参数统计\")\nprint(\"=\" * 60)\ntrainable_count = sum([np.prod(w.shape) for w in model_frozen.trainable_weights])\nnon_trainable_count = sum([np.prod(w.shape) for w in model_frozen.non_trainable_weights])\ntotal_count = trainable_count + non_trainable_count\n\nprint(f\"可训练参数: {trainable_count:,} ({trainable_count/1e6:.2f}M)\")\nprint(f\"冻结参数: {non_trainable_count:,} ({non_trainable_count/1e6:.2f}M)\")\nprint(f\"总参数: {total_count:,} ({total_count/1e6:.2f}M)\")\nprint(f\"\\n参数减少比例: {(non_trainable_count/total_count)*100:.1f}% 的参数被冻结\")\nprint(\"=\" * 60)",
   "id": "ecad752d83ea26a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T05:48:51.732996Z",
     "start_time": "2025-09-14T05:46:51.131372Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n使用数据增强进行端到端训练\n\n训练配置:\n- 训练集使用数据增强\n- 验证集仅归一化(不增强)\n- 使用较小学习率保护预训练权重\n- 添加EarlyStopping防止过拟合\n\"\"\"\n\n# 创建数据生成器\ntrain_datagen_e2e = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\nval_datagen_e2e = ImageDataGenerator(rescale=1./255)\n\n# 创建数据流\ntrain_generator_e2e = train_datagen_e2e.flow_from_directory(\n    str(TRAIN_DIR),\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=32,\n    class_mode='binary',\n    shuffle=True,\n    seed=RANDOM_SEED\n)\n\nvalidation_generator_e2e = val_datagen_e2e.flow_from_directory(\n    str(VALIDATION_DIR),\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=32,\n    class_mode='binary',\n    shuffle=False\n)\n\n# 编译模型\nmodel_frozen.compile(\n    optimizer=optimizers.RMSprop(learning_rate=LEARNING_RATE),\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\n# 计算训练步数\nsteps_per_epoch_e2e = train_generator_e2e.samples // 32\nvalidation_steps_e2e = validation_generator_e2e.samples // 32\n\n# 配置回调\nearly_stopping_e2e = EarlyStopping(\n    monitor='val_loss',\n    patience=3,\n    restore_best_weights=True,\n    verbose=1\n)\n\nprint(\"=\" * 60)\nprint(\"开始端到端训练 (冻结VGG16 + 数据增强)\")\nprint(\"=\" * 60)\nprint(f\"训练样本: {train_generator_e2e.samples}\")\nprint(f\"验证样本: {validation_generator_e2e.samples}\")\nprint(f\"批次大小: 32\")\nprint(f\"最大轮数: {EPOCHS}\")\nprint(f\"数据增强: 已启用\")\nprint(\"=\" * 60 + \"\\n\")\n\n# 训练模型\nhistory_e2e = model_frozen.fit(\n    train_generator_e2e,\n    steps_per_epoch=steps_per_epoch_e2e,\n    epochs=EPOCHS,\n    validation_data=validation_generator_e2e,\n    validation_steps=validation_steps_e2e,\n    callbacks=[early_stopping_e2e],\n    verbose=1\n)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"端到端训练完成\")\nprint(\"=\" * 60)\n\n# 显示结果\nfinal_train_acc_e2e = history_e2e.history['accuracy'][-1]\nfinal_val_acc_e2e = history_e2e.history['val_accuracy'][-1]\n\nprint(f\"\\n最终结果:\")\nprint(f\"  训练准确率: {final_train_acc_e2e:.4f}\")\nprint(f\"  验证准确率: {final_val_acc_e2e:.4f}\")\nprint(f\"\\n对比特征提取法:\")\nprint(f\"  特征提取验证准确率: {final_val_acc:.4f}\")\nprint(f\"  端到端验证准确率: {final_val_acc_e2e:.4f}\")\nprint(f\"  差异: {final_val_acc_e2e - final_val_acc:+.4f}\")\nprint(\"=\" * 60)",
   "id": "3c8cd44cb2228b15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T05:58:15.580113Z",
     "start_time": "2025-09-14T05:58:15.430445Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n可视化端到端训练结果\n\"\"\"\n\nimport matplotlib.pyplot as plt\n\n# 提取训练历史\nacc_e2e = history_e2e.history['accuracy']\nval_acc_e2e = history_e2e.history['val_accuracy']\nloss_e2e = history_e2e.history['loss']\nval_loss_e2e = history_e2e.history['val_loss']\nepochs_range_e2e = range(1, len(acc_e2e) + 1)\n\n# 创建图表\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\n# 准确率曲线\nax1.plot(epochs_range_e2e, acc_e2e, 'bo-', label='训练准确率', linewidth=2, markersize=8)\nax1.plot(epochs_range_e2e, val_acc_e2e, 'rs-', label='验证准确率', linewidth=2, markersize=8)\nax1.set_title('端到端训练: 准确率', fontsize=14, fontweight='bold')\nax1.set_xlabel('Epoch', fontsize=12)\nax1.set_ylabel('准确率', fontsize=12)\nax1.legend(fontsize=11)\nax1.grid(True, alpha=0.3)\n\n# 损失曲线\nax2.plot(epochs_range_e2e, loss_e2e, 'bo-', label='训练损失', linewidth=2, markersize=8)\nax2.plot(epochs_range_e2e, val_loss_e2e, 'rs-', label='验证损失', linewidth=2, markersize=8)\nax2.set_title('端到端训练: 损失', fontsize=14, fontweight='bold')\nax2.set_xlabel('Epoch', fontsize=12)\nax2.set_ylabel('损失', fontsize=12)\nax2.legend(fontsize=11)\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"总结\")\nprint(\"=\" * 60)\nprint(\"\\n特征提取 vs 端到端训练:\")\nprint(f\"  方法1 (特征提取): 验证准确率 = {final_val_acc:.4f}\")\nprint(f\"  方法2 (端到端): 验证准确率 = {final_val_acc_e2e:.4f}\")\nprint(\"\\n两种方法各有优势:\")\nprint(\"  特征提取:\")\nprint(\"    ✓ 训练速度快\")\nprint(\"    ✓ 内存需求小\")\nprint(\"    ✗ 无法使用数据增强\")\nprint(\"\\n  端到端:\")\nprint(\"    ✓ 可以使用数据增强\")\nprint(\"    ✓ 性能通常更好\")\nprint(\"    ✗ 训练速度较慢\")\nprint(\"=\" * 60)",
   "id": "ff3c86deb7618cd6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "\"\"\"\n总结与展望\n\n本notebook演示了迁移学习的特征提取方法:\n✓ 使用预训练VGG16提取图像特征\n✓ 对比两种训练方式(特征提取 vs 端到端)\n✓ 理解冻结权重的重要性\n✓ 观察迁移学习的性能优势\n\n关键收获:\n1. 迁移学习显著减少训练时间和数据需求\n2. 预训练特征具有很强的通用性\n3. 特征提取适合快速原型和小数据集\n4. 端到端训练性能更好但成本更高\n\n下一步:\n- 模型微调(Fine-tuning): 解冻部分卷积层进一步优化\n- 尝试其他预训练模型(ResNet, EfficientNet等)\n- 在测试集上评估最终性能\n- 优化超参数(学习率, Dropout率等)\n\"\"\"\n\nprint(\"=\" * 60)\nprint(\"Notebook执行完成\")\nprint(\"=\" * 60)\nprint(\"\\n迁移学习优势总结:\")\nprint(\"  ✓ 大幅减少训练时间\")\nprint(\"  ✓ 在小数据集上也能获得好效果\")\nprint(\"  ✓ 利用ImageNet上学到的通用特征\")\nprint(\"\\n推荐阅读:\")\nprint(\"  - 使用模型微调分类猫狗.ipynb\")\nprint(\"  - 了解如何解冻层进行Fine-tuning\")\nprint(\"=\" * 60)",
   "id": "28ad15b216e304ad"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}