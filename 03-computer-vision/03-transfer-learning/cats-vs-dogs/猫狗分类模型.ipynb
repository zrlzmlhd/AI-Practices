{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T09:53:17.045842Z",
     "start_time": "2025-09-13T09:53:13.376143Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n猫狗分类模型 - 基础卷积神经网络实现\n\n本notebook演示如何从头构建一个卷积神经网络(CNN)来进行二分类任务。\n通过这个示例,你将学习到:\n1. 卷积神经网络的基本架构设计\n2. 数据预处理和归一化的重要性\n3. 模型编译和训练的完整流程\n4. 过拟合现象的识别和分析\n\n技术要点:\n- 使用多层卷积-池化结构提取图像特征\n- 采用Sigmoid激活函数实现二分类\n- RMSprop优化器适合处理非平稳目标\n\n作者: [Your Name]\n日期: 2024-01\n\"\"\"\n\nimport os\nimport warnings\nfrom pathlib import Path\n\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models, optimizers\n\n# 禁用不必要的警告信息\nwarnings.filterwarnings('ignore')\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n\n# 设置随机种子以确保结果可复现\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntf.random.set_seed(RANDOM_SEED)\n\nprint(f\"TensorFlow版本: {tf.__version__}\")\nprint(f\"GPU可用: {len(tf.config.list_physical_devices('GPU')) > 0}\")",
   "id": "50abd21b7e7f50e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T09:53:20.921295Z",
     "start_time": "2025-09-13T09:53:20.905855Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n数据路径配置模块\n\n使用相对路径确保代码的可移植性。\n数据集目录结构应该如下:\n猫狗数据集/\n├── dataset/\n│   ├── train/\n│   │   ├── cats/\n│   │   └── dogs/\n│   ├── validation/\n│   │   ├── cats/\n│   │   └── dogs/\n│   └── test/\n│       ├── cats/\n│       └── dogs/\n\"\"\"\n\n# 数据集根目录配置(相对于notebook的路径)\nDATA_ROOT = Path(\"猫狗数据集/dataset\")\n\n# 各个数据集的子目录\nTRAIN_DIR = DATA_ROOT / \"train\"\nVALIDATION_DIR = DATA_ROOT / \"validation\"\nTEST_DIR = DATA_ROOT / \"test\"\n\n# 验证路径是否存在\nprint(\"=\" * 60)\nprint(\"数据路径验证\")\nprint(\"=\" * 60)\nfor name, path in [(\"训练集\", TRAIN_DIR), \n                    (\"验证集\", VALIDATION_DIR), \n                    (\"测试集\", TEST_DIR)]:\n    exists = path.exists()\n    status = \"✓\" if exists else \"✗\"\n    print(f\"{status} {name}: {path} {'(存在)' if exists else '(不存在)'}\")\n    \n    if exists:\n        # 统计每个类别的样本数量\n        cats_count = len(list((path / \"cats\").glob(\"*.jpg\"))) if (path / \"cats\").exists() else 0\n        dogs_count = len(list((path / \"dogs\").glob(\"*.jpg\"))) if (path / \"dogs\").exists() else 0\n        print(f\"   猫: {cats_count}张, 狗: {dogs_count}张, 总计: {cats_count + dogs_count}张\")\n\nprint(\"=\" * 60)",
   "id": "859cdb5b612fda58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T09:53:23.003737Z",
     "start_time": "2025-09-13T09:53:21.582540Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n模型超参数配置\n\n这些参数控制模型的训练行为和网络结构。\n在生产环境中，通常会通过配置文件或命令行参数来管理这些设置。\n\"\"\"\n\n# 图像预处理参数\nIMG_HEIGHT = 150  # 输入图像高度\nIMG_WIDTH = 150   # 输入图像宽度\nIMG_CHANNELS = 3  # RGB图像通道数\n\n# 训练参数\nBATCH_SIZE = 32        # 批次大小,影响训练速度和内存占用\nEPOCHS = 2             # 训练轮数(测试用,生产环境建议30+)\nLEARNING_RATE = 1e-4   # 学习率,控制参数更新步长\n\n# 打印配置信息\nprint(\"=\" * 60)\nprint(\"模型配置\")\nprint(\"=\" * 60)\nprint(f\"输入图像尺寸: {IMG_HEIGHT}x{IMG_WIDTH}x{IMG_CHANNELS}\")\nprint(f\"批次大小: {BATCH_SIZE}\")\nprint(f\"训练轮数: {EPOCHS} (注意: 当前为测试配置)\")\nprint(f\"学习率: {LEARNING_RATE}\")\nprint(\"=\" * 60)",
   "id": "ef4db4cec491c872",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T09:53:24.587216Z",
     "start_time": "2025-09-13T09:53:24.548641Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n构建卷积神经网络模型\n\n网络架构设计说明:\n1. 4个卷积块,每个块包含:\n   - Conv2D: 卷积层,提取图像特征\n   - MaxPooling2D: 池化层,降低特征维度,增强特征鲁棒性\n   \n2. 特征图数量递增(32→64→128→128):\n   - 浅层捕获边缘、纹理等低级特征\n   - 深层捕获物体部件、形状等高级特征\n   \n3. 全连接层:\n   - Flatten: 将2D特征图展平为1D向量\n   - Dense(512): 特征整合和高级抽象\n   - Dense(1): 二分类输出(sigmoid激活)\n\n为什么使用这种架构?\n- 多层卷积逐步提取抽象特征\n- 池化层减少计算量并增强平移不变性\n- 特征图递增平衡了计算效率和表达能力\n\"\"\"\n\ndef build_cnn_model(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)):\n    \"\"\"\n    构建用于二分类的卷积神经网络\n    \n    Args:\n        input_shape: 输入图像的形状 (height, width, channels)\n        \n    Returns:\n        未编译的Keras模型\n    \"\"\"\n    model = models.Sequential(name='Cat_Dog_CNN')\n    \n    # 第1个卷积块: 32个3x3卷积核\n    model.add(layers.Conv2D(\n        32, (3, 3), \n        activation='relu',\n        input_shape=input_shape,\n        name='conv1'\n    ))\n    model.add(layers.MaxPooling2D((2, 2), name='pool1'))\n    \n    # 第2个卷积块: 64个3x3卷积核\n    model.add(layers.Conv2D(64, (3, 3), activation='relu', name='conv2'))\n    model.add(layers.MaxPooling2D((2, 2), name='pool2'))\n    \n    # 第3个卷积块: 128个3x3卷积核\n    model.add(layers.Conv2D(128, (3, 3), activation='relu', name='conv3'))\n    model.add(layers.MaxPooling2D((2, 2), name='pool3'))\n    \n    # 第4个卷积块: 128个3x3卷积核\n    model.add(layers.Conv2D(128, (3, 3), activation='relu', name='conv4'))\n    model.add(layers.MaxPooling2D((2, 2), name='pool4'))\n    \n    # 展平特征图\n    model.add(layers.Flatten(name='flatten'))\n    \n    # 全连接层\n    model.add(layers.Dense(512, activation='relu', name='fc1'))\n    \n    # 输出层: 二分类使用sigmoid激活\n    model.add(layers.Dense(1, activation='sigmoid', name='output'))\n    \n    return model\n\n# 创建模型实例\nmodel = build_cnn_model()\n\n# 显示模型结构\nprint(\"\\n\" + \"=\" * 60)\nprint(\"模型架构\")\nprint(\"=\" * 60)\nmodel.summary()\nprint(\"=\" * 60)\n\n# 计算模型参数量\ntotal_params = model.count_params()\nprint(f\"\\n总参数量: {total_params:,} ({total_params/1e6:.2f}M)\")",
   "id": "8baf38a44de71d01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T10:14:49.509202Z",
     "start_time": "2025-09-13T10:03:57.020087Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n数据加载和预处理\n\n使用ImageDataGenerator进行数据预处理:\n1. rescale=1./255: 将像素值从[0,255]归一化到[0,1]\n   - 神经网络在小范围数值上训练更稳定\n   - 避免梯度爆炸/消失问题\n   \n2. flow_from_directory: 从目录结构自动加载数据\n   - 自动识别子文件夹作为类别标签\n   - 批量加载,节省内存\n   \n注意: 此阶段不使用数据增强,仅做归一化\n\"\"\"\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# 创建数据生成器(仅归一化)\ntrain_datagen = ImageDataGenerator(rescale=1./255)\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n# 训练集生成器\ntrain_generator = train_datagen.flow_from_directory(\n    str(TRAIN_DIR),  # 转换Path对象为字符串\n    target_size=(IMG_HEIGHT, IMG_WIDTH),  # 调整所有图像到统一尺寸\n    batch_size=BATCH_SIZE,\n    class_mode='binary',  # 二分类模式,标签为0或1\n    shuffle=True,         # 每个epoch打乱数据\n    seed=RANDOM_SEED      # 设置随机种子保证可复现\n)\n\n# 验证集生成器\nvalidation_generator = validation_datagen.flow_from_directory(\n    str(VALIDATION_DIR),\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    shuffle=False  # 验证集不需要打乱\n)\n\n# 测试集生成器\ntest_generator = test_datagen.flow_from_directory(\n    str(TEST_DIR),\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    shuffle=False\n)\n\n# 显示数据加载信息\nprint(\"\\n\" + \"=\" * 60)\nprint(\"数据生成器信息\")\nprint(\"=\" * 60)\nprint(f\"类别映射: {train_generator.class_indices}\")\nprint(f\"训练集批次数: {len(train_generator)}\")\nprint(f\"验证集批次数: {len(validation_generator)}\")\nprint(f\"测试集批次数: {len(test_generator)}\")\n\n# 查看一个批次的数据形状\nsample_batch, sample_labels = next(iter(train_generator))\nprint(f\"\\n单批次数据形状: {sample_batch.shape}\")\nprint(f\"单批次标签形状: {sample_labels.shape}\")\nprint(f\"像素值范围: [{sample_batch.min():.3f}, {sample_batch.max():.3f}]\")\nprint(\"=\" * 60)",
   "id": "74a4b65fe22adef4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T10:44:37.639603Z",
     "start_time": "2025-09-13T10:44:37.460949Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n模型编译和训练\n\n编译配置说明:\n1. optimizer=RMSprop: \n   - 适合处理非平稳目标和RNN\n   - 使用移动平均来平滑梯度\n   \n2. loss=binary_crossentropy:\n   - 二分类的标准损失函数\n   - 衡量预测概率分布与真实分布的差异\n   \n3. metrics=['accuracy']:\n   - 监控分类准确率\n   - 注意: accuracy仅用于监控,不参与优化\n   \n训练策略:\n- 计算steps_per_epoch确保遍历完整数据集\n- 使用validation_data监控泛化能力\n- 当前epochs=2仅用于快速测试\n\"\"\"\n\n# 编译模型\nmodel.compile(\n    optimizer=optimizers.RMSprop(learning_rate=LEARNING_RATE),\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"开始训练模型\")\nprint(\"=\" * 60)\nprint(f\"训练样本数: {train_generator.samples}\")\nprint(f\"验证样本数: {validation_generator.samples}\")\nprint(f\"批次大小: {BATCH_SIZE}\")\nprint(f\"训练轮数: {EPOCHS}\")\nprint(\"=\" * 60 + \"\\n\")\n\n# 计算每个epoch的步数\n# steps_per_epoch = 样本总数 // 批次大小\nsteps_per_epoch = train_generator.samples // BATCH_SIZE\nvalidation_steps = validation_generator.samples // BATCH_SIZE\n\n# 训练模型\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=steps_per_epoch,\n    epochs=EPOCHS,\n    validation_data=validation_generator,\n    validation_steps=validation_steps,\n    verbose=1  # 显示进度条\n)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"训练完成\")\nprint(\"=\" * 60)",
   "id": "c8e4c7c17e2bade4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T10:46:29.865054Z",
     "start_time": "2025-09-13T10:46:29.861056Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n查看训练历史记录\n\nhistory.history字典包含每个epoch的指标值:\n- loss: 训练集损失\n- accuracy: 训练集准确率\n- val_loss: 验证集损失\n- val_accuracy: 验证集准确率\n\n通过对比训练集和验证集的指标,可以判断模型是否过拟合:\n- 如果训练准确率持续上升,但验证准确率停滞或下降 → 过拟合\n- 如果两者都持续上升 → 模型正常学习\n\"\"\"\n\nprint(\"=\" * 60)\nprint(\"训练历史记录的指标\")\nprint(\"=\" * 60)\nprint(f\"可用指标: {list(history.history.keys())}\")\nprint(\"=\" * 60)\n\n# 显示最终的训练结果\nfinal_train_loss = history.history['loss'][-1]\nfinal_train_acc = history.history['accuracy'][-1]\nfinal_val_loss = history.history['val_loss'][-1]\nfinal_val_acc = history.history['val_accuracy'][-1]\n\nprint(f\"\\n最终训练结果 (Epoch {EPOCHS}):\")\nprint(f\"  训练损失: {final_train_loss:.4f}\")\nprint(f\"  训练准确率: {final_train_acc:.4f}\")\nprint(f\"  验证损失: {final_val_loss:.4f}\")\nprint(f\"  验证准确率: {final_val_acc:.4f}\")\nprint(\"=\" * 60)",
   "id": "c89f43a7849924bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T10:49:40.025901Z",
     "start_time": "2025-09-13T10:49:39.401019Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n可视化训练过程\n\n通过绘制训练和验证的损失/准确率曲线,可以直观地:\n1. 观察模型收敛情况\n2. 识别过拟合现象\n3. 判断是否需要更多训练轮数\n\n过拟合的典型特征:\n- 训练损失持续下降,验证损失上升或波动\n- 训练准确率持续上升,验证准确率停滞或下降\n- 两条曲线之间的差距越来越大\n\"\"\"\n\nimport matplotlib.pyplot as plt\n\n# 提取训练历史数据\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(1, len(acc) + 1)\n\n# 创建图表\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\n# 绘制准确率曲线\nax1.plot(epochs_range, acc, 'bo-', label='训练准确率', linewidth=2, markersize=8)\nax1.plot(epochs_range, val_acc, 'rs-', label='验证准确率', linewidth=2, markersize=8)\nax1.set_title('训练和验证准确率', fontsize=14, fontweight='bold')\nax1.set_xlabel('Epoch', fontsize=12)\nax1.set_ylabel('准确率', fontsize=12)\nax1.legend(fontsize=11)\nax1.grid(True, alpha=0.3)\n\n# 绘制损失曲线\nax2.plot(epochs_range, loss, 'bo-', label='训练损失', linewidth=2, markersize=8)\nax2.plot(epochs_range, val_loss, 'rs-', label='验证损失', linewidth=2, markersize=8)\nax2.set_title('训练和验证损失', fontsize=14, fontweight='bold')\nax2.set_xlabel('Epoch', fontsize=12)\nax2.set_ylabel('损失', fontsize=12)\nax2.legend(fontsize=11)\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# 分析过拟合程度\nif len(acc) > 1:\n    acc_gap = acc[-1] - val_acc[-1]\n    print(\"\\n\" + \"=\" * 60)\n    print(\"过拟合分析\")\n    print(\"=\" * 60)\n    print(f\"训练准确率: {acc[-1]:.4f}\")\n    print(f\"验证准确率: {val_acc[-1]:.4f}\")\n    print(f\"准确率差距: {acc_gap:.4f}\")\n    \n    if acc_gap > 0.1:\n        print(\"\\n⚠️  检测到明显过拟合!\")\n        print(\"建议:\")\n        print(\"  1. 使用数据增强\")\n        print(\"  2. 添加Dropout层\")\n        print(\"  3. 减少模型复杂度\")\n        print(\"  4. 使用L2正则化\")\n    elif acc_gap > 0.05:\n        print(\"\\n⚠️  检测到轻微过拟合\")\n        print(\"可以考虑使用正则化技术\")\n    else:\n        print(\"\\n✓ 模型泛化良好\")\n    print(\"=\" * 60)",
   "id": "cc3738d25db023d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T10:54:26.420918Z",
     "start_time": "2025-09-13T10:54:26.406919Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n数据增强技术\n\n数据增强(Data Augmentation)是提高模型泛化能力的重要技术。\n通过对训练图像应用随机变换,可以:\n1. 增加训练数据的多样性\n2. 减少过拟合\n3. 提高模型对图像变化的鲁棒性\n\n各参数说明:\n- rotation_range=40: 随机旋转±40度\n- width_shift_range=0.2: 水平平移±20%图像宽度\n- height_shift_range=0.2: 垂直平移±20%图像高度\n- shear_range=0.2: 剪切变换强度\n- zoom_range=0.2: 随机缩放±20%\n- horizontal_flip=True: 随机水平翻转\n- fill_mode='nearest': 填充新像素的方法\n\n注意: 数据增强只应用于训练集,不应用于验证集和测试集!\n\"\"\"\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# 创建带数据增强的生成器\ntrain_datagen_augmented = ImageDataGenerator(\n    rescale=1./255,              # 归一化\n    rotation_range=40,           # 随机旋转\n    width_shift_range=0.2,       # 水平平移\n    height_shift_range=0.2,      # 垂直平移\n    shear_range=0.2,             # 剪切变换\n    zoom_range=0.2,              # 随机缩放\n    horizontal_flip=True,        # 水平翻转\n    fill_mode='nearest'          # 填充策略\n)\n\nprint(\"=\" * 60)\nprint(\"数据增强配置\")\nprint(\"=\" * 60)\nprint(\"已启用的增强技术:\")\nprint(\"  ✓ 随机旋转 (±40°)\")\nprint(\"  ✓ 随机水平/垂直平移 (±20%)\")\nprint(\"  ✓ 剪切变换 (强度: 0.2)\")\nprint(\"  ✓ 随机缩放 (±20%)\")\nprint(\"  ✓ 随机水平翻转\")\nprint(\"\\n注意: 增强仅应用于训练集\")\nprint(\"=\" * 60)",
   "id": "6ee24ec2ea6ece26",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T11:02:17.613006Z",
     "start_time": "2025-09-13T11:02:17.300430Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n可视化数据增强效果\n\n通过展示同一张图片的多个增强版本,可以直观理解数据增强的作用。\n这有助于:\n1. 验证增强参数是否合理\n2. 检查是否有过度增强(导致图像失真)\n3. 确保增强后的图像仍然可识别\n\"\"\"\n\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# 选择一张样本图片\n# 尝试从训练集中找一张猫的图片\nsample_img_path = None\ncats_dir = TRAIN_DIR / \"cats\"\nif cats_dir.exists():\n    cat_images = list(cats_dir.glob(\"*.jpg\"))\n    if cat_images:\n        sample_img_path = cat_images[0]\n\nif sample_img_path is None:\n    print(\"警告: 未找到样本图片,跳过可视化\")\nelse:\n    # 加载图片\n    img = load_img(sample_img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n    x = img_to_array(img)\n    x = x.reshape((1,) + x.shape)  # 转换为(1, height, width, 3)\n    \n    # 生成4个增强版本\n    print(f\"原始图片: {sample_img_path.name}\")\n    print(\"生成增强样本...\")\n    \n    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n    axes = axes.ravel()\n    \n    i = 0\n    for batch in train_datagen_augmented.flow(x, batch_size=1):\n        axes[i].imshow(array_to_img(batch[0]))\n        axes[i].set_title(f'增强样本 {i+1}', fontsize=12, fontweight='bold')\n        axes[i].axis('off')\n        i += 1\n        if i >= 4:\n            break\n    \n    plt.suptitle('数据增强效果展示', fontsize=14, fontweight='bold', y=0.98)\n    plt.tight_layout()\n    plt.show()\n    \n    print(\"=\" * 60)\n    print(\"数据增强效果说明\")\n    print(\"=\" * 60)\n    print(\"观察点:\")\n    print(\"  - 图像是否保持可识别性\")\n    print(\"  - 变换是否自然合理\")\n    print(\"  - 是否有明显失真\")\n    print(\"=\" * 60)",
   "id": "a37b464940237a66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T11:10:37.201796Z",
     "start_time": "2025-09-13T11:10:37.137285Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n改进模型: 添加Dropout正则化\n\nDropout是一种强大的正则化技术:\n1. 原理: 训练时随机\"丢弃\"部分神经元\n2. 效果: 防止神经元过度依赖特定连接\n3. 结果: 提高模型泛化能力,减少过拟合\n\nDropout rate=0.5的含义:\n- 训练时: 每个神经元有50%概率被临时移除\n- 测试时: 使用所有神经元,但权重按比例缩放\n\n为什么放在Flatten之后?\n- 卷积层通常不加Dropout(或使用SpatialDropout2D)\n- 全连接层更容易过拟合,需要Dropout保护\n\"\"\"\n\ndef build_cnn_with_dropout(input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), \n                           dropout_rate=0.5):\n    \"\"\"\n    构建带Dropout的卷积神经网络\n    \n    Args:\n        input_shape: 输入图像形状\n        dropout_rate: Dropout比例,范围[0,1]\n        \n    Returns:\n        未编译的Keras模型\n    \"\"\"\n    model = models.Sequential(name='Cat_Dog_CNN_Dropout')\n    \n    # 卷积块 1-4 (与原模型相同)\n    model.add(layers.Conv2D(32, (3, 3), activation='relu', \n                            input_shape=input_shape, name='conv1'))\n    model.add(layers.MaxPooling2D((2, 2), name='pool1'))\n    \n    model.add(layers.Conv2D(64, (3, 3), activation='relu', name='conv2'))\n    model.add(layers.MaxPooling2D((2, 2), name='pool2'))\n    \n    model.add(layers.Conv2D(128, (3, 3), activation='relu', name='conv3'))\n    model.add(layers.MaxPooling2D((2, 2), name='pool3'))\n    \n    model.add(layers.Conv2D(128, (3, 3), activation='relu', name='conv4'))\n    model.add(layers.MaxPooling2D((2, 2), name='pool4'))\n    \n    # 展平\n    model.add(layers.Flatten(name='flatten'))\n    \n    # 添加Dropout (关键改进!)\n    model.add(layers.Dropout(dropout_rate, name='dropout'))\n    \n    # 全连接层\n    model.add(layers.Dense(512, activation='relu', name='fc1'))\n    \n    # 输出层\n    model.add(layers.Dense(1, activation='sigmoid', name='output'))\n    \n    return model\n\n# 创建改进后的模型\nmodel_with_dropout = build_cnn_with_dropout(dropout_rate=0.5)\n\nprint(\"=\" * 60)\nprint(\"改进模型架构 (添加Dropout)\")\nprint(\"=\" * 60)\nmodel_with_dropout.summary()\nprint(\"=\" * 60)\nprint(\"\\n关键改进:\")\nprint(\"  ✓ 在全连接层前添加Dropout(rate=0.5)\")\nprint(\"  ✓ 预期效果: 显著减少过拟合\")\nprint(\"=\" * 60)",
   "id": "6d25a41a350a5d9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T11:56:58.301386Z",
     "start_time": "2025-09-13T11:26:08.282650Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n使用数据增强和Dropout训练改进模型\n\n综合应用两种正则化技术:\n1. 数据增强: 扩充训练数据多样性\n2. Dropout: 防止神经网络过拟合\n\n训练策略:\n- 使用增强后的训练数据\n- 验证集不做增强(评估真实泛化能力)\n- 较小的学习率确保稳定收敛\n\"\"\"\n\n# 编译改进后的模型\nmodel_with_dropout.compile(\n    optimizer=optimizers.RMSprop(learning_rate=LEARNING_RATE),\n    loss='binary_crossentropy',\n    metrics=['accuracy']\n)\n\n# 创建增强训练集生成器\ntrain_generator_augmented = train_datagen_augmented.flow_from_directory(\n    str(TRAIN_DIR),\n    target_size=(IMG_HEIGHT, IMG_WIDTH),\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    shuffle=True,\n    seed=RANDOM_SEED\n)\n\n# 计算训练步数\nsteps_per_epoch_aug = train_generator_augmented.samples // BATCH_SIZE\nvalidation_steps_aug = validation_generator.samples // BATCH_SIZE\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"开始训练改进模型 (数据增强 + Dropout)\")\nprint(\"=\" * 60)\nprint(f\"训练样本数: {train_generator_augmented.samples}\")\nprint(f\"验证样本数: {validation_generator.samples}\")\nprint(f\"数据增强: 已启用\")\nprint(f\"Dropout率: 0.5\")\nprint(f\"训练轮数: {EPOCHS}\")\nprint(\"=\" * 60 + \"\\n\")\n\n# 训练模型\nhistory_augmented = model_with_dropout.fit(\n    train_generator_augmented,\n    steps_per_epoch=steps_per_epoch_aug,\n    epochs=EPOCHS,\n    validation_data=validation_generator,\n    validation_steps=validation_steps_aug,\n    verbose=1\n)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"改进模型训练完成\")\nprint(\"=\" * 60)\n\n# 显示最终结果\nfinal_train_loss_aug = history_augmented.history['loss'][-1]\nfinal_train_acc_aug = history_augmented.history['accuracy'][-1]\nfinal_val_loss_aug = history_augmented.history['val_loss'][-1]\nfinal_val_acc_aug = history_augmented.history['val_accuracy'][-1]\n\nprint(f\"\\n最终训练结果 (Epoch {EPOCHS}):\")\nprint(f\"  训练损失: {final_train_loss_aug:.4f}\")\nprint(f\"  训练准确率: {final_train_acc_aug:.4f}\")\nprint(f\"  验证损失: {final_val_loss_aug:.4f}\")\nprint(f\"  验证准确率: {final_val_acc_aug:.4f}\")\n\n# 对比原始模型\nprint(f\"\\n与原始模型对比:\")\nprint(f\"  准确率差距(原始): {acc[-1] - val_acc[-1]:.4f}\")\nprint(f\"  准确率差距(改进): {final_train_acc_aug - final_val_acc_aug:.4f}\")\nprint(\"=\" * 60)",
   "id": "6ebf40634ec95ab6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T12:00:14.763632Z",
     "start_time": "2025-09-13T12:00:14.681119Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n保存训练好的模型\n\n模型保存的重要性:\n1. 避免重复训练,节省时间和计算资源\n2. 部署模型到生产环境\n3. 后续进行模型评估和分析\n\nKeras支持两种保存格式:\n- .h5格式 (HDF5): 传统格式,兼容性好\n- SavedModel格式: TensorFlow推荐,支持更多特性\n\"\"\"\n\n# 定义模型保存路径\nMODEL_SAVE_DIR = Path(\"models\")\nMODEL_SAVE_DIR.mkdir(exist_ok=True)\n\nmodel_save_path = MODEL_SAVE_DIR / \"cat_dog_classifier_improved.h5\"\n\n# 保存模型\ntry:\n    model_with_dropout.save(str(model_save_path))\n    print(\"=\" * 60)\n    print(\"模型保存\")\n    print(\"=\" * 60)\n    print(f\"✓ 模型已保存到: {model_save_path}\")\n    print(f\"  文件大小: {model_save_path.stat().st_size / (1024*1024):.2f} MB\")\n    print(\"=\" * 60)\n    \n    # 验证模型可以加载\n    print(\"\\n验证模型加载...\")\n    loaded_model = models.load_model(str(model_save_path))\n    print(\"✓ 模型加载成功\")\n    \nexcept Exception as e:\n    print(f\"✗ 模型保存失败: {e}\")",
   "id": "e6d0c0697244eb41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T11:58:11.099699Z",
     "start_time": "2025-09-13T11:58:11.084698Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n检查改进模型的训练历史\n\n查看history对象中保存的指标,用于后续可视化和分析\n\"\"\"\n\nprint(\"=\" * 60)\nprint(\"改进模型训练历史指标\")\nprint(\"=\" * 60)\nprint(f\"可用指标: {list(history_augmented.history.keys())}\")\nprint(f\"训练轮数: {len(history_augmented.history['loss'])}\")\nprint(\"=\" * 60)",
   "id": "87d0c5e8b78a0de7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T11:58:27.571424Z",
     "start_time": "2025-09-13T11:58:27.442654Z"
    }
   },
   "cell_type": "code",
   "source": "\"\"\"\n可视化改进模型的训练过程\n\n对比原始模型和改进模型的表现,验证正则化技术的效果\n\"\"\"\n\nimport matplotlib.pyplot as plt\n\n# 提取改进模型的训练历史\nacc_aug = history_augmented.history['accuracy']\nval_acc_aug = history_augmented.history['val_accuracy']\nloss_aug = history_augmented.history['loss']\nval_loss_aug = history_augmented.history['val_loss']\nepochs_range_aug = range(1, len(acc_aug) + 1)\n\n# 创建图表\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\n# 绘制准确率曲线\nax1.plot(epochs_range_aug, acc_aug, 'bo-', label='训练准确率', linewidth=2, markersize=8)\nax1.plot(epochs_range_aug, val_acc_aug, 'rs-', label='验证准确率', linewidth=2, markersize=8)\nax1.set_title('训练和验证准确率 (数据增强+Dropout)', fontsize=14, fontweight='bold')\nax1.set_xlabel('Epoch', fontsize=12)\nax1.set_ylabel('准确率', fontsize=12)\nax1.legend(fontsize=11)\nax1.grid(True, alpha=0.3)\n\n# 绘制损失曲线\nax2.plot(epochs_range_aug, loss_aug, 'bo-', label='训练损失', linewidth=2, markersize=8)\nax2.plot(epochs_range_aug, val_loss_aug, 'rs-', label='验证损失', linewidth=2, markersize=8)\nax2.set_title('训练和验证损失 (数据增强+Dropout)', fontsize=14, fontweight='bold')\nax2.set_xlabel('Epoch', fontsize=12)\nax2.set_ylabel('损失', fontsize=12)\nax2.legend(fontsize=11)\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.show()\n\n# 分析改进效果\nif len(acc_aug) > 1:\n    acc_gap_aug = acc_aug[-1] - val_acc_aug[-1]\n    print(\"\\n\" + \"=\" * 60)\n    print(\"改进模型 - 过拟合分析\")\n    print(\"=\" * 60)\n    print(f\"训练准确率: {acc_aug[-1]:.4f}\")\n    print(f\"验证准确率: {val_acc_aug[-1]:.4f}\")\n    print(f\"准确率差距: {acc_gap_aug:.4f}\")\n    \n    if acc_gap_aug > 0.1:\n        print(\"\\n⚠️  仍存在过拟合,可进一步:\")\n        print(\"  - 增加训练轮数\")\n        print(\"  - 调整Dropout率\")\n        print(\"  - 尝试更强的数据增强\")\n    elif acc_gap_aug > 0.05:\n        print(\"\\n✓ 过拟合已显著改善\")\n    else:\n        print(\"\\n✓ 模型泛化优秀!\")\n    print(\"=\" * 60)\n\n# 对比原始模型和改进模型\nprint(\"\\n\" + \"=\" * 60)\nprint(\"模型对比总结\")\nprint(\"=\" * 60)\nprint(f\"原始模型 - 训练准确率: {acc[-1]:.4f}, 验证准确率: {val_acc[-1]:.4f}, 差距: {acc[-1]-val_acc[-1]:.4f}\")\nprint(f\"改进模型 - 训练准确率: {acc_aug[-1]:.4f}, 验证准确率: {val_acc_aug[-1]:.4f}, 差距: {acc_gap_aug:.4f}\")\nprint(f\"\\n验证准确率提升: {(val_acc_aug[-1] - val_acc[-1]):.4f}\")\nprint(f\"过拟合程度降低: {((acc[-1]-val_acc[-1]) - acc_gap_aug):.4f}\")\nprint(\"=\" * 60)",
   "id": "bf149c28aa389239",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "\"\"\"\n总结与后续步骤\n\n本notebook涵盖的内容:\n✓ 从头构建CNN进行二分类\n✓ 理解过拟合现象及其诊断方法\n✓ 应用数据增强技术\n✓ 使用Dropout进行正则化\n✓ 对比不同技术的效果\n\n后续改进方向:\n1. 使用预训练模型(VGG, ResNet等) - 参见其他notebook\n2. 模型微调(Fine-tuning)\n3. 使用学习率调度(Learning Rate Scheduling)\n4. 尝试其他正则化技术(BatchNormalization, L2正则化)\n5. 集成学习(Ensemble)\n\n生产部署考虑:\n- 模型量化以减小模型大小\n- 转换为TensorFlow Lite用于移动设备\n- 设置合理的推理阈值\n- 实现错误处理和日志记录\n\"\"\"\n\nprint(\"=\" * 60)\nprint(\"notebook执行完成\")\nprint(\"=\" * 60)\nprint(\"\\n关键成果:\")\nprint(\"  ✓ 基础CNN模型已训练\")\nprint(\"  ✓ 改进模型(数据增强+Dropout)已训练\")\nprint(\"  ✓ 模型已保存到本地\")\nprint(\"\\n建议:\")\nprint(\"  - 在完整数据集上训练更多epochs(30+)\")\nprint(\"  - 尝试使用预训练模型提升性能\")\nprint(\"  - 在测试集上评估最终性能\")\nprint(\"=\" * 60)",
   "id": "78ff359029e78275"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}