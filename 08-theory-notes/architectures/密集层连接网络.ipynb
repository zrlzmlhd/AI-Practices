{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 密集连接网络 (Dense/Fully Connected Networks)\n",
    "\n",
    "## 核心概念\n",
    "\n",
    "密集连接网络（也称全连接网络）是最基础的神经网络结构，由Dense层堆叠而成。每个神经元都与前一层的所有神经元连接。\n",
    "\n",
    "### 核心特性\n",
    "\n",
    "1. **全连接性** (Fully Connected)\n",
    "   - 每个神经元与上一层所有神经元相连\n",
    "   - 参数量 = `input_size × output_size + output_size`\n",
    "   - 可以学习任意复杂的非线性映射\n",
    "\n",
    "2. **层级特征提取**\n",
    "   - 浅层学习简单特征组合\n",
    "   - 深层学习抽象特征表示\n",
    "   - 逐层提取高阶特征\n",
    "\n",
    "3. **通用逼近能力**\n",
    "   - 理论上可以逼近任意连续函数\n",
    "   - 需要足够的隐藏层和神经元\n",
    "   - 实践中需要合理设计防止过拟合\n",
    "\n",
    "### 适用场景\n",
    "\n",
    "- **结构化表格数据**: 特征工程后的向量数据\n",
    "- **分类任务**: 二分类、多分类、多标签分类\n",
    "- **回归任务**: 单变量回归、多变量回归\n",
    "- **网络末端**: 作为CNN、RNN等网络的分类/回归头\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "from sklearn.datasets import make_classification, make_multilabel_classification, make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error, r2_score\n",
    "\n",
    "print(f\"TensorFlow版本: {tf.__version__}\")\n",
    "print(f\"GPU可用: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# 设置随机种子\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. 二分类问题 (Binary Classification)\n",
    "\n",
    "### 关键配置\n",
    "- **输出层**: 1个神经元 + sigmoid激活\n",
    "- **损失函数**: `binary_crossentropy`\n",
    "- **评估指标**: accuracy, precision, recall, AUC\n",
    "\n",
    "### 典型应用\n",
    "- 垃圾邮件检测\n",
    "- 欺诈检测\n",
    "- 疾病诊断（是/否）\n",
    "- 情感分析（正面/负面）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成二分类数据集\n",
    "X_binary, y_binary = make_classification(\n",
    "    n_samples=10000,\n",
    "    n_features=20,\n",
    "    n_informative=15,\n",
    "    n_redundant=5,\n",
    "    n_classes=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 数据划分\n",
    "X_train_bin, X_test_bin, y_train_bin, y_test_bin = train_test_split(\n",
    "    X_binary, y_binary, test_size=0.2, random_state=42, stratify=y_binary\n",
    ")\n",
    "\n",
    "# 标准化\n",
    "scaler_bin = StandardScaler()\n",
    "X_train_bin = scaler_bin.fit_transform(X_train_bin)\n",
    "X_test_bin = scaler_bin.transform(X_test_bin)\n",
    "\n",
    "print(f\"训练集形状: {X_train_bin.shape}\")\n",
    "print(f\"测试集形状: {X_test_bin.shape}\")\n",
    "print(f\"类别分布: {np.bincount(y_train_bin)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_binary_classifier(input_dim, hidden_layers=[64, 32], dropout_rate=0.3):\n",
    "    \"\"\"\n",
    "    构建二分类模型\n",
    "    \n",
    "    参数:\n",
    "        input_dim: 输入特征维度\n",
    "        hidden_layers: 隐藏层神经元数量列表\n",
    "        dropout_rate: Dropout比例\n",
    "    \n",
    "    返回:\n",
    "        编译后的模型\n",
    "    \"\"\"\n",
    "    model = models.Sequential(name='Binary_Classifier')\n",
    "    \n",
    "    # 输入层\n",
    "    model.add(layers.Input(shape=(input_dim,)))\n",
    "    \n",
    "    # 隐藏层\n",
    "    for i, units in enumerate(hidden_layers):\n",
    "        model.add(layers.Dense(units, activation='relu', name=f'hidden_{i+1}'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "    \n",
    "    # 输出层：1个神经元 + sigmoid激活\n",
    "    # sigmoid将输出映射到(0, 1)，表示属于正类的概率\n",
    "    model.add(layers.Dense(1, activation='sigmoid', name='output'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建并编译二分类模型\n",
    "model_binary = build_binary_classifier(input_dim=X_train_bin.shape[1])\n",
    "\n",
    "model_binary.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',  # 二分类交叉熵损失\n",
    "    metrics=['accuracy', \n",
    "             keras.metrics.Precision(name='precision'),\n",
    "             keras.metrics.Recall(name='recall'),\n",
    "             keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "model_binary.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型（测试用简化参数）\n",
    "history_binary = model_binary.fit(\n",
    "    X_train_bin, y_train_bin,\n",
    "    batch_size=128,\n",
    "    epochs=30,  # 测试时用2个epoch，实际训练建议30-50\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估二分类模型\n",
    "results = model_binary.evaluate(X_test_bin, y_test_bin, verbose=0)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"二分类模型测试结果:\")\n",
    "for name, value in zip(model_binary.metrics_names, results):\n",
    "    print(f\"{name}: {value:.4f}\")\n",
    "\n",
    "# 预测\n",
    "y_pred_prob = model_binary.predict(X_test_bin, verbose=0)\n",
    "y_pred_bin = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "# 混淆矩阵\n",
    "cm = confusion_matrix(y_test_bin, y_pred_bin)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('二分类混淆矩阵')\n",
    "plt.ylabel('真实标签')\n",
    "plt.xlabel('预测标签')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n分类报告:\")\n",
    "print(classification_report(y_test_bin, y_pred_bin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. 单标签多分类问题 (Multi-class Classification)\n",
    "\n",
    "### 关键配置\n",
    "- **输出层**: N个神经元 (N=类别数) + softmax激活\n",
    "- **损失函数**: \n",
    "  - 标签是one-hot编码: `categorical_crossentropy`\n",
    "  - 标签是整数编码: `sparse_categorical_crossentropy`\n",
    "- **评估指标**: accuracy, top-k accuracy\n",
    "\n",
    "### 典型应用\n",
    "- 手写数字识别\n",
    "- 文档分类\n",
    "- 图像分类\n",
    "- 物种识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用MNIST数据集作为多分类示例\n",
    "(X_train_multi, y_train_multi), (X_test_multi, y_test_multi) = mnist.load_data()\n",
    "\n",
    "# 展平图像：28x28 → 784\n",
    "X_train_multi = X_train_multi.reshape(-1, 784).astype('float32') / 255.0\n",
    "X_test_multi = X_test_multi.reshape(-1, 784).astype('float32') / 255.0\n",
    "\n",
    "# 标签one-hot编码\n",
    "num_classes = 10\n",
    "y_train_multi_cat = keras.utils.to_categorical(y_train_multi, num_classes)\n",
    "y_test_multi_cat = keras.utils.to_categorical(y_test_multi, num_classes)\n",
    "\n",
    "print(f\"训练集形状: {X_train_multi.shape}\")\n",
    "print(f\"标签形状(one-hot): {y_train_multi_cat.shape}\")\n",
    "print(f\"类别数: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_multiclass_classifier(input_dim, num_classes, hidden_layers=[256, 128, 64]):\n",
    "    \"\"\"\n",
    "    构建多分类模型\n",
    "    \n",
    "    参数:\n",
    "        input_dim: 输入特征维度\n",
    "        num_classes: 类别数量\n",
    "        hidden_layers: 隐藏层神经元数量列表\n",
    "    \n",
    "    返回:\n",
    "        编译后的模型\n",
    "    \"\"\"\n",
    "    model = models.Sequential(name='Multiclass_Classifier')\n",
    "    \n",
    "    model.add(layers.Input(shape=(input_dim,)))\n",
    "    \n",
    "    # 隐藏层\n",
    "    for i, units in enumerate(hidden_layers):\n",
    "        model.add(layers.Dense(units, activation='relu', name=f'hidden_{i+1}'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    # 输出层：N个神经元 + softmax激活\n",
    "    # softmax确保输出和为1，每个值表示对应类别的概率\n",
    "    model.add(layers.Dense(num_classes, activation='softmax', name='output'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建并编译多分类模型\n",
    "model_multiclass = build_multiclass_classifier(\n",
    "    input_dim=784,\n",
    "    num_classes=10\n",
    ")\n",
    "\n",
    "model_multiclass.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',  # one-hot编码用categorical\n",
    "    metrics=['accuracy', keras.metrics.TopKCategoricalAccuracy(k=3, name='top3_acc')]\n",
    ")\n",
    "\n",
    "model_multiclass.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "history_multiclass = model_multiclass.fit(\n",
    "    X_train_multi, y_train_multi_cat,\n",
    "    batch_size=256,\n",
    "    epochs=30,  # 测试时用2个epoch\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估多分类模型\n",
    "results = model_multiclass.evaluate(X_test_multi, y_test_multi_cat, verbose=0)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"多分类模型测试结果:\")\n",
    "for name, value in zip(model_multiclass.metrics_names, results):\n",
    "    print(f\"{name}: {value:.4f}\")\n",
    "\n",
    "# 预测并可视化\n",
    "y_pred_multi = model_multiclass.predict(X_test_multi[:16], verbose=0)\n",
    "y_pred_classes = np.argmax(y_pred_multi, axis=1)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(16):\n",
    "    plt.subplot(2, 8, i+1)\n",
    "    plt.imshow(X_test_multi[i].reshape(28, 28), cmap='gray')\n",
    "    true_label = y_test_multi[i]\n",
    "    pred_label = y_pred_classes[i]\n",
    "    confidence = y_pred_multi[i][pred_label]\n",
    "    \n",
    "    color = 'green' if true_label == pred_label else 'red'\n",
    "    plt.title(f'T:{true_label} P:{pred_label}\\n{confidence:.2%}', \n",
    "              fontsize=8, color=color)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. 多标签分类问题 (Multi-label Classification)\n",
    "\n",
    "### 关键配置\n",
    "- **输出层**: N个神经元 (N=标签数) + sigmoid激活\n",
    "- **损失函数**: `binary_crossentropy` (每个标签独立二分类)\n",
    "- **标签格式**: k-hot编码 (可以同时为多个类别)\n",
    "\n",
    "### 与多分类的区别\n",
    "- 多分类: 互斥类别（softmax），只能属于一个类\n",
    "- 多标签: 非互斥（sigmoid），可以属于多个类\n",
    "\n",
    "### 典型应用\n",
    "- 图片标签预测（一张图可能有多个标签）\n",
    "- 文本主题分类（一篇文章可能属于多个主题）\n",
    "- 电影类型分类（动作+冒险+科幻）\n",
    "- 疾病诊断（患者可能同时患有多种疾病）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成多标签分类数据集\n",
    "X_multilabel, y_multilabel = make_multilabel_classification(\n",
    "    n_samples=5000,\n",
    "    n_features=50,\n",
    "    n_classes=10,\n",
    "    n_labels=3,  # 平均每个样本有3个标签\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 数据划分\n",
    "X_train_ml, X_test_ml, y_train_ml, y_test_ml = train_test_split(\n",
    "    X_multilabel, y_multilabel, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 标准化\n",
    "scaler_ml = StandardScaler()\n",
    "X_train_ml = scaler_ml.fit_transform(X_train_ml)\n",
    "X_test_ml = scaler_ml.transform(X_test_ml)\n",
    "\n",
    "print(f\"训练集形状: {X_train_ml.shape}\")\n",
    "print(f\"标签形状: {y_train_ml.shape}\")\n",
    "print(f\"标签示例(k-hot): {y_train_ml[0]}\")\n",
    "print(f\"平均标签数: {y_train_ml.sum(axis=1).mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_multilabel_classifier(input_dim, num_labels, hidden_layers=[128, 64]):\n",
    "    \"\"\"\n",
    "    构建多标签分类模型\n",
    "    \n",
    "    参数:\n",
    "        input_dim: 输入特征维度\n",
    "        num_labels: 标签数量\n",
    "        hidden_layers: 隐藏层神经元数量列表\n",
    "    \n",
    "    返回:\n",
    "        编译后的模型\n",
    "    \"\"\"\n",
    "    model = models.Sequential(name='Multilabel_Classifier')\n",
    "    \n",
    "    model.add(layers.Input(shape=(input_dim,)))\n",
    "    \n",
    "    # 隐藏层\n",
    "    for i, units in enumerate(hidden_layers):\n",
    "        model.add(layers.Dense(units, activation='relu', name=f'hidden_{i+1}'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    # 输出层：N个神经元 + sigmoid激活\n",
    "    # 每个输出独立进行二分类判断\n",
    "    model.add(layers.Dense(num_labels, activation='sigmoid', name='output'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建并编译多标签分类模型\n",
    "model_multilabel = build_multilabel_classifier(\n",
    "    input_dim=X_train_ml.shape[1],\n",
    "    num_labels=y_train_ml.shape[1]\n",
    ")\n",
    "\n",
    "model_multilabel.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',  # 每个标签独立的二分类损失\n",
    "    metrics=[\n",
    "        keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "        keras.metrics.Precision(name='precision'),\n",
    "        keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_multilabel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "history_multilabel = model_multilabel.fit(\n",
    "    X_train_ml, y_train_ml,\n",
    "    batch_size=128,\n",
    "    epochs=30,  # 测试时用2个epoch\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估多标签分类模型\n",
    "results = model_multilabel.evaluate(X_test_ml, y_test_ml, verbose=0)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"多标签分类模型测试结果:\")\n",
    "for name, value in zip(model_multilabel.metrics_names, results):\n",
    "    print(f\"{name}: {value:.4f}\")\n",
    "\n",
    "# 预测\n",
    "y_pred_ml = model_multilabel.predict(X_test_ml[:5], verbose=0)\n",
    "y_pred_binary = (y_pred_ml > 0.5).astype(int)\n",
    "\n",
    "print(\"\\n预测示例:\")\n",
    "for i in range(5):\n",
    "    print(f\"样本 {i+1}:\")\n",
    "    print(f\"  真实标签: {y_test_ml[i]}\")\n",
    "    print(f\"  预测标签: {y_pred_binary[i]}\")\n",
    "    print(f\"  预测概率: {y_pred_ml[i].round(2)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. 回归问题 (Regression)\n",
    "\n",
    "### 关键配置\n",
    "- **输出层**: \n",
    "  - 单变量回归: 1个神经元，无激活函数\n",
    "  - 多变量回归: N个神经元，无激活函数\n",
    "- **损失函数**: \n",
    "  - `mean_squared_error` (MSE): 惩罚大误差\n",
    "  - `mean_absolute_error` (MAE): 对离群点更鲁棒\n",
    "  - `huber_loss`: MSE和MAE的折衷\n",
    "- **评估指标**: MSE, MAE, R²\n",
    "\n",
    "### 典型应用\n",
    "- 房价预测\n",
    "- 股票价格预测\n",
    "- 销量预测\n",
    "- 年龄估计"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成回归数据集\n",
    "X_reg, y_reg = make_regression(\n",
    "    n_samples=5000,\n",
    "    n_features=30,\n",
    "    n_informative=20,\n",
    "    noise=10,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 数据划分\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# 标准化输入和输出\n",
    "scaler_X_reg = StandardScaler()\n",
    "scaler_y_reg = StandardScaler()\n",
    "\n",
    "X_train_reg = scaler_X_reg.fit_transform(X_train_reg)\n",
    "X_test_reg = scaler_X_reg.transform(X_test_reg)\n",
    "\n",
    "y_train_reg = scaler_y_reg.fit_transform(y_train_reg.reshape(-1, 1)).flatten()\n",
    "y_test_reg = scaler_y_reg.transform(y_test_reg.reshape(-1, 1)).flatten()\n",
    "\n",
    "print(f\"训练集形状: {X_train_reg.shape}\")\n",
    "print(f\"目标值范围: [{y_train_reg.min():.2f}, {y_train_reg.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_regressor(input_dim, output_dim=1, hidden_layers=[128, 64, 32]):\n",
    "    \"\"\"\n",
    "    构建回归模型\n",
    "    \n",
    "    参数:\n",
    "        input_dim: 输入特征维度\n",
    "        output_dim: 输出维度（单变量=1，多变量=N）\n",
    "        hidden_layers: 隐藏层神经元数量列表\n",
    "    \n",
    "    返回:\n",
    "        编译后的模型\n",
    "    \"\"\"\n",
    "    model = models.Sequential(name='Regressor')\n",
    "    \n",
    "    model.add(layers.Input(shape=(input_dim,)))\n",
    "    \n",
    "    # 隐藏层\n",
    "    for i, units in enumerate(hidden_layers):\n",
    "        model.add(layers.Dense(units, activation='relu', name=f'hidden_{i+1}'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.2))\n",
    "    \n",
    "    # 输出层：无激活函数\n",
    "    # 输出可以是任意实数\n",
    "    model.add(layers.Dense(output_dim, name='output'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建并编译回归模型\n",
    "model_regression = build_regressor(input_dim=X_train_reg.shape[1])\n",
    "\n",
    "model_regression.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mse',  # 均方误差\n",
    "    metrics=[\n",
    "        keras.metrics.MeanAbsoluteError(name='mae'),\n",
    "        keras.metrics.RootMeanSquaredError(name='rmse')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_regression.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "history_regression = model_regression.fit(\n",
    "    X_train_reg, y_train_reg,\n",
    "    batch_size=128,\n",
    "    epochs=30,  # 测试时用2个epoch\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评估回归模型\n",
    "results = model_regression.evaluate(X_test_reg, y_test_reg, verbose=0)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"回归模型测试结果:\")\n",
    "for name, value in zip(model_regression.metrics_names, results):\n",
    "    print(f\"{name}: {value:.4f}\")\n",
    "\n",
    "# 预测并计算R²\n",
    "y_pred_reg = model_regression.predict(X_test_reg, verbose=0).flatten()\n",
    "r2 = r2_score(y_test_reg, y_pred_reg)\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "# 可视化预测结果\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 预测值 vs 真实值散点图\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test_reg, y_pred_reg, alpha=0.5)\n",
    "plt.plot([y_test_reg.min(), y_test_reg.max()], \n",
    "         [y_test_reg.min(), y_test_reg.max()], 'r--', lw=2)\n",
    "plt.xlabel('真实值')\n",
    "plt.ylabel('预测值')\n",
    "plt.title(f'预测值 vs 真实值 (R²={r2:.4f})')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 残差分布\n",
    "plt.subplot(1, 2, 2)\n",
    "residuals = y_test_reg - y_pred_reg\n",
    "plt.hist(residuals, bins=50, edgecolor='black')\n",
    "plt.xlabel('残差')\n",
    "plt.ylabel('频数')\n",
    "plt.title('残差分布')\n",
    "plt.axvline(x=0, color='r', linestyle='--', lw=2)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. 关键知识总结\n",
    "\n",
    "### 任务类型对照表\n",
    "\n",
    "| 任务类型 | 输出层配置 | 激活函数 | 损失函数 | 标签格式 |\n",
    "|---------|-----------|---------|---------|----------|\n",
    "| **二分类** | 1个神经元 | sigmoid | binary_crossentropy | 0/1 |\n",
    "| **多分类** | N个神经元 | softmax | categorical_crossentropy | one-hot |\n",
    "| **多分类(整数标签)** | N个神经元 | softmax | sparse_categorical_crossentropy | 整数 |\n",
    "| **多标签** | N个神经元 | sigmoid | binary_crossentropy | k-hot |\n",
    "| **回归** | 1个神经元 | 无 | mse/mae | 连续值 |\n",
    "| **多变量回归** | N个神经元 | 无 | mse/mae | 连续向量 |\n",
    "\n",
    "### Dense层参数计算\n",
    "\n",
    "对于 `Dense(units)`，如果输入维度为 `D_in`:\n",
    "- **参数量** = `D_in × units + units` (权重 + 偏置)\n",
    "- **输出形状** = `(batch_size, units)`\n",
    "\n",
    "### 网络设计原则\n",
    "\n",
    "1. **隐藏层数量**\n",
    "   - 简单问题: 1-2层\n",
    "   - 中等复杂: 3-4层\n",
    "   - 复杂问题: 5层以上\n",
    "\n",
    "2. **神经元数量**\n",
    "   - 输入层: 根据特征数量\n",
    "   - 隐藏层: 通常逐层递减 (256 → 128 → 64)\n",
    "   - 输出层: 根据任务类型\n",
    "\n",
    "3. **激活函数选择**\n",
    "   - 隐藏层: ReLU（首选）、LeakyReLU、ELU\n",
    "   - 输出层: 根据任务类型（见上表）\n",
    "\n",
    "4. **正则化技术**\n",
    "   - Dropout: 0.2-0.5\n",
    "   - Batch Normalization: 加速训练\n",
    "   - L1/L2正则化: 控制权重大小\n",
    "\n",
    "### 常见问题与解决方案\n",
    "\n",
    "| 问题 | 现象 | 解决方案 |\n",
    "|------|------|----------|\n",
    "| **过拟合** | 训练精度高，验证精度低 | 增加Dropout、减少神经元、数据增强 |\n",
    "| **欠拟合** | 训练和验证精度都低 | 增加网络容量、训练更多epoch |\n",
    "| **梯度消失** | 深层网络训练困难 | 使用ReLU、BatchNorm、ResNet结构 |\n",
    "| **类别不平衡** | 偏向多数类 | 类权重、重采样、focal loss |\n",
    "| **训练慢** | 收敛速度慢 | 提高学习率、BatchNorm、优化器调整 |\n",
    "\n",
    "---\n",
    "\n",
    "## 完整训练配置模板\n",
    "\n",
    "```python\n",
    "# 实际项目中建议使用的完整训练配置\n",
    "\n",
    "# 回调函数\n",
    "# callbacks = [\n",
    "#     keras.callbacks.EarlyStopping(\n",
    "#         monitor='val_loss',\n",
    "#         patience=15,\n",
    "#         restore_best_weights=True\n",
    "#     ),\n",
    "#     keras.callbacks.ReduceLROnPlateau(\n",
    "#         monitor='val_loss',\n",
    "#         factor=0.5,\n",
    "#         patience=7,\n",
    "#         min_lr=1e-7\n",
    "#     ),\n",
    "#     keras.callbacks.ModelCheckpoint(\n",
    "#         'best_model.h5',\n",
    "#         monitor='val_accuracy',\n",
    "#         save_best_only=True\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "# 训练\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     batch_size=64,\n",
    "#     epochs=100,\n",
    "#     validation_split=0.2,\n",
    "#     callbacks=callbacks,\n",
    "#     verbose=1\n",
    "# )\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}