{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 卷积神经网络 (Convolutional Neural Networks)\n",
    "\n",
    "## 核心概念\n",
    "\n",
    "卷积神经网络是一种专门用于处理具有网格结构数据的神经网络架构，特别适用于图像、序列等数据。\n",
    "\n",
    "### 核心特性\n",
    "\n",
    "1. **局部连接性** (Local Connectivity)\n",
    "   - 每个神经元只与输入数据的局部区域连接\n",
    "   - 大幅减少参数数量，提高计算效率\n",
    "   - 符合视觉感受野的生物学特性\n",
    "\n",
    "2. **参数共享** (Parameter Sharing)\n",
    "   - 同一个卷积核在整个输入上滑动\n",
    "   - 进一步减少参数，防止过拟合\n",
    "   - 学习到的特征可在不同位置复用\n",
    "\n",
    "3. **平移不变性** (Translation Invariance)\n",
    "   - 对输入的空间位置变化具有鲁棒性\n",
    "   - 特征检测不依赖于绝对位置\n",
    "   - 提高模型的泛化能力\n",
    "\n",
    "### 适用数据类型\n",
    "\n",
    "- **Conv1D**: 一维序列数据（文本、时间序列、音频信号）\n",
    "- **Conv2D**: 二维网格数据（灰度/彩色图像）\n",
    "- **Conv3D**: 三维体积数据（视频、医学影像）\n",
    "\n",
    "### 典型架构模式\n",
    "\n",
    "```\n",
    "Input → [Conv → Activation → Pooling] × N → Flatten/GlobalPooling → Dense → Output\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境准备与数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"TensorFlow版本: {tf.__version__}\")\n",
    "print(f\"GPU可用: {tf.config.list_physical_devices('GPU')}\")\n",
    "\n",
    "# 设置随机种子以保证结果可复现\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载CIFAR-10数据集\n",
    "# CIFAR-10包含60000张32x32彩色图像，分为10个类别\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# 数据集基本信息\n",
    "print(f\"训练集形状: {X_train.shape}\")  # (50000, 32, 32, 3)\n",
    "print(f\"测试集形状: {X_test.shape}\")    # (10000, 32, 32, 3)\n",
    "print(f\"标签形状: {y_train.shape}\")     # (50000, 1)\n",
    "print(f\"数据类型: {X_train.dtype}\")\n",
    "print(f\"像素值范围: [{X_train.min()}, {X_train.max()}]\")\n",
    "\n",
    "# 类别名称\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据可视化\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(20):\n",
    "    plt.subplot(4, 5, i + 1)\n",
    "    plt.imshow(X_train[i])\n",
    "    plt.title(class_names[y_train[i][0]], fontsize=9)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "# 1. 归一化到[0, 1]区间，加速收敛\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# 2. 标签one-hot编码\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(f\"预处理后数据范围: [{X_train.min():.2f}, {X_train.max():.2f}]\")\n",
    "print(f\"标签形状: {y_train.shape}\")  # (50000, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. 标准卷积神经网络 (Standard CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_standard_cnn(input_shape=(32, 32, 3), num_classes=10):\n",
    "    \"\"\"\n",
    "    构建标准卷积神经网络\n",
    "    \n",
    "    架构特点:\n",
    "    - 逐层增加通道数(32→64→128)\n",
    "    - 使用MaxPooling降低空间维度\n",
    "    - 使用Dropout防止过拟合\n",
    "    - 最后使用全局平均池化替代Flatten，减少参数\n",
    "    \n",
    "    参数:\n",
    "        input_shape: 输入数据形状 (height, width, channels)\n",
    "        num_classes: 分类类别数\n",
    "    \n",
    "    返回:\n",
    "        编译后的Keras模型\n",
    "    \"\"\"\n",
    "    model = models.Sequential(name='Standard_CNN')\n",
    "    \n",
    "    # 第一个卷积块\n",
    "    # Conv2D(filters, kernel_size, ...)\n",
    "    # - filters: 卷积核数量，决定输出通道数\n",
    "    # - kernel_size: 卷积核大小，通常使用3x3或5x5\n",
    "    # - padding='same': 保持空间维度不变\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', \n",
    "                            padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())  # 批归一化，加速训练\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))  # 空间维度减半: 32x32 → 16x16\n",
    "    model.add(layers.Dropout(0.25))         # 随机丢弃25%神经元\n",
    "    \n",
    "    # 第二个卷积块\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))  # 16x16 → 8x8\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    \n",
    "    # 第三个卷积块\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))  # 8x8 → 4x4\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    \n",
    "    # 全局平均池化层\n",
    "    # 相比Flatten，GAP可以:\n",
    "    # 1. 大幅减少参数 (4x4x128=2048 → 128)\n",
    "    # 2. 降低过拟合风险\n",
    "    # 3. 对输入尺寸更加灵活\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    \n",
    "    # 全连接分类层\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建并编译模型\n",
    "model_standard = build_standard_cnn()\n",
    "\n",
    "# 编译模型\n",
    "model_standard.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 查看模型结构\n",
    "model_standard.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型（使用简化参数进行测试）\n",
    "history_standard = model_standard.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=128,\n",
    "    epochs=50,  # 测试时使用2个epoch，实际训练建议50-100\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. 深度可分离卷积网络 (Depthwise Separable Convolution)\n",
    "\n",
    "### 原理说明\n",
    "\n",
    "深度可分离卷积将标准卷积分解为两步：\n",
    "\n",
    "1. **Depthwise卷积**: 对每个输入通道独立进行空间卷积\n",
    "2. **Pointwise卷积**: 1x1卷积对通道进行线性组合\n",
    "\n",
    "### 计算复杂度对比\n",
    "\n",
    "假设输入: `(H, W, C_in)`, 输出: `(H, W, C_out)`, 卷积核: `K×K`\n",
    "\n",
    "- **标准卷积**: `H × W × C_in × C_out × K²` 次乘法\n",
    "- **深度可分离卷积**: `H × W × C_in × K² + H × W × C_in × C_out` 次乘法\n",
    "\n",
    "**计算量降低**: 约 `1/C_out + 1/K²` 倍\n",
    "\n",
    "对于 `C_out=256, K=3`: 降低约 **8-9倍**\n",
    "\n",
    "### 优势\n",
    "- 参数量显著减少（约8-10倍）\n",
    "- 训练速度更快\n",
    "- 降低过拟合风险\n",
    "- 准确率通常相当或略优于标准卷积\n",
    "\n",
    "### 应用\n",
    "- MobileNet系列（移动端模型）\n",
    "- Xception网络\n",
    "- EfficientNet系列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_separable_cnn(input_shape=(32, 32, 3), num_classes=10):\n",
    "    \"\"\"\n",
    "    构建深度可分离卷积网络\n",
    "    \n",
    "    使用SeparableConv2D替代Conv2D，显著减少参数量和计算量\n",
    "    \"\"\"\n",
    "    model = models.Sequential(name='Separable_CNN')\n",
    "    \n",
    "    # 第一层仍使用标准卷积（输入通道较少时）\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', \n",
    "                            padding='same', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    \n",
    "    # 后续使用深度可分离卷积\n",
    "    model.add(layers.SeparableConv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    \n",
    "    model.add(layers.SeparableConv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.SeparableConv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    \n",
    "    model.add(layers.SeparableConv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.SeparableConv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.25))\n",
    "    \n",
    "    # 全局平均池化 + 分类层\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建深度可分离卷积模型\n",
    "model_separable = build_separable_cnn()\n",
    "\n",
    "model_separable.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_separable.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数量对比\n",
    "standard_params = model_standard.count_params()\n",
    "separable_params = model_separable.count_params()\n",
    "\n",
    "print(f\"标准卷积网络参数量: {standard_params:,}\")\n",
    "print(f\"深度可分离卷积参数量: {separable_params:,}\")\n",
    "print(f\"参数减少比例: {(1 - separable_params/standard_params)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练深度可分离卷积模型\n",
    "history_separable = model_separable.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=128,\n",
    "    epochs=50,  # 测试时使用2个epoch\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. 模型评估与对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在测试集上评估\n",
    "print(\"=\"*50)\n",
    "print(\"标准卷积网络:\")\n",
    "loss_std, acc_std = model_standard.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"测试损失: {loss_std:.4f}\")\n",
    "print(f\"测试精度: {acc_std:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"深度可分离卷积网络:\")\n",
    "loss_sep, acc_sep = model_separable.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"测试损失: {loss_sep:.4f}\")\n",
    "print(f\"测试精度: {acc_sep:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"对比总结:\")\n",
    "print(f\"参数量减少: {(1 - separable_params/standard_params)*100:.1f}%\")\n",
    "print(f\"精度差异: {(acc_sep - acc_std)*100:+.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化训练历史\n",
    "def plot_training_history(history, title):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # 损失曲线\n",
    "    axes[0].plot(history.history['loss'], label='训练损失')\n",
    "    axes[0].plot(history.history['val_loss'], label='验证损失')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title(f'{title} - 损失')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 精度曲线\n",
    "    axes[1].plot(history.history['accuracy'], label='训练精度')\n",
    "    axes[1].plot(history.history['val_accuracy'], label='验证精度')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_title(f'{title} - 精度')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history_standard, '标准卷积网络')\n",
    "plot_training_history(history_separable, '深度可分离卷积网络')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. 预测与可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机选择一些测试样本进行预测\n",
    "num_samples = 10\n",
    "indices = np.random.choice(len(X_test), num_samples, replace=False)\n",
    "\n",
    "# 获取预测结果\n",
    "predictions = model_separable.predict(X_test[indices])\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(y_test[indices], axis=1)\n",
    "\n",
    "# 可视化预测结果\n",
    "plt.figure(figsize=(15, 6))\n",
    "for i in range(num_samples):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    plt.imshow(X_test[indices[i]])\n",
    "    \n",
    "    pred_class = predicted_classes[i]\n",
    "    true_class = true_classes[i]\n",
    "    confidence = predictions[i][pred_class]\n",
    "    \n",
    "    color = 'green' if pred_class == true_class else 'red'\n",
    "    title = f'预测: {class_names[pred_class]}\\n'\n",
    "    title += f'真实: {class_names[true_class]}\\n'\n",
    "    title += f'置信度: {confidence:.2%}'\n",
    "    \n",
    "    plt.title(title, fontsize=8, color=color)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. 关键知识总结\n",
    "\n",
    "### 卷积层参数计算\n",
    "\n",
    "对于 `Conv2D(filters, (k, k))`，如果输入通道数为 `C_in`:\n",
    "- **参数量** = `k × k × C_in × filters + filters` (权重 + 偏置)\n",
    "- **输出形状** = `(H_out, W_out, filters)`\n",
    "\n",
    "其中:\n",
    "- `H_out = (H_in + 2×padding - k) / stride + 1`\n",
    "- `W_out = (W_in + 2×padding - k) / stride + 1`\n",
    "\n",
    "### Pooling层作用\n",
    "\n",
    "1. **降低空间维度**: 减少计算量和参数\n",
    "2. **增强平移不变性**: 对微小位移更鲁棒\n",
    "3. **扩大感受野**: 每个神经元看到更大的输入区域\n",
    "4. **防止过拟合**: 丢弃部分空间信息\n",
    "\n",
    "### 常用技巧\n",
    "\n",
    "1. **批归一化** (Batch Normalization)\n",
    "   - 加速训练收敛\n",
    "   - 允许使用更大的学习率\n",
    "   - 起到正则化作用\n",
    "\n",
    "2. **Dropout**\n",
    "   - 训练时随机丢弃神经元\n",
    "   - 防止过拟合\n",
    "   - 通常在全连接层使用较大比例(0.5)，卷积层使用较小比例(0.25)\n",
    "\n",
    "3. **全局平均池化** vs **Flatten**\n",
    "   - GAP参数更少，更不容易过拟合\n",
    "   - GAP对输入尺寸变化更鲁棒\n",
    "   - Flatten保留更多空间信息\n",
    "\n",
    "### 网络设计原则\n",
    "\n",
    "1. **逐层增加通道数**: 32 → 64 → 128 → 256\n",
    "2. **逐层减小空间维度**: 通过pooling或stride=2的卷积\n",
    "3. **深度优先**: 多个小卷积核(3×3)优于单个大卷积核(5×5)\n",
    "4. **正则化**: BN + Dropout + 数据增强\n",
    "5. **激活函数**: ReLU及其变体(LeakyReLU, ELU)表现最好\n",
    "\n",
    "---\n",
    "\n",
    "## 完整训练代码模板\n",
    "\n",
    "```python\n",
    "# 实际项目中建议使用的完整训练配置\n",
    "# epochs = 100\n",
    "# batch_size = 64\n",
    "\n",
    "# callbacks = [\n",
    "#     keras.callbacks.EarlyStopping(\n",
    "#         monitor='val_loss',\n",
    "#         patience=10,\n",
    "#         restore_best_weights=True\n",
    "#     ),\n",
    "#     keras.callbacks.ReduceLROnPlateau(\n",
    "#         monitor='val_loss',\n",
    "#         factor=0.5,\n",
    "#         patience=5,\n",
    "#         min_lr=1e-7\n",
    "#     ),\n",
    "#     keras.callbacks.ModelCheckpoint(\n",
    "#         'best_model.h5',\n",
    "#         monitor='val_accuracy',\n",
    "#         save_best_only=True\n",
    "#     )\n",
    "# ]\n",
    "\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     batch_size=batch_size,\n",
    "#     epochs=epochs,\n",
    "#     validation_split=0.1,\n",
    "#     callbacks=callbacks,\n",
    "#     verbose=1\n",
    "# )\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}