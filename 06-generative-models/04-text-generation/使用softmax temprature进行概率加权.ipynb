{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": "# Temperature采样的数学原理与可视化\n\n## 1. 理论背景\n\n在序列生成任务中，模型输出的是logits（未归一化的对数概率）。标准的softmax函数将这些logits转换为概率分布。\n\n**标准Softmax函数**:\n$$P(i) = \\frac{\\exp(z_i)}{\\sum_j \\exp(z_j)}$$\n\n**Temperature Softmax函数**:\n$$P_T(i) = \\frac{\\exp(z_i/T)}{\\sum_j \\exp(z_j/T)}$$\n\n其中：\n- $z_i$ 是第 $i$ 个类别的logit\n- $T$ 是温度参数\n- $P_T(i)$ 是经过温度缩放后的概率\n\n## 2. 温度参数的影响\n\n- **$T \\to 0$**: 概率分布变得极度尖锐，接近one-hot分布（贪婪采样）\n- **$T = 1$**: 保持模型原始输出的概率分布\n- **$T > 1$**: 概率分布变得平滑，增加低概率项的采样机会\n- **$T \\to \\infty$**: 概率分布趋近均匀分布（完全随机）"
  },
  {
   "cell_type": "code",
   "id": "50k40yif8k",
   "source": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# 设置中文显示\nplt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\nplt.rcParams['axes.unicode_minus'] = False\n\n# 设置随机种子\nnp.random.seed(42)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "iohktj4tze",
   "source": "## 7. 总结与实践建议\n\n### 核心要点\n\n1. **温度参数的本质**：调整概率分布的\"锐度\"，控制模型输出的确定性与多样性之间的权衡\n\n2. **数学性质**：\n   - 温度缩放是在logit空间进行的线性变换\n   - 等价于在概率空间进行指数变换后重新归一化\n   - 不改变概率的相对顺序，只改变其差距\n\n3. **信息论视角**：\n   - 温度控制输出分布的熵\n   - 低温 = 低熵 = 低不确定性 = 高确定性\n   - 高温 = 高熵 = 高不确定性 = 高随机性\n\n### 实际应用指南\n\n| 任务类型 | 推荐温度范围 | 说明 |\n|---------|-------------|------|\n| 机器翻译 | 0.3 - 0.7 | 需要高准确性，避免幻觉 |\n| 代码生成 | 0.2 - 0.5 | 语法严格，错误代价高 |\n| 摘要生成 | 0.5 - 0.8 | 平衡准确性和表达多样性 |\n| 对话系统 | 0.7 - 1.0 | 需要自然和多样的回复 |\n| 创意写作 | 0.8 - 1.5 | 鼓励创造性和新颖性 |\n| 故事续写 | 1.0 - 2.0 | 追求意外和想象力 |\n\n### 调优技巧\n\n1. **起始建议**：从T=0.7开始，根据生成质量调整\n2. **A/B测试**：对比不同温度下的生成样本，选择最佳值\n3. **动态调整**：生成过程中可以动态改变温度（如开始低温，后期高温）\n4. **与其他技术结合**：配合Top-k、Top-p（nucleus sampling）使用效果更佳\n\n### 常见陷阱\n\n- ❌ **过低温度** (T<0.1)：输出过于重复和单调\n- ❌ **过高温度** (T>3.0)：输出不连贯，出现语法错误\n- ❌ **忽视任务特性**：不同任务需要不同温度策略\n- ✅ **实验验证**：始终通过实验验证温度参数的效果",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "1olshbxa45f",
   "source": "# 模拟一个简化的词汇表\nvocabulary = ['the', 'a', 'is', 'are', 'cat', 'dog', 'beautiful', 'runs', 'quickly', 'slowly',\n              'happy', 'sad', 'very', 'extremely', 'and', 'but', 'or', 'with', 'without', 'in']\n\n# 模拟模型输出的logits（假设\"the\"和\"a\"概率较高）\nsimulated_logits = np.array([3.0, 2.5, 1.0, 0.8, 1.5, 1.2, 0.5, 0.6, 0.3, 0.2,\n                              0.4, 0.1, 0.7, 0.0, 1.1, 0.9, 0.4, 0.8, 0.3, 0.6])\n\ndef sample_words(logits, vocab, temperature, num_samples=100):\n    \"\"\"\n    从给定的logits分布中采样单词\n    \n    参数:\n        logits: 模型输出的logits\n        vocab: 词汇表\n        temperature: 温度参数\n        num_samples: 采样次数\n    返回:\n        采样结果的频率分布\n    \"\"\"\n    probs = temperature_softmax(logits, temperature)\n    \n    # 进行多次采样\n    samples = np.random.choice(len(vocab), size=num_samples, p=probs)\n    \n    # 统计频率\n    unique, counts = np.unique(samples, return_counts=True)\n    frequencies = np.zeros(len(vocab))\n    frequencies[unique] = counts / num_samples\n    \n    return frequencies, probs\n\n\n# 测试不同温度下的采样\ntest_temps = [0.2, 1.0, 2.0]\nnum_samples = 1000\n\nfig, axes = plt.subplots(len(test_temps), 1, figsize=(14, 12))\n\nfor idx, temp in enumerate(test_temps):\n    sample_freq, theory_probs = sample_words(simulated_logits, vocabulary, temp, num_samples)\n    \n    x = np.arange(len(vocabulary))\n    width = 0.35\n    \n    # 理论概率与实际采样频率对比\n    axes[idx].bar(x - width/2, theory_probs, width, label='理论概率', alpha=0.8, color='steelblue')\n    axes[idx].bar(x + width/2, sample_freq, width, label='采样频率', alpha=0.8, color='coral')\n    \n    axes[idx].set_title(f'温度 T={temp} (采样{num_samples}次)', fontsize=13, fontweight='bold')\n    axes[idx].set_xticks(x)\n    axes[idx].set_xticklabels(vocabulary, rotation=45, ha='right')\n    axes[idx].set_ylabel('概率/频率')\n    axes[idx].legend()\n    axes[idx].grid(axis='y', alpha=0.3)\n    \n    # 显示top-3采样词\n    top3_indices = np.argsort(sample_freq)[-3:][::-1]\n    top3_words = [vocabulary[i] for i in top3_indices]\n    top3_freqs = [sample_freq[i] for i in top3_indices]\n    \n    info_text = f\"Top-3采样词: {', '.join([f'{w}({f:.2%})' for w, f in zip(top3_words, top3_freqs)])}\"\n    axes[idx].text(0.02, 0.95, info_text, transform=axes[idx].transAxes,\n                   verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.7))\n\nplt.tight_layout()\nplt.savefig('sampling_comparison.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"\\\\n分析：\")\nprint(\"- T=0.2: 采样高度集中在概率最高的词（'the', 'a'），生成文本单调\")\nprint(\"- T=1.0: 采样分布与理论概率一致，平衡了确定性和多样性\")\nprint(\"- T=2.0: 采样更加分散，低概率词也有机会被选中，生成文本更具创造性\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "omx35vszwc",
   "source": "## 6. 实际应用：文本生成示例\n\n演示在实际文本生成场景中，不同温度参数如何影响采样结果",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "tk9dr262ifl",
   "source": "def compute_entropy(probs):\n    \"\"\"计算概率分布的香农熵\"\"\"\n    return -np.sum(probs * np.log(probs + 1e-10))\n\n\n# 测试温度与熵的关系\ntemperature_range = np.linspace(0.1, 5.0, 50)\nentropies = []\nmax_probs = []\n\nfor temp in temperature_range:\n    probs = temperature_softmax(logits, temp)\n    entropies.append(compute_entropy(probs))\n    max_probs.append(np.max(probs))\n\n# 绘制关系图\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\n# 熵随温度变化\nax1.plot(temperature_range, entropies, linewidth=2.5, color='darkred')\nax1.axvline(x=1.0, color='gray', linestyle='--', alpha=0.5, label='T=1 (标准)')\nax1.set_xlabel('温度参数 T', fontsize=12)\nax1.set_ylabel('熵 (nats)', fontsize=12)\nax1.set_title('熵与温度的关系', fontsize=14, fontweight='bold')\nax1.grid(alpha=0.3)\nax1.legend()\n\n# 最大概率随温度变化\nax2.plot(temperature_range, max_probs, linewidth=2.5, color='darkblue')\nax2.axvline(x=1.0, color='gray', linestyle='--', alpha=0.5, label='T=1 (标准)')\nax2.set_xlabel('温度参数 T', fontsize=12)\nax2.set_ylabel('最大概率', fontsize=12)\nax2.set_title('最大概率与温度的关系', fontsize=14, fontweight='bold')\nax2.grid(alpha=0.3)\nax2.legend()\n\nplt.tight_layout()\nplt.savefig('entropy_temperature_relationship.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"\\\\n关键发现：\")\nprint(f\"- 低温(T=0.1)时，熵={entropies[0]:.3f}，最大概率={max_probs[0]:.3f}\")\nprint(f\"- 标准(T=1.0)时，熵={entropies[np.argmin(np.abs(temperature_range-1.0))]:.3f}，\"\n      f\"最大概率={max_probs[np.argmin(np.abs(temperature_range-1.0))]:.3f}\")\nprint(f\"- 高温(T=5.0)时，熵={entropies[-1]:.3f}，最大概率={max_probs[-1]:.3f}\")\nprint(f\"- 均匀分布的理论最大熵: {np.log(vocab_size):.3f}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ulq5d01mht",
   "source": "## 5. 熵与温度的关系\n\n温度参数直接影响概率分布的熵。熵是衡量不确定性的指标，熵越高表示分布越均匀，不确定性越大。\n\n**香农熵的定义**:\n$$H(P) = -\\sum_i P(i) \\log P(i)$$",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "htomj8cogu",
   "source": "# 创建一个模拟的logits分布\nvocab_size = 20\nlogits = np.random.randn(vocab_size) * 2  # 模拟模型输出\nlogits = np.sort(logits)[::-1]  # 降序排列以便观察\n\n# 测试不同的温度参数\ntemperatures = [0.1, 0.5, 1.0, 2.0, 5.0]\n\n# 可视化\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\naxes = axes.flatten()\n\nfor idx, temp in enumerate(temperatures):\n    probs = temperature_softmax(logits, temp)\n    \n    axes[idx].bar(range(vocab_size), probs, alpha=0.7, color='steelblue')\n    axes[idx].set_title(f'Temperature T = {temp}', fontsize=14, fontweight='bold')\n    axes[idx].set_xlabel('词汇索引 (按logit降序排列)')\n    axes[idx].set_ylabel('概率')\n    axes[idx].grid(axis='y', alpha=0.3)\n    \n    # 添加统计信息\n    entropy = -np.sum(probs * np.log(probs + 1e-10))\n    max_prob = np.max(probs)\n    axes[idx].text(0.02, 0.95, f'熵: {entropy:.3f}\\\\n最大概率: {max_prob:.3f}',\n                   transform=axes[idx].transAxes, verticalalignment='top',\n                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n\n# 隐藏多余的子图\naxes[-1].axis('off')\n\nplt.tight_layout()\nplt.savefig('temperature_effect.png', dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(\"\\\\n观察：\")\nprint(\"- T=0.1: 分布极度尖锐，几乎所有概率集中在最高logit项\")\nprint(\"- T=0.5: 分布较尖锐，主要概率集中在前几项\")\nprint(\"- T=1.0: 标准分布，保持模型原始输出\")\nprint(\"- T=2.0: 分布变平滑，低概率项机会增加\")\nprint(\"- T=5.0: 分布接近均匀，几乎是随机采样\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1eim2y1y0x3",
   "source": "## 4. 可视化：温度参数的影响\n\n通过可视化展示不同温度参数如何改变概率分布的形状",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "mtcr2ks86ce",
   "source": "def softmax(logits):\n    \"\"\"\n    标准softmax函数\n    \n    参数:\n        logits: 未归一化的对数概率\n    返回:\n        概率分布\n    \"\"\"\n    exp_logits = np.exp(logits - np.max(logits))  # 减去最大值以数值稳定\n    return exp_logits / np.sum(exp_logits)\n\n\ndef temperature_softmax(logits, temperature=1.0):\n    \"\"\"\n    带温度参数的softmax函数\n    \n    参数:\n        logits: 未归一化的对数概率\n        temperature: 温度参数\n            - T < 1: 使分布更尖锐\n            - T = 1: 标准softmax\n            - T > 1: 使分布更平滑\n    返回:\n        经过温度缩放的概率分布\n    \"\"\"\n    scaled_logits = logits / temperature\n    return softmax(scaled_logits)\n\n\ndef reweight_distribution(original_probs, temperature=1.0):\n    \"\"\"\n    对已有的概率分布进行温度重加权（另一种实现方式）\n    \n    该方法通过对概率取对数转回logit空间，应用温度缩放后再转回概率空间\n    \n    参数:\n        original_probs: 原始概率分布（和为1）\n        temperature: 温度参数\n    返回:\n        重加权后的概率分布\n    \"\"\"\n    # 转回logit空间\n    logits = np.log(original_probs + 1e-10)  # 加小常数避免log(0)\n    \n    # 温度缩放\n    scaled_logits = logits / temperature\n    \n    # 转回概率空间\n    exp_logits = np.exp(scaled_logits)\n    return exp_logits / np.sum(exp_logits)\n\n\n# 测试两种实现的等价性\ntest_logits = np.array([2.0, 1.0, 0.1])\ntest_probs = softmax(test_logits)\ntest_temp = 0.5\n\nmethod1 = temperature_softmax(test_logits, test_temp)\nmethod2 = reweight_distribution(test_probs, test_temp)\n\nprint(\"原始logits:\", test_logits)\nprint(\"原始概率分布:\", test_probs)\nprint(f\"\\n温度T={test_temp}时:\")\nprint(\"方法1 (temperature_softmax):\", method1)\nprint(\"方法2 (reweight_distribution):\", method2)\nprint(\"两种方法的最大差异:\", np.max(np.abs(method1 - method2)))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "lkykwu9uvbf",
   "source": "## 3. 核心函数实现\n\n实现两种版本的temperature采样函数：\n1. 基于概率分布的重加权\n2. 基于logits的直接缩放",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}