{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# DeepDream 完整实现\n",
    "\n",
    "## 1. 算法原理\n",
    "\n",
    "DeepDream是Google在2015年提出的一种基于卷积神经网络的图像生成技术。其核心思想是：\n",
    "\n",
    "### 1.1 基本原理\n",
    "- **反向运行CNN**：不同于传统的图像分类（输入图像→输出类别），DeepDream固定网络权重，修改输入图像\n",
    "- **梯度上升**：通过梯度上升（而非梯度下降）来最大化某些层的激活值\n",
    "- **特征增强**：网络会在图像中\"看到\"并增强它认为存在的模式\n",
    "\n",
    "### 1.2 技术细节\n",
    "- **多层激活加权**：同时最大化多个中间层的激活，每层赋予不同权重\n",
    "- **损失函数**：L = Σ(w_i * ||A_i||²)，其中A_i是第i层的激活，w_i是权重系数\n",
    "- **多尺度处理（Octave）**：在不同尺度上依次处理图像，产生更丰富的细节\n",
    "- **梯度标准化**：确保梯度更新的稳定性，避免数值溢出\n",
    "\n",
    "### 1.3 关键技术\n",
    "- **避免边缘伪影**：在计算损失时忽略边缘像素（2:-2切片）\n",
    "- **激活缩放**：根据激活张量的总元素数量进行归一化\n",
    "- **渐进式放大**：从小尺度开始，逐步放大图像并精细化细节"
   ],
   "id": "intro_cell"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. 环境准备与依赖导入"
   ],
   "id": "imports_title"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.applications import inception_v3\nfrom tensorflow.keras.preprocessing import image\nimport matplotlib.pyplot as plt\nfrom scipy.ndimage import zoom\nimport warnings\nimport os\n\n# 设置环境变量以减少TensorFlow日志输出\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\nwarnings.filterwarnings('ignore')\n\n# 在Keras 3中，learning phase自动处理，无需手动设置\n# 模型在inference模式下会自动禁用Dropout等训练行为\n\nprint(f\"TensorFlow版本: {tf.__version__}\")\nprint(f\"Keras版本: {keras.__version__}\")",
   "id": "imports_cell"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. 图像预处理与后处理\n",
    "\n",
    "### 3.1 预处理说明\n",
    "- Inception-v3要求输入归一化到[-1, 1]范围\n",
    "- 需要从[0, 255]的RGB值转换为网络期望的格式\n",
    "\n",
    "### 3.2 后处理说明\n",
    "- 将网络输出的[-1, 1]值转回[0, 255]的图像格式\n",
    "- 裁剪到有效范围并转换为uint8类型"
   ],
   "id": "preprocess_title"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def preprocess_image(image_path, target_size=None):\n",
    "    \"\"\"\n",
    "    加载并预处理图像\n",
    "    \n",
    "    参数:\n",
    "        image_path: 图像文件路径\n",
    "        target_size: 目标尺寸(height, width)，None表示保持原始尺寸\n",
    "    \n",
    "    返回:\n",
    "        预处理后的图像数组，shape=(1, height, width, 3)\n",
    "    \"\"\"\n",
    "    img = image.load_img(image_path)\n",
    "    \n",
    "    if target_size:\n",
    "        img = img.resize(target_size)\n",
    "    \n",
    "    # 转换为numpy数组，shape=(height, width, 3)，dtype=float32\n",
    "    img_array = image.img_to_array(img)\n",
    "    \n",
    "    # 添加batch维度：(height, width, 3) -> (1, height, width, 3)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Inception-v3的预处理：将[0, 255]归一化到[-1, 1]\n",
    "    img_array = inception_v3.preprocess_input(img_array)\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "\n",
    "def deprocess_image(img_array):\n",
    "    \"\"\"\n",
    "    将预处理的图像转换回可显示的格式\n",
    "    \n",
    "    参数:\n",
    "        img_array: 预处理后的图像，shape=(1, height, width, 3)\n",
    "    \n",
    "    返回:\n",
    "        可显示的图像数组，shape=(height, width, 3)，dtype=uint8\n",
    "    \"\"\"\n",
    "    # 移除batch维度\n",
    "    if img_array.ndim == 4:\n",
    "        img_array = img_array[0]\n",
    "    \n",
    "    # 反向Inception-v3的预处理：从[-1, 1]转回[0, 255]\n",
    "    # Inception-v3使用的预处理是：x = (x / 127.5) - 1\n",
    "    # 所以反向操作是：x = (x + 1) * 127.5\n",
    "    img_array = (img_array + 1.0) * 127.5\n",
    "    \n",
    "    # 裁剪到[0, 255]范围\n",
    "    img_array = np.clip(img_array, 0, 255)\n",
    "    \n",
    "    # 转换为uint8类型\n",
    "    return img_array.astype('uint8')\n",
    "\n",
    "\n",
    "def resize_image(img, scale):\n",
    "    \"\"\"\n",
    "    缩放图像\n",
    "    \n",
    "    参数:\n",
    "        img: 输入图像，shape=(1, height, width, 3)\n",
    "        scale: 缩放因子\n",
    "    \n",
    "    返回:\n",
    "        缩放后的图像\n",
    "    \"\"\"\n",
    "    # zoom的参数是每个维度的缩放因子\n",
    "    # (1, scale, scale, 1)表示：batch维度不变，高宽按scale缩放，通道维度不变\n",
    "    return zoom(img, (1, scale, scale, 1), order=1)"
   ],
   "id": "preprocess_cell"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 4. 加载预训练的Inception-v3模型\n",
    "\n",
    "### 4.1 模型选择\n",
    "- **Inception-v3**：Google开发的高效图像识别网络\n",
    "- **不包含顶层**：去掉全连接分类层，只保留卷积特征提取部分\n",
    "- **预训练权重**：使用ImageNet数据集训练的权重\n",
    "\n",
    "### 4.2 层选择策略\n",
    "- **mixed2-5**：Inception-v3的中间层，包含从低级到高级的特征\n",
    "- **低层（mixed2）**：捕捉边缘、纹理等简单特征\n",
    "- **高层（mixed5）**：捕捉复杂的语义特征（如物体部件）"
   ],
   "id": "model_title"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# 加载不包含顶层全连接层的Inception-v3模型\n# include_top=False: 去掉最后的全连接分类层\n# weights='imagenet': 使用在ImageNet上预训练的权重\n\n# 注意：首次运行时会自动下载模型权重文件（约87MB）\n# 下载地址：https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/\n# 如果网络无法访问，可手动下载后放置到 ~/.keras/models/ 目录\n# 文件名：inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n\nbase_model = inception_v3.InceptionV3(weights='imagenet', include_top=False)\n\nprint(f\"模型加载成功，共有 {len(base_model.layers)} 层\")\nprint(\"\\n部分关键层名称：\")\nfor i, layer in enumerate(base_model.layers):\n    if 'mixed' in layer.name:\n        print(f\"  索引 {i}: {layer.name} - 输出形状: {layer.output_shape}\")",
   "id": "model_cell"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 5. 配置DeepDream参数\n",
    "\n",
    "### 5.1 层贡献权重\n",
    "- 字典键：层名称\n",
    "- 字典值：该层对最终损失的贡献系数\n",
    "- **权重调整**：较高的权重会让该层的特征更明显\n",
    "\n",
    "### 5.2 参数设置\n",
    "- **step_size**：每次梯度上升的步长，控制效果强度\n",
    "- **num_iterations**：梯度上升的迭代次数\n",
    "- **octave_scale**：每个octave的缩放比例（通常为1.4）\n",
    "- **num_octaves**：octave的数量，影响细节层次"
   ],
   "id": "config_title"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 层贡献配置：不同层对损失的贡献权重\n",
    "# mixed2: 低层特征（边缘、简单纹理）\n",
    "# mixed3-4: 中层特征（复杂纹理、简单形状）\n",
    "# mixed5: 高层特征（物体部件、复杂模式）\n",
    "layer_contributions = {\n",
    "    'mixed2': 0.2,\n",
    "    'mixed3': 3.0,\n",
    "    'mixed4': 2.0,\n",
    "    'mixed5': 1.5,\n",
    "}\n",
    "\n",
    "# DeepDream算法参数\n",
    "settings = {\n",
    "    'step_size': 0.01,         # 梯度上升步长（测试用较小值）\n",
    "    'num_iterations': 20,       # 迭代次数（测试用较小值）\n",
    "    'octave_scale': 1.4,        # octave缩放因子\n",
    "    'num_octaves': 3,           # octave数量（测试用较小值）\n",
    "}\n",
    "\n",
    "print(\"DeepDream配置：\")\n",
    "print(f\"  层贡献权重: {layer_contributions}\")\n",
    "print(f\"  步长: {settings['step_size']}\")\n",
    "print(f\"  迭代次数: {settings['num_iterations']}\")\n",
    "print(f\"  Octave数量: {settings['num_octaves']}\")\n",
    "print(f\"  Octave缩放: {settings['octave_scale']}\")"
   ],
   "id": "config_cell"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 6. 构建损失函数\n",
    "\n",
    "### 6.1 损失计算原理\n",
    "- **目标**：最大化选定层的激活值\n",
    "- **公式**：L = Σ w_i × (Σ A_i²) / N_i\n",
    "  - w_i: 层i的权重系数\n",
    "  - A_i: 层i的激活张量\n",
    "  - N_i: 激活张量的总元素数量（用于归一化）\n",
    "\n",
    "### 6.2 技术要点\n",
    "- **边缘裁剪**：`[:, 2:-2, 2:-2, :]` 避免边缘伪影\n",
    "- **平方求和**：使用L2范数衡量激活强度\n",
    "- **归一化**：除以激活张量大小，使不同层的贡献可比"
   ],
   "id": "loss_title"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 创建层名称到层对象的映射字典\n",
    "layer_dict = {layer.name: layer for layer in base_model.layers}\n",
    "\n",
    "# 初始化损失为0\n",
    "loss = tf.Variable(0.0)\n",
    "\n",
    "# 遍历每个需要最大化激活的层\n",
    "for layer_name in layer_contributions:\n",
    "    # 获取该层的贡献系数\n",
    "    coeff = layer_contributions[layer_name]\n",
    "    \n",
    "    # 获取该层的输出激活\n",
    "    activation = layer_dict[layer_name].output\n",
    "    \n",
    "    # 计算激活张量的总元素数量\n",
    "    # tf.shape获取动态形状，tf.cast转换为float32，tf.reduce_prod计算所有维度的乘积\n",
    "    scaling = tf.cast(tf.reduce_prod(tf.shape(activation)), dtype=tf.float32)\n",
    "    \n",
    "    # 累加该层对总损失的贡献\n",
    "    # activation[:, 2:-2, 2:-2, :]: 裁剪边缘2个像素，避免边界伪影\n",
    "    # tf.square: 计算每个激活值的平方\n",
    "    # tf.reduce_sum: 求和所有激活值\n",
    "    # / scaling: 归一化，使不同大小的层贡献可比\n",
    "    loss = loss + coeff * tf.reduce_sum(tf.square(activation[:, 2:-2, 2:-2, :])) / scaling\n",
    "\n",
    "print(\"损失函数构建完成\")\n",
    "print(f\"损失计算涉及 {len(layer_contributions)} 个层\")"
   ],
   "id": "loss_cell"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 7. 梯度计算与标准化\n",
    "\n",
    "### 7.1 梯度上升\n",
    "- **与训练的区别**：训练时梯度下降（最小化损失），这里梯度上升（最大化激活）\n",
    "- **计算对象**：计算损失相对于输入图像的梯度，而非模型参数\n",
    "\n",
    "### 7.2 梯度标准化\n",
    "- **目的**：防止梯度过大或过小导致的不稳定\n",
    "- **方法**：除以梯度的L2范数+一个小的epsilon\n",
    "- **效果**：确保每次更新的幅度一致，由step_size控制"
   ],
   "id": "gradient_title"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "@tf.function\n",
    "def compute_loss_and_gradients(input_image):\n",
    "    \"\"\"\n",
    "    计算损失和梯度（使用tf.function装饰器优化性能）\n",
    "    \n",
    "    参数:\n",
    "        input_image: 输入图像张量\n",
    "    \n",
    "    返回:\n",
    "        loss: 损失值\n",
    "        gradients: 标准化后的梯度\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 监视输入图像，使其可被求导\n",
    "        tape.watch(input_image)\n",
    "        \n",
    "        # 前向传播，计算损失\n",
    "        _ = base_model(input_image)\n",
    "        loss_value = loss\n",
    "    \n",
    "    # 计算损失相对于输入图像的梯度\n",
    "    gradients = tape.gradient(loss_value, input_image)\n",
    "    \n",
    "    # 梯度标准化：除以L2范数\n",
    "    # tf.reduce_mean(tf.square(gradients)): 计算梯度的均方值\n",
    "    # tf.sqrt: 取平方根得到L2范数\n",
    "    # 1e-8: 防止除零\n",
    "    gradients /= tf.maximum(tf.sqrt(tf.reduce_mean(tf.square(gradients))), 1e-8)\n",
    "    \n",
    "    return loss_value, gradients\n",
    "\n",
    "\n",
    "def gradient_ascent_step(image, step_size):\n",
    "    \"\"\"\n",
    "    执行一步梯度上升\n",
    "    \n",
    "    参数:\n",
    "        image: 当前图像\n",
    "        step_size: 步长\n",
    "    \n",
    "    返回:\n",
    "        loss_value: 当前损失值\n",
    "        updated_image: 更新后的图像\n",
    "    \"\"\"\n",
    "    loss_value, gradients = compute_loss_and_gradients(image)\n",
    "    \n",
    "    # 梯度上升：沿着梯度方向更新图像\n",
    "    # 注意：这里是加法（梯度上升），而非减法（梯度下降）\n",
    "    updated_image = image + step_size * gradients\n",
    "    \n",
    "    return loss_value, updated_image\n",
    "\n",
    "print(\"梯度计算函数已定义\")"
   ],
   "id": "gradient_cell"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 8. DeepDream核心算法实现\n",
    "\n",
    "### 8.1 单尺度DeepDream\n",
    "- 在固定尺寸的图像上执行多次梯度上升\n",
    "- 每次迭代都增强网络识别到的模式\n",
    "\n",
    "### 8.2 多尺度（Octave）处理\n",
    "- **原理**：模拟人类视觉的多尺度感知\n",
    "- **流程**：\n",
    "  1. 将图像缩小到最小尺度\n",
    "  2. 在当前尺度上执行DeepDream\n",
    "  3. 放大图像到下一个尺度\n",
    "  4. 将上一尺度的细节加回放大后的图像\n",
    "  5. 重复步骤2-4直到原始尺寸\n",
    "\n",
    "### 8.3 细节注入\n",
    "- **lost_detail**：在放大过程中损失的高频细节\n",
    "- **注入方式**：将损失的细节加回到放大后的图像中\n",
    "- **作用**：保持图像的精细结构，产生更丰富的效果"
   ],
   "id": "deepdream_title"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def deepdream_at_scale(image, num_iterations, step_size, verbose=False):\n",
    "    \"\"\"\n",
    "    在单一尺度上执行DeepDream\n",
    "    \n",
    "    参数:\n",
    "        image: 输入图像（numpy数组）\n",
    "        num_iterations: 迭代次数\n",
    "        step_size: 梯度上升步长\n",
    "        verbose: 是否打印进度\n",
    "    \n",
    "    返回:\n",
    "        处理后的图像\n",
    "    \"\"\"\n",
    "    # 转换为TensorFlow张量\n",
    "    image_tensor = tf.constant(image, dtype=tf.float32)\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        loss_value, image_tensor = gradient_ascent_step(image_tensor, step_size)\n",
    "        \n",
    "        if verbose and (i % 5 == 0 or i == num_iterations - 1):\n",
    "            print(f\"    迭代 {i+1}/{num_iterations}, 损失值: {loss_value:.4f}\")\n",
    "    \n",
    "    # 转换回numpy数组\n",
    "    return image_tensor.numpy()\n",
    "\n",
    "\n",
    "def deepdream(image_path, output_path=None, visualize=True):\n",
    "    \"\"\"\n",
    "    完整的多尺度DeepDream实现\n",
    "    \n",
    "    参数:\n",
    "        image_path: 输入图像路径\n",
    "        output_path: 输出图像路径（None表示不保存）\n",
    "        visualize: 是否可视化结果\n",
    "    \n",
    "    返回:\n",
    "        处理后的图像数组\n",
    "    \"\"\"\n",
    "    print(f\"\\n开始处理图像: {image_path}\")\n",
    "    \n",
    "    # 1. 加载和预处理原始图像\n",
    "    original_image = preprocess_image(image_path)\n",
    "    original_shape = original_image.shape[1:3]  # (height, width)\n",
    "    print(f\"原始图像尺寸: {original_shape}\")\n",
    "    \n",
    "    # 2. 定义octave的尺度序列\n",
    "    octave_scale = settings['octave_scale']\n",
    "    num_octaves = settings['num_octaves']\n",
    "    \n",
    "    # 计算每个octave的缩放因子（从小到大）\n",
    "    successive_scales = [octave_scale ** -i for i in range(num_octaves)]\n",
    "    print(f\"Octave缩放序列: {[f'{s:.3f}' for s in successive_scales]}\")\n",
    "    \n",
    "    # 3. 将图像缩小到最小尺度\n",
    "    smallest_scale = successive_scales[0]\n",
    "    shrunk_image = resize_image(original_image, smallest_scale)\n",
    "    print(f\"\\n最小尺度图像尺寸: {shrunk_image.shape[1:3]}\")\n",
    "    \n",
    "    # 4. 多尺度处理主循环\n",
    "    for octave_idx, scale in enumerate(successive_scales):\n",
    "        print(f\"\\n处理 Octave {octave_idx + 1}/{num_octaves} (缩放因子: {scale:.3f})\")\n",
    "        \n",
    "        # 4.1 计算当前octave的目标尺寸\n",
    "        target_size = tuple(int(dim * scale) for dim in original_shape)\n",
    "        print(f\"  目标尺寸: {target_size}\")\n",
    "        \n",
    "        # 4.2 放大图像到目标尺寸\n",
    "        upscaled_image = resize_image(shrunk_image, scale / smallest_scale * octave_scale ** octave_idx)\n",
    "        \n",
    "        # 4.3 计算放大过程中损失的细节\n",
    "        # 将图像先放大再缩小，与直接缩小的差异就是损失的细节\n",
    "        same_size_original = resize_image(original_image, scale)\n",
    "        lost_detail = same_size_original - upscaled_image\n",
    "        \n",
    "        # 4.4 在当前尺度执行DeepDream\n",
    "        shrunk_image = deepdream_at_scale(\n",
    "            upscaled_image,\n",
    "            num_iterations=settings['num_iterations'],\n",
    "            step_size=settings['step_size'],\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # 4.5 将损失的细节注入回图像\n",
    "        shrunk_image += lost_detail\n",
    "        print(f\"  完成，当前图像尺寸: {shrunk_image.shape[1:3]}\")\n",
    "    \n",
    "    # 5. 后处理：转换为可显示的图像格式\n",
    "    result = deprocess_image(shrunk_image)\n",
    "    print(f\"\\nDeepDream处理完成，最终尺寸: {result.shape}\")\n",
    "    \n",
    "    # 6. 保存结果\n",
    "    if output_path:\n",
    "        from PIL import Image\n",
    "        Image.fromarray(result).save(output_path)\n",
    "        print(f\"结果已保存至: {output_path}\")\n",
    "    \n",
    "    # 7. 可视化对比\n",
    "    if visualize:\n",
    "        original_display = deprocess_image(original_image)\n",
    "        \n",
    "        plt.figure(figsize=(14, 6))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(original_display)\n",
    "        plt.title('原始图像', fontsize=14)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(result)\n",
    "        plt.title('DeepDream处理后', fontsize=14)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"DeepDream主函数已定义\")"
   ],
   "id": "deepdream_cell"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 9. 测试与应用示例\n",
    "\n",
    "### 9.1 使用说明\n",
    "- 准备一张输入图像（建议尺寸300-800像素）\n",
    "- 修改下方代码中的图像路径\n",
    "- 运行单元格查看效果\n",
    "\n",
    "### 9.2 参数调整建议\n",
    "- **增强效果强度**：增大 `step_size` 或 `num_iterations`\n",
    "- **改变风格**：调整 `layer_contributions` 中的权重\n",
    "- **更多细节**：增加 `num_octaves`\n",
    "- **更大的结构**：增大 `octave_scale`\n",
    "\n",
    "### 9.3 性能优化\n",
    "- 测试时使用较小的 `num_iterations` 和 `num_octaves`\n",
    "- 正式运行时可增大这些参数以获得更好的效果\n",
    "- GPU加速可显著提升处理速度"
   ],
   "id": "example_title"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 示例：处理一张图像\n",
    "# 请将下面的路径替换为您的图像路径\n",
    "\n",
    "# 方式1: 使用URL（需要先下载）\n",
    "# import urllib.request\n",
    "# url = 'https://example.com/your-image.jpg'\n",
    "# urllib.request.urlretrieve(url, 'test_image.jpg')\n",
    "# result = deepdream('test_image.jpg', output_path='deepdream_result.jpg')\n",
    "\n",
    "# 方式2: 使用本地图像\n",
    "# result = deepdream('/path/to/your/image.jpg', output_path='deepdream_result.jpg')\n",
    "\n",
    "# 方式3: 生成测试图像\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# 创建一个简单的测试图像（渐变色块）\n",
    "test_img = np.zeros((400, 400, 3), dtype=np.uint8)\n",
    "for i in range(400):\n",
    "    for j in range(400):\n",
    "        test_img[i, j] = [i * 255 // 400, j * 255 // 400, (i + j) * 255 // 800]\n",
    "\n",
    "Image.fromarray(test_img).save('test_input.jpg')\n",
    "print(\"测试图像已生成: test_input.jpg\")\n",
    "\n",
    "# 运行DeepDream\n",
    "result = deepdream('test_input.jpg', output_path='deepdream_output.jpg', visualize=True)"
   ],
   "id": "example_cell"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 10. 高级应用：参数实验\n",
    "\n",
    "### 10.1 生产环境推荐参数\n",
    "```python\n",
    "settings = {\n",
    "    'step_size': 0.01,\n",
    "    'num_iterations': 50,      # 增加到50\n",
    "    'octave_scale': 1.4,\n",
    "    'num_octaves': 5,          # 增加到5\n",
    "}\n",
    "```\n",
    "\n",
    "### 10.2 不同风格配置\n",
    "\n",
    "**风格1：精细纹理**\n",
    "```python\n",
    "layer_contributions = {\n",
    "    'mixed2': 5.0,   # 强调低层纹理\n",
    "    'mixed3': 1.0,\n",
    "    'mixed4': 0.5,\n",
    "    'mixed5': 0.2,\n",
    "}\n",
    "```\n",
    "\n",
    "**风格2：抽象形状**\n",
    "```python\n",
    "layer_contributions = {\n",
    "    'mixed2': 0.1,\n",
    "    'mixed3': 0.5,\n",
    "    'mixed4': 2.0,\n",
    "    'mixed5': 5.0,   # 强调高层语义\n",
    "}\n",
    "```"
   ],
   "id": "advanced_title"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 恢复生产环境参数\n",
    "def reset_to_production_settings():\n",
    "    \"\"\"\n",
    "    恢复为生产环境推荐的参数设置\n",
    "    \"\"\"\n",
    "    global settings\n",
    "    settings = {\n",
    "        'step_size': 0.01,\n",
    "        'num_iterations': 50,\n",
    "        'octave_scale': 1.4,\n",
    "        'num_octaves': 5,\n",
    "    }\n",
    "    print(\"参数已恢复为生产环境设置：\")\n",
    "    print(f\"  步长: {settings['step_size']}\")\n",
    "    print(f\"  迭代次数: {settings['num_iterations']}\")\n",
    "    print(f\"  Octave数量: {settings['num_octaves']}\")\n",
    "\n",
    "# 取消注释下行以恢复生产参数\n",
    "# reset_to_production_settings()"
   ],
   "id": "production_cell"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 11. 技术总结\n",
    "\n",
    "### 11.1 核心技术点\n",
    "1. **特征可视化**：通过梯度上升可视化CNN学到的特征\n",
    "2. **多尺度处理**：Octave金字塔产生层次化的细节\n",
    "3. **梯度标准化**：确保优化过程的稳定性\n",
    "4. **细节注入**：保留图像的高频信息\n",
    "\n",
    "### 11.2 实现要点\n",
    "- 使用预训练网络的中间层激活\n",
    "- 损失函数是多层激活的加权和\n",
    "- 边缘裁剪避免伪影\n",
    "- 按激活大小归一化损失\n",
    "\n",
    "### 11.3 应用场景\n",
    "- 艺术创作和图像风格化\n",
    "- 神经网络可解释性研究\n",
    "- 特征可视化和分析\n",
    "- 创意设计和广告制作\n",
    "\n",
    "### 11.4 扩展方向\n",
    "- 尝试不同的预训练模型（VGG、ResNet等）\n",
    "- 实现引导式DeepDream（guided dreaming）\n",
    "- 结合风格迁移技术\n",
    "- 视频序列的DeepDream处理"
   ],
   "id": "summary_title"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}