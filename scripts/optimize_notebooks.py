#!/usr/bin/env python3
"""
Notebookæ‰¹é‡ä¼˜åŒ–è„šæœ¬
ç”¨äºè‡ªåŠ¨ä¿®å¤å¸¸è§é—®é¢˜ï¼š
1. æ›¿æ¢å¼ƒç”¨çš„API (fit_generator -> fit)
2. æ·»åŠ éšæœºç§å­è®¾ç½®
3. ä¿®å¤importè¯­å¥
4. è§„èŒƒåŒ–ä»£ç é£æ ¼
5. æ·»åŠ æ ‡å‡†é…ç½®å¤´
"""

import json
import os
import re
from pathlib import Path
from typing import List, Tuple, Optional


# ============================================================
# æ ‡å‡†ä»£ç æ¨¡æ¿
# ============================================================

STANDARD_IMPORTS_ML = '''# ============================================================
# å¯¼å…¥å¿…è¦çš„åº“
# ============================================================

# æ•°å€¼è®¡ç®—
import numpy as np

# æ•°æ®å¤„ç†
import pandas as pd

# å¯è§†åŒ–
import matplotlib.pyplot as plt

# ============================================================
# é…ç½®å‚æ•°
# ============================================================

# è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿ç»“æœå¯é‡å¤
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)

# å¯è§†åŒ–é…ç½®
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.figsize'] = (10, 6)
plt.rcParams['figure.dpi'] = 100

# å¿½ç•¥è­¦å‘Š
import warnings
warnings.filterwarnings('ignore')

print("âœ“ ç¯å¢ƒé…ç½®å®Œæˆ")'''

STANDARD_IMPORTS_DL = '''# ============================================================
# å¯¼å…¥å¿…è¦çš„åº“
# ============================================================

# æ•°å€¼è®¡ç®—
import numpy as np

# å¯è§†åŒ–
import matplotlib.pyplot as plt

# æ·±åº¦å­¦ä¹ æ¡†æ¶
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# ============================================================
# é…ç½®å‚æ•°
# ============================================================

# è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿ç»“æœå¯é‡å¤
RANDOM_SEED = 42
np.random.seed(RANDOM_SEED)
tf.random.set_seed(RANDOM_SEED)

# GPUé…ç½®
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print(f"âœ“ GPUå¯ç”¨: {len(gpus)}ä¸ª")
    except RuntimeError as e:
        print(f"GPUé…ç½®é”™è¯¯: {e}")
else:
    print("âš  æœªæ£€æµ‹åˆ°GPUï¼Œä½¿ç”¨CPU")

# å¯è§†åŒ–é…ç½®
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.figsize'] = (10, 6)

# å¿½ç•¥è­¦å‘Š
import warnings
warnings.filterwarnings('ignore')

print("âœ“ ç¯å¢ƒé…ç½®å®Œæˆ")
print(f"âœ“ TensorFlowç‰ˆæœ¬: {tf.__version__}")'''


def load_notebook(path: Path) -> dict:
    """åŠ è½½notebookæ–‡ä»¶"""
    with open(path, 'r', encoding='utf-8') as f:
        return json.load(f)


def save_notebook(path: Path, notebook: dict) -> None:
    """ä¿å­˜notebookæ–‡ä»¶"""
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(notebook, f, ensure_ascii=False, indent=1)


def fix_deprecated_apis(source: str) -> Tuple[str, List[str]]:
    """
    ä¿®å¤å¼ƒç”¨çš„APIè°ƒç”¨
    è¿”å›: (ä¿®å¤åçš„ä»£ç , ä¿®å¤åˆ—è¡¨)
    """
    fixes = []

    # æ›¿æ¢ fit_generator -> fit
    if 'fit_generator' in source:
        source = source.replace('fit_generator', 'fit')
        fixes.append('fit_generator -> fit')

    # æ›¿æ¢ predict_generator -> predict
    if 'predict_generator' in source:
        source = source.replace('predict_generator', 'predict')
        fixes.append('predict_generator -> predict')

    # æ›¿æ¢ evaluate_generator -> evaluate
    if 'evaluate_generator' in source:
        source = source.replace('evaluate_generator', 'evaluate')
        fixes.append('evaluate_generator -> evaluate')

    # æ›¿æ¢ keras.preprocessing.image -> keras.utils
    if 'keras.preprocessing.image' in source:
        source = source.replace('keras.preprocessing.image', 'keras.utils')
        fixes.append('keras.preprocessing.image -> keras.utils')

    # ä¿®å¤ tf.keras.optimizers.schedules çš„æ—§API
    if 'schedules.ExponentialDecay' in source and 'learning_rate_schedule' not in source:
        # è¿™ä¸ªéœ€è¦æ›´å¤æ‚çš„å¤„ç†ï¼Œæš‚æ—¶åªæ ‡è®°
        pass

    return source, fixes


def fix_hardcoded_paths(source: str) -> Tuple[str, List[str]]:
    """
    æ£€æµ‹ç¡¬ç¼–ç è·¯å¾„
    è¿”å›: (åŸä»£ç , è­¦å‘Šåˆ—è¡¨)
    """
    warnings = []

    # æ£€æµ‹Windowsè·¯å¾„
    windows_pattern = r'r?["\']C:\\[^"\']+["\']'
    if re.search(windows_pattern, source):
        warnings.append('æ£€æµ‹åˆ°Windowsç¡¬ç¼–ç è·¯å¾„')

    # æ£€æµ‹Linuxç»å¯¹è·¯å¾„
    linux_pattern = r'r?["\']/home/[^"\']+["\']'
    if re.search(linux_pattern, source):
        warnings.append('æ£€æµ‹åˆ°Linuxç¡¬ç¼–ç è·¯å¾„')

    # æ£€æµ‹macOSç”¨æˆ·è·¯å¾„
    macos_pattern = r'r?["\']/Users/[^"\']+["\']'
    if re.search(macos_pattern, source):
        warnings.append('æ£€æµ‹åˆ°macOSç¡¬ç¼–ç è·¯å¾„')

    return source, warnings


def fix_common_issues(source: str) -> Tuple[str, List[str]]:
    """
    ä¿®å¤å¸¸è§ä»£ç é—®é¢˜
    è¿”å›: (ä¿®å¤åçš„ä»£ç , ä¿®å¤åˆ—è¡¨)
    """
    fixes = []

    # ä¿®å¤ np.int -> int (numpy 1.24+å·²å¼ƒç”¨)
    if 'np.int,' in source or 'np.int)' in source or 'np.int]' in source:
        source = re.sub(r'\bnp\.int\b', 'int', source)
        fixes.append('np.int -> int')

    # ä¿®å¤ np.float -> float
    if 'np.float,' in source or 'np.float)' in source or 'np.float]' in source:
        source = re.sub(r'\bnp\.float\b', 'float', source)
        fixes.append('np.float -> float')

    # ä¿®å¤ np.bool -> bool
    if 'np.bool,' in source or 'np.bool)' in source or 'np.bool]' in source:
        source = re.sub(r'\bnp\.bool\b', 'bool', source)
        fixes.append('np.bool -> bool')

    return source, fixes


def check_has_random_seed(notebook: dict) -> bool:
    """æ£€æŸ¥notebookæ˜¯å¦å·²è®¾ç½®éšæœºç§å­"""
    for cell in notebook.get('cells', []):
        if cell.get('cell_type') == 'code':
            source = ''.join(cell.get('source', []))
            if 'random.seed' in source or 'np.random.seed' in source or 'tf.random.set_seed' in source:
                return True
    return False


def check_is_deep_learning(notebook: dict) -> bool:
    """æ£€æŸ¥æ˜¯å¦æ˜¯æ·±åº¦å­¦ä¹ notebook"""
    for cell in notebook.get('cells', []):
        if cell.get('cell_type') == 'code':
            source = ''.join(cell.get('source', []))
            if 'tensorflow' in source.lower() or 'keras' in source.lower() or 'torch' in source.lower():
                return True
    return False


def add_random_seed_to_imports(source: str, is_dl: bool = False) -> str:
    """åœ¨importè¯­å¥åæ·»åŠ éšæœºç§å­è®¾ç½®"""
    lines = source.split('\n')
    new_lines = []
    seed_added = False

    for i, line in enumerate(lines):
        new_lines.append(line)
        # åœ¨numpy importåæ·»åŠ seed
        if not seed_added and ('import numpy' in line or 'import np' in line):
            if is_dl:
                # æ£€æŸ¥åé¢æ˜¯å¦å·²æœ‰seed
                remaining = '\n'.join(lines[i+1:])
                if 'random.seed' not in remaining[:200]:
                    new_lines.append('')
                    new_lines.append('# è®¾ç½®éšæœºç§å­')
                    new_lines.append('RANDOM_SEED = 42')
                    new_lines.append('np.random.seed(RANDOM_SEED)')
                    seed_added = True
            else:
                remaining = '\n'.join(lines[i+1:])
                if 'random.seed' not in remaining[:200]:
                    new_lines.append('')
                    new_lines.append('# è®¾ç½®éšæœºç§å­')
                    new_lines.append('np.random.seed(42)')
                    seed_added = True

    return '\n'.join(new_lines)


def process_notebook(path: Path, dry_run: bool = False, add_seed: bool = False) -> dict:
    """
    å¤„ç†å•ä¸ªnotebook
    è¿”å›å¤„ç†æŠ¥å‘Š
    """
    report = {
        'path': str(path),
        'fixes': [],
        'warnings': [],
        'error': None
    }

    try:
        notebook = load_notebook(path)

        # æ£€æŸ¥ç‰¹å¾
        has_seed = check_has_random_seed(notebook)
        is_dl = check_is_deep_learning(notebook)

        if not has_seed:
            report['warnings'].append('ç¼ºå°‘éšæœºç§å­è®¾ç½®')

        modified = False
        for cell in notebook.get('cells', []):
            if cell.get('cell_type') == 'code':
                source = ''.join(cell.get('source', []))
                original_source = source

                # ä¿®å¤å¼ƒç”¨API
                source, fixes = fix_deprecated_apis(source)
                report['fixes'].extend(fixes)

                # ä¿®å¤å¸¸è§é—®é¢˜
                source, common_fixes = fix_common_issues(source)
                report['fixes'].extend(common_fixes)

                # æ£€æŸ¥ç¡¬ç¼–ç è·¯å¾„
                _, warnings = fix_hardcoded_paths(source)
                report['warnings'].extend(warnings)

                # å¦‚æœéœ€è¦æ·»åŠ éšæœºç§å­
                if add_seed and not has_seed:
                    source = add_random_seed_to_imports(source, is_dl)
                    if source != original_source:
                        report['fixes'].append('æ·»åŠ éšæœºç§å­')
                        has_seed = True

                if source != original_source:
                    if isinstance(cell['source'], list):
                        cell['source'] = source.split('\n')
                        cell['source'] = [line + '\n' for line in cell['source'][:-1]] + [cell['source'][-1]]
                    else:
                        cell['source'] = source
                    modified = True

        if modified and not dry_run:
            save_notebook(path, notebook)
            report['status'] = 'modified'
        elif modified:
            report['status'] = 'would_modify'
        else:
            report['status'] = 'no_change'

    except Exception as e:
        report['error'] = str(e)
        report['status'] = 'error'

    return report


def find_notebooks(root_dir: Path) -> List[Path]:
    """æŸ¥æ‰¾æ‰€æœ‰notebookæ–‡ä»¶"""
    notebooks = list(root_dir.rglob('*.ipynb'))
    # è¿‡æ»¤æ‰checkpointæ–‡ä»¶
    return [nb for nb in notebooks if '.ipynb_checkpoints' not in str(nb)]


def generate_quality_report(reports: List[dict]) -> str:
    """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
    total = len(reports)
    with_issues = sum(1 for r in reports if r['fixes'] or r['warnings'])
    modified = sum(1 for r in reports if r['status'] in ['modified', 'would_modify'])
    errors = sum(1 for r in reports if r['error'])

    missing_seed = sum(1 for r in reports if 'ç¼ºå°‘éšæœºç§å­è®¾ç½®' in r.get('warnings', []))
    hardcoded_paths = sum(1 for r in reports if any('ç¡¬ç¼–ç è·¯å¾„' in w for w in r.get('warnings', [])))

    report = f"""
# Notebookè´¨é‡æŠ¥å‘Š

## æ¦‚è§ˆ
- æ€»æ–‡ä»¶æ•°: {total}
- æœ‰é—®é¢˜çš„æ–‡ä»¶: {with_issues}
- å·²ä¿®æ”¹æ–‡ä»¶: {modified}
- å¤„ç†é”™è¯¯: {errors}

## é—®é¢˜åˆ†å¸ƒ
- ç¼ºå°‘éšæœºç§å­: {missing_seed}
- ç¡¬ç¼–ç è·¯å¾„: {hardcoded_paths}

## è¯¦ç»†é—®é¢˜åˆ—è¡¨
"""

    for r in reports:
        if r['fixes'] or r['warnings']:
            report += f"\n### {r['path']}\n"
            if r['fixes']:
                report += f"- ä¿®å¤: {', '.join(set(r['fixes']))}\n"
            if r['warnings']:
                report += f"- è­¦å‘Š: {', '.join(set(r['warnings']))}\n"

    return report


def main():
    import argparse

    parser = argparse.ArgumentParser(description='æ‰¹é‡ä¼˜åŒ–Jupyter Notebooks')
    parser.add_argument('--dry-run', action='store_true', help='ä»…æ£€æŸ¥ï¼Œä¸å®é™…ä¿®æ”¹')
    parser.add_argument('--path', type=str, default='.', help='é¡¹ç›®æ ¹ç›®å½•')
    parser.add_argument('--add-seed', action='store_true', help='è‡ªåŠ¨æ·»åŠ éšæœºç§å­')
    parser.add_argument('--report', type=str, help='è¾“å‡ºè´¨é‡æŠ¥å‘Šåˆ°æ–‡ä»¶')
    args = parser.parse_args()

    root = Path(args.path)
    notebooks = find_notebooks(root)

    print(f"æ‰¾åˆ° {len(notebooks)} ä¸ªnotebookæ–‡ä»¶")
    print("=" * 60)

    reports = []
    total_fixes = 0
    total_warnings = 0
    modified_count = 0

    for nb_path in notebooks:
        report = process_notebook(nb_path, dry_run=args.dry_run, add_seed=args.add_seed)
        reports.append(report)

        if report['fixes'] or report['warnings'] or report['error']:
            print(f"\nğŸ““ {report['path']}")

            if report['fixes']:
                print(f"  âœ… ä¿®å¤: {', '.join(set(report['fixes']))}")
                total_fixes += len(report['fixes'])

            if report['warnings']:
                print(f"  âš ï¸  è­¦å‘Š: {', '.join(set(report['warnings']))}")
                total_warnings += len(report['warnings'])

            if report['error']:
                print(f"  âŒ é”™è¯¯: {report['error']}")

            if report['status'] in ['modified', 'would_modify']:
                modified_count += 1

    print("\n" + "=" * 60)
    print(f"ğŸ“Š æ€»ç»“:")
    print(f"  - å¤„ç†æ–‡ä»¶: {len(notebooks)}")
    print(f"  - ä¿®å¤é—®é¢˜: {total_fixes}")
    print(f"  - è­¦å‘Šæ•°é‡: {total_warnings}")
    print(f"  - ä¿®æ”¹æ–‡ä»¶: {modified_count}")

    if args.dry_run:
        print("\nâš ï¸  è¿™æ˜¯dry-runæ¨¡å¼ï¼Œæ²¡æœ‰å®é™…ä¿®æ”¹æ–‡ä»¶")
        print("   ç§»é™¤ --dry-run å‚æ•°ä»¥åº”ç”¨ä¿®æ”¹")

    if args.report:
        quality_report = generate_quality_report(reports)
        with open(args.report, 'w', encoding='utf-8') as f:
            f.write(quality_report)
        print(f"\nğŸ“ è´¨é‡æŠ¥å‘Šå·²ä¿å­˜åˆ°: {args.report}")


if __name__ == '__main__':
    main()
