{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# PCA 逆变换与数据重构\n",
    "\n",
    "## 概述\n",
    "\n",
    "PCA 逆变换（Inverse Transform）是将降维后的数据映射回原始特征空间的过程。虽然降维是有损压缩，但通过逆变换可以近似重构原始数据。\n",
    "\n",
    "## 数学原理\n",
    "\n",
    "设原始数据为 $X \\in \\mathbb{R}^{m \\times n}$，PCA 投影矩阵为 $W_d \\in \\mathbb{R}^{n \\times d}$：\n",
    "\n",
    "- **正向变换（降维）**：$X_{reduced} = X \\cdot W_d$\n",
    "- **逆变换（重构）**：$X_{reconstructed} = X_{reduced} \\cdot W_d^\\top$\n",
    "\n",
    "## 重构误差\n",
    "\n",
    "重构误差衡量了降维过程中的信息损失：\n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{m} \\sum_{i=1}^{m} \\|x_i - \\hat{x}_i\\|^2$$\n",
    "\n",
    "## 本节内容\n",
    "\n",
    "1. MNIST 数据集上的 PCA 压缩\n",
    "2. 不同成分数下的重构效果\n",
    "3. 重构图像可视化\n",
    "4. 压缩率与质量的权衡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports-section",
   "metadata": {},
   "source": [
    "## 1. 环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 设置随机种子\n",
    "np.random.seed(42)\n",
    "\n",
    "# 设置中文显示\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-section",
   "metadata": {},
   "source": [
    "## 2. 数据加载\n",
    "\n",
    "使用 MNIST 手写数字数据集：\n",
    "- 70,000 张 28×28 灰度图像\n",
    "- 展平为 784 维向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 MNIST 数据集（使用子集加速演示）\n",
    "print(\"正在加载 MNIST 数据集...\")\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\n",
    "X, y = mnist.data, mnist.target\n",
    "\n",
    "# 使用子集进行快速演示\n",
    "n_samples = 10000\n",
    "indices = np.random.choice(len(X), n_samples, replace=False)\n",
    "X_subset = X[indices].astype(np.float32)\n",
    "y_subset = y[indices]\n",
    "\n",
    "print(f\"原始数据形状: {X.shape}\")\n",
    "print(f\"子集数据形状: {X_subset.shape}\")\n",
    "print(f\"每张图像维度: {X_subset.shape[1]} (28×28 像素)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normalize",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 归一化到 [0, 1]\n",
    "X_normalized = X_subset / 255.0\n",
    "\n",
    "print(f\"像素值范围: [{X_normalized.min():.2f}, {X_normalized.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pca-components-section",
   "metadata": {},
   "source": [
    "## 3. 不同成分数的 PCA 降维与重构\n",
    "\n",
    "比较使用不同主成分数量时的重构效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pca-experiments",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试不同的主成分数量\n",
    "n_components_list = [10, 30, 50, 100, 154, 300]\n",
    "\n",
    "results = []\n",
    "\n",
    "for n_comp in n_components_list:\n",
    "    # 创建并训练 PCA\n",
    "    pca = PCA(n_components=n_comp)\n",
    "    X_reduced = pca.fit_transform(X_normalized)\n",
    "    \n",
    "    # 逆变换重构数据\n",
    "    X_reconstructed = pca.inverse_transform(X_reduced)\n",
    "    \n",
    "    # 计算重构误差\n",
    "    mse = mean_squared_error(X_normalized, X_reconstructed)\n",
    "    explained_var = pca.explained_variance_ratio_.sum()\n",
    "    compression_ratio = 784 / n_comp\n",
    "    \n",
    "    results.append({\n",
    "        'n_components': n_comp,\n",
    "        'mse': mse,\n",
    "        'explained_variance': explained_var,\n",
    "        'compression_ratio': compression_ratio,\n",
    "        'pca': pca,\n",
    "        'X_reconstructed': X_reconstructed\n",
    "    })\n",
    "    \n",
    "    print(f\"成分数: {n_comp:3d} | 解释方差: {explained_var:.4f} | \"\n",
    "          f\"MSE: {mse:.6f} | 压缩比: {compression_ratio:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualization-section",
   "metadata": {},
   "source": [
    "## 4. 重构效果可视化\n",
    "\n",
    "展示同一张图像在不同压缩程度下的重构效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-reconstruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择几张图像进行可视化\n",
    "n_display = 5\n",
    "display_indices = np.random.choice(n_samples, n_display, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(n_display, len(n_components_list) + 1, \n",
    "                         figsize=(16, 2.5 * n_display))\n",
    "\n",
    "for row, idx in enumerate(display_indices):\n",
    "    # 原始图像\n",
    "    axes[row, 0].imshow(X_normalized[idx].reshape(28, 28), cmap='gray')\n",
    "    axes[row, 0].set_title('Original' if row == 0 else '')\n",
    "    axes[row, 0].axis('off')\n",
    "    \n",
    "    # 不同成分数的重构\n",
    "    for col, result in enumerate(results):\n",
    "        reconstructed = result['X_reconstructed'][idx].reshape(28, 28)\n",
    "        axes[row, col + 1].imshow(reconstructed, cmap='gray')\n",
    "        if row == 0:\n",
    "            axes[row, col + 1].set_title(f\"n={result['n_components']}\\n\"\n",
    "                                         f\"({result['explained_variance']*100:.1f}%)\")\n",
    "        axes[row, col + 1].axis('off')\n",
    "\n",
    "plt.suptitle('PCA Reconstruction with Different Number of Components', \n",
    "             fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis-section",
   "metadata": {},
   "source": [
    "## 5. 压缩效率分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "n_comps = [r['n_components'] for r in results]\n",
    "mses = [r['mse'] for r in results]\n",
    "explained_vars = [r['explained_variance'] for r in results]\n",
    "compression_ratios = [r['compression_ratio'] for r in results]\n",
    "\n",
    "# 重构误差 vs 成分数\n",
    "axes[0].plot(n_comps, mses, 'o-', color='steelblue', linewidth=2, markersize=8)\n",
    "axes[0].set_xlabel('Number of Components')\n",
    "axes[0].set_ylabel('Mean Squared Error')\n",
    "axes[0].set_title('Reconstruction Error vs Components')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 解释方差 vs 成分数\n",
    "axes[1].plot(n_comps, explained_vars, 'o-', color='green', linewidth=2, markersize=8)\n",
    "axes[1].axhline(y=0.95, color='red', linestyle='--', label='95% threshold')\n",
    "axes[1].set_xlabel('Number of Components')\n",
    "axes[1].set_ylabel('Explained Variance Ratio')\n",
    "axes[1].set_title('Explained Variance vs Components')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# MSE vs 压缩比\n",
    "axes[2].plot(compression_ratios, mses, 'o-', color='orange', linewidth=2, markersize=8)\n",
    "axes[2].set_xlabel('Compression Ratio')\n",
    "axes[2].set_ylabel('Mean Squared Error')\n",
    "axes[2].set_title('Reconstruction Error vs Compression')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-section",
   "metadata": {},
   "source": [
    "## 6. 详细案例：154 成分的重构\n",
    "\n",
    "154 个成分是常用的 MNIST 压缩设置，可保留约 95% 的方差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-case",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 154 成分进行详细分析\n",
    "pca_154 = PCA(n_components=154)\n",
    "X_reduced_154 = pca_154.fit_transform(X_normalized)\n",
    "X_reconstructed_154 = pca_154.inverse_transform(X_reduced_154)\n",
    "\n",
    "print(f\"原始数据大小: {X_normalized.nbytes / 1024 / 1024:.2f} MB\")\n",
    "print(f\"降维后数据大小: {X_reduced_154.nbytes / 1024 / 1024:.2f} MB\")\n",
    "print(f\"压缩比: {X_normalized.nbytes / X_reduced_154.nbytes:.2f}x\")\n",
    "print(f\"保留方差: {pca_154.explained_variance_ratio_.sum() * 100:.2f}%\")\n",
    "print(f\"重构 MSE: {mean_squared_error(X_normalized, X_reconstructed_154):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "error-distribution",
   "metadata": {},
   "outputs": [],
   "source": "# 每张图像的重构误差分布\nper_image_mse = np.mean((X_normalized - X_reconstructed_154) ** 2, axis=1)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# 误差分布直方图\naxes[0].hist(per_image_mse, bins=50, color='steelblue', edgecolor='white', alpha=0.7)\naxes[0].axvline(per_image_mse.mean(), color='red', linestyle='--', \n                label=f'Mean: {per_image_mse.mean():.4f}')\naxes[0].set_xlabel('Mean Squared Error')\naxes[0].set_ylabel('Frequency')\naxes[0].set_title('Distribution of Per-Image Reconstruction Error')\naxes[0].legend()\n\n# 最好和最差重构示例\nbest_idx = np.argmin(per_image_mse)\nworst_idx = np.argmax(per_image_mse)\n\n# 创建对比子图\naxes[1].set_visible(False)\ngs = fig.add_gridspec(1, 4, left=0.55, right=0.98, wspace=0.1)\nax_best_orig = fig.add_subplot(gs[0, 0])\nax_best_recon = fig.add_subplot(gs[0, 1])\nax_worst_orig = fig.add_subplot(gs[0, 2])\nax_worst_recon = fig.add_subplot(gs[0, 3])\n\nax_best_orig.imshow(X_normalized[best_idx].reshape(28, 28), cmap='gray')\nax_best_orig.set_title('Best\\nOriginal')\nax_best_orig.axis('off')\n\nax_best_recon.imshow(X_reconstructed_154[best_idx].reshape(28, 28), cmap='gray')\nax_best_recon.set_title(f'MSE:\\n{per_image_mse[best_idx]:.4f}')\nax_best_recon.axis('off')\n\nax_worst_orig.imshow(X_normalized[worst_idx].reshape(28, 28), cmap='gray')\nax_worst_orig.set_title('Worst\\nOriginal')\nax_worst_orig.axis('off')\n\nax_worst_recon.imshow(X_reconstructed_154[worst_idx].reshape(28, 28), cmap='gray')\nax_worst_recon.set_title(f'MSE:\\n{per_image_mse[worst_idx]:.4f}')\nax_worst_recon.axis('off')\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "components-visualization-section",
   "metadata": {},
   "source": [
    "## 7. 主成分可视化\n",
    "\n",
    "将前几个主成分可视化为图像，理解它们捕捉的特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-components",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化前 20 个主成分\n",
    "n_show = 20\n",
    "fig, axes = plt.subplots(4, 5, figsize=(12, 10))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < n_show:\n",
    "        component = pca_154.components_[i].reshape(28, 28)\n",
    "        ax.imshow(component, cmap='RdBu_r')\n",
    "        ax.set_title(f'PC{i+1}\\n({pca_154.explained_variance_ratio_[i]*100:.1f}%)')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Top 20 Principal Components (Eigenfaces)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-section",
   "metadata": {},
   "source": [
    "## 8. 总结\n",
    "\n",
    "### 关键发现\n",
    "\n",
    "1. **压缩效率**：154 个成分（784维的约 20%）可保留 ~95% 的信息\n",
    "\n",
    "2. **重构质量**：\n",
    "   - 成分数越多，重构越精确\n",
    "   - 边际效益递减：增加更多成分带来的改善越来越小\n",
    "\n",
    "3. **实际应用考量**：\n",
    "   - 压缩存储和传输\n",
    "   - 去噪（低阶重构可去除高频噪声）\n",
    "   - 异常检测（高重构误差可能表示异常）\n",
    "\n",
    "### 逆变换的局限性\n",
    "\n",
    "- 重构是近似的，无法完全恢复原始数据\n",
    "- 丢失的信息对应被舍弃的主成分方向\n",
    "- 对于高度非线性的数据结构，线性 PCA 的重构效果有限"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}