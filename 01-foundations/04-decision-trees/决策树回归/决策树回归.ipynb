{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# 决策树回归 (Decision Tree Regression)\n",
    "\n",
    "本 notebook 系统性地介绍决策树在回归任务中的应用，涵盖以下核心内容：\n",
    "\n",
    "1. **理论基础**：决策树回归的工作原理与 MSE 分裂准则\n",
    "2. **一维回归**：可视化阶梯状预测特性\n",
    "3. **多维回归**：在真实数据集上的应用\n",
    "4. **正则化**：通过超参数控制模型复杂度\n",
    "5. **模型评估**：交叉验证与学习曲线分析\n",
    "\n",
    "---\n",
    "\n",
    "## 核心知识点\n",
    "\n",
    "- 决策树回归在每个叶子节点输出**常数值**（节点内样本目标值的均值）\n",
    "- 分裂准则基于**均方误差 (MSE)** 最小化\n",
    "- 预测函数呈**阶梯状**，无法像线性模型那样外推\n",
    "- 需要通过正则化（如 `max_depth`）防止过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1",
   "metadata": {},
   "source": [
    "## 1. 环境配置与数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 标准库\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 数值计算\n",
    "import numpy as np\n",
    "\n",
    "# 可视化\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# scikit-learn 模块\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# 设置随机种子保证可复现性\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"环境配置完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": [
    "## 2. 一维回归：理解阶梯状预测\n",
    "\n",
    "决策树回归的核心特性是**阶梯状预测**：\n",
    "- 每个叶子节点输出一个常数值\n",
    "- 整体预测函数由多个水平线段组成\n",
    "- `max_depth` 越大，阶梯越细密，拟合越精细\n",
    "\n",
    "下面用正弦函数生成数据，直观展示这一特性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d-regression-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成带噪声的正弦数据\n",
    "n_samples = 200\n",
    "X_1d = np.sort(5 * np.random.rand(n_samples, 1), axis=0)\n",
    "y_1d = np.sin(X_1d).ravel() + np.random.normal(0, 0.1, n_samples)\n",
    "\n",
    "# 用于绘制预测曲线的连续点\n",
    "X_plot = np.linspace(0, 5, 500).reshape(-1, 1)\n",
    "\n",
    "print(f\"数据形状: X={X_1d.shape}, y={y_1d.shape}\")\n",
    "print(f\"目标值范围: [{y_1d.min():.3f}, {y_1d.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d-regression-compare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对比不同深度的决策树回归效果\n",
    "depths = [2, 4, 6, 10]\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "for ax, depth in zip(axes.ravel(), depths):\n",
    "    # 训练模型\n",
    "    reg = DecisionTreeRegressor(max_depth=depth, random_state=RANDOM_STATE)\n",
    "    reg.fit(X_1d, y_1d)\n",
    "    y_pred = reg.predict(X_plot)\n",
    "    \n",
    "    # 计算训练集 MSE\n",
    "    train_mse = mean_squared_error(y_1d, reg.predict(X_1d))\n",
    "    \n",
    "    # 绘图\n",
    "    ax.scatter(X_1d, y_1d, c='steelblue', alpha=0.5, s=20, label='Training data')\n",
    "    ax.plot(X_plot, np.sin(X_plot), 'g--', linewidth=2, label='True function')\n",
    "    ax.plot(X_plot, y_pred, 'r-', linewidth=2, label='Prediction')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_title(f'max_depth={depth}, MSE={train_mse:.4f}, leaves={reg.get_n_leaves()}')\n",
    "    ax.legend(loc='upper right', fontsize=8)\n",
    "\n",
    "plt.suptitle('Decision Tree Regression: Effect of max_depth on Prediction Shape', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": [
    "## 3. 多维回归：加州房价数据集\n",
    "\n",
    "使用加州房价数据集 (California Housing) 演示决策树回归在实际问题中的应用。\n",
    "\n",
    "**数据集特征：**\n",
    "- 8 个特征：房龄、房间数、人口密度、地理位置等\n",
    "- 目标变量：房价中位数（以 10 万美元为单位）\n",
    "- 样本数：20,640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing.data, housing.target\n",
    "feature_names = housing.feature_names\n",
    "\n",
    "print(f\"数据集形状: X={X.shape}, y={y.shape}\")\n",
    "print(f\"\\n特征列表:\")\n",
    "for i, name in enumerate(feature_names):\n",
    "    print(f\"  {i+1}. {name}: mean={X[:, i].mean():.2f}, std={X[:, i].std():.2f}\")\n",
    "\n",
    "print(f\"\\n目标变量统计:\")\n",
    "print(f\"  mean={y.mean():.3f}, std={y.std():.3f}\")\n",
    "print(f\"  range=[{y.min():.3f}, {y.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-test-split",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(f\"训练集: {X_train.shape[0]} 样本\")\n",
    "print(f\"测试集: {X_test.shape[0]} 样本\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": [
    "## 4. 模型训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    评估回归模型性能\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : 已训练的回归模型\n",
    "    X_train, y_train : 训练数据\n",
    "    X_test, y_test : 测试数据\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict : 包含各项评估指标的字典\n",
    "    \"\"\"\n",
    "    # 预测\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    metrics = {\n",
    "        'train_mse': mean_squared_error(y_train, y_train_pred),\n",
    "        'test_mse': mean_squared_error(y_test, y_test_pred),\n",
    "        'train_rmse': np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
    "        'test_rmse': np.sqrt(mean_squared_error(y_test, y_test_pred)),\n",
    "        'train_mae': mean_absolute_error(y_train, y_train_pred),\n",
    "        'test_mae': mean_absolute_error(y_test, y_test_pred),\n",
    "        'train_r2': r2_score(y_train, y_train_pred),\n",
    "        'test_r2': r2_score(y_test, y_test_pred)\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "# 训练基准模型（无正则化）\n",
    "tree_full = DecisionTreeRegressor(random_state=RANDOM_STATE)\n",
    "tree_full.fit(X_train, y_train)\n",
    "\n",
    "metrics_full = evaluate_model(tree_full, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"无正则化决策树 (Full Tree):\")\n",
    "print(f\"  树深度: {tree_full.get_depth()}\")\n",
    "print(f\"  叶子数: {tree_full.get_n_leaves()}\")\n",
    "print(f\"  Train RMSE: {metrics_full['train_rmse']:.4f}\")\n",
    "print(f\"  Test RMSE:  {metrics_full['test_rmse']:.4f}\")\n",
    "print(f\"  Train R²:   {metrics_full['train_r2']:.4f}\")\n",
    "print(f\"  Test R²:    {metrics_full['test_r2']:.4f}\")\n",
    "print(f\"\\n过拟合程度: Train/Test RMSE ratio = {metrics_full['train_rmse']/metrics_full['test_rmse']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5",
   "metadata": {},
   "source": [
    "## 5. 正则化：超参数调优\n",
    "\n",
    "### 5.1 max_depth 的影响\n",
    "\n",
    "通过限制树的最大深度来控制模型复杂度，是最常用的正则化方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "depth-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析不同 max_depth 对性能的影响\n",
    "depths = range(1, 25)\n",
    "train_scores, test_scores = [], []\n",
    "\n",
    "for depth in depths:\n",
    "    tree = DecisionTreeRegressor(max_depth=depth, random_state=RANDOM_STATE)\n",
    "    tree.fit(X_train, y_train)\n",
    "    train_scores.append(-mean_squared_error(y_train, tree.predict(X_train)))\n",
    "    test_scores.append(-mean_squared_error(y_test, tree.predict(X_test)))\n",
    "\n",
    "# 绘制验证曲线\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(depths, np.sqrt(-np.array(train_scores)), 'b-o', label='Training RMSE', markersize=4)\n",
    "ax.plot(depths, np.sqrt(-np.array(test_scores)), 'r-o', label='Test RMSE', markersize=4)\n",
    "\n",
    "# 标记最佳深度\n",
    "best_depth = depths[np.argmin(-np.array(test_scores))]\n",
    "ax.axvline(x=best_depth, color='green', linestyle='--', alpha=0.7, label=f'Best depth={best_depth}')\n",
    "\n",
    "ax.set_xlabel('max_depth')\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('Validation Curve: max_depth vs RMSE')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"最佳深度: {best_depth}\")\n",
    "print(f\"对应 Test RMSE: {np.sqrt(-test_scores[best_depth-1]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5-2",
   "metadata": {},
   "source": [
    "### 5.2 多参数交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对最佳深度模型进行交叉验证\n",
    "tree_optimized = DecisionTreeRegressor(\n",
    "    max_depth=best_depth,\n",
    "    min_samples_leaf=5,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# 5 折交叉验证\n",
    "cv_scores = cross_val_score(\n",
    "    tree_optimized, X_train, y_train,\n",
    "    cv=5, scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "cv_rmse = np.sqrt(-cv_scores)\n",
    "\n",
    "print(\"5 折交叉验证结果:\")\n",
    "print(f\"  RMSE (各折): {cv_rmse}\")\n",
    "print(f\"  Mean RMSE:   {cv_rmse.mean():.4f}\")\n",
    "print(f\"  Std RMSE:    {cv_rmse.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练最终模型并在测试集上评估\n",
    "tree_optimized.fit(X_train, y_train)\n",
    "metrics_opt = evaluate_model(tree_optimized, X_train, y_train, X_test, y_test)\n",
    "\n",
    "print(\"优化后的决策树:\")\n",
    "print(f\"  树深度: {tree_optimized.get_depth()}\")\n",
    "print(f\"  叶子数: {tree_optimized.get_n_leaves()}\")\n",
    "print(f\"  Train RMSE: {metrics_opt['train_rmse']:.4f}\")\n",
    "print(f\"  Test RMSE:  {metrics_opt['test_rmse']:.4f}\")\n",
    "print(f\"  Train R²:   {metrics_opt['train_r2']:.4f}\")\n",
    "print(f\"  Test R²:    {metrics_opt['test_r2']:.4f}\")\n",
    "\n",
    "print(\"\\n性能对比:\")\n",
    "print(f\"  Test RMSE 提升: {(metrics_full['test_rmse'] - metrics_opt['test_rmse']) / metrics_full['test_rmse'] * 100:.1f}%\")\n",
    "print(f\"  模型复杂度降低: {tree_full.get_n_leaves()} -> {tree_optimized.get_n_leaves()} 叶子\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6",
   "metadata": {},
   "source": [
    "## 6. 学习曲线分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "learning-curve",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制学习曲线\n",
    "train_sizes, train_scores_lc, test_scores_lc = learning_curve(\n",
    "    DecisionTreeRegressor(max_depth=best_depth, min_samples_leaf=5, random_state=RANDOM_STATE),\n",
    "    X_train, y_train,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "train_rmse_mean = np.sqrt(-train_scores_lc.mean(axis=1))\n",
    "train_rmse_std = np.sqrt(-train_scores_lc).std(axis=1)\n",
    "test_rmse_mean = np.sqrt(-test_scores_lc.mean(axis=1))\n",
    "test_rmse_std = np.sqrt(-test_scores_lc).std(axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.fill_between(train_sizes, train_rmse_mean - train_rmse_std, train_rmse_mean + train_rmse_std, alpha=0.1, color='blue')\n",
    "ax.fill_between(train_sizes, test_rmse_mean - test_rmse_std, test_rmse_mean + test_rmse_std, alpha=0.1, color='red')\n",
    "ax.plot(train_sizes, train_rmse_mean, 'b-o', label='Training RMSE')\n",
    "ax.plot(train_sizes, test_rmse_mean, 'r-o', label='Cross-validation RMSE')\n",
    "\n",
    "ax.set_xlabel('Training Set Size')\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('Learning Curve: Decision Tree Regressor')\n",
    "ax.legend(loc='best')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7",
   "metadata": {},
   "source": [
    "## 7. 特征重要性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征重要性可视化\n",
    "importances = tree_optimized.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.barh(range(len(importances)), importances[indices], color='steelblue')\n",
    "ax.set_yticks(range(len(importances)))\n",
    "ax.set_yticklabels([feature_names[i] for i in indices])\n",
    "ax.set_xlabel('Feature Importance')\n",
    "ax.set_title('Decision Tree Regressor: Feature Importance')\n",
    "ax.invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"特征重要性排名:\")\n",
    "for i, idx in enumerate(indices):\n",
    "    print(f\"  {i+1}. {feature_names[idx]}: {importances[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-8",
   "metadata": {},
   "source": [
    "## 8. 预测结果可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prediction-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 真实值 vs 预测值散点图\n",
    "y_pred = tree_optimized.predict(X_test)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 散点图\n",
    "ax1 = axes[0]\n",
    "ax1.scatter(y_test, y_pred, alpha=0.3, s=10)\n",
    "ax1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', linewidth=2, label='Perfect prediction')\n",
    "ax1.set_xlabel('Actual Values')\n",
    "ax1.set_ylabel('Predicted Values')\n",
    "ax1.set_title('Actual vs Predicted')\n",
    "ax1.legend()\n",
    "\n",
    "# 残差分布\n",
    "ax2 = axes[1]\n",
    "residuals = y_test - y_pred\n",
    "ax2.hist(residuals, bins=50, edgecolor='black', alpha=0.7)\n",
    "ax2.axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "ax2.set_xlabel('Residual (Actual - Predicted)')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title(f'Residual Distribution (mean={residuals.mean():.3f}, std={residuals.std():.3f})')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-9",
   "metadata": {},
   "source": [
    "## 9. 决策树结构可视化（简化版）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tree-viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练一个简化版树用于可视化\n",
    "tree_simple = DecisionTreeRegressor(max_depth=3, random_state=RANDOM_STATE)\n",
    "tree_simple.fit(X_train, y_train)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "plot_tree(\n",
    "    tree_simple,\n",
    "    feature_names=feature_names,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=10,\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_title('Decision Tree Structure (max_depth=3)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n树结构说明:\")\n",
    "print(\"  - 每个节点显示: 分裂条件、MSE、样本数、预测值\")\n",
    "print(\"  - 颜色深浅表示预测值高低\")\n",
    "print(\"  - 左分支表示条件为真，右分支表示条件为假\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-10",
   "metadata": {},
   "source": [
    "## 10. 总结\n",
    "\n",
    "### 关键发现\n",
    "\n",
    "1. **阶梯状预测**：决策树回归的预测值是离散的阶梯形状，由叶子节点数量决定精细程度\n",
    "\n",
    "2. **过拟合风险**：无正则化的决策树容易过拟合，训练误差接近 0 但泛化能力差\n",
    "\n",
    "3. **正则化效果**：通过 `max_depth` 和 `min_samples_leaf` 可以有效控制过拟合\n",
    "\n",
    "4. **特征重要性**：决策树天然提供特征重要性度量，有助于理解数据\n",
    "\n",
    "### 实践建议\n",
    "\n",
    "- 优先调节 `max_depth`（通常 5-15 之间）\n",
    "- 设置 `min_samples_leaf` 避免叶子节点过小\n",
    "- 使用交叉验证选择最佳超参数\n",
    "- 考虑使用集成方法（随机森林、梯度提升）获得更好性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unit-test",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 单元测试：验证代码正确性\n",
    "# ============================================================\n",
    "\n",
    "def run_tests():\n",
    "    \"\"\"运行基础功能测试\"\"\"\n",
    "    print(\"=\"*50)\n",
    "    print(\"运行单元测试...\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 测试 1: 模型可以正常训练\n",
    "    try:\n",
    "        model = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "        model.fit(X_train[:100], y_train[:100])  # 使用小数据集加速\n",
    "        assert model.get_depth() <= 5\n",
    "        print(\"[PASS] 测试 1: 模型训练成功\")\n",
    "    except Exception as e:\n",
    "        print(f\"[FAIL] 测试 1: {e}\")\n",
    "    \n",
    "    # 测试 2: 预测输出形状正确\n",
    "    try:\n",
    "        pred = model.predict(X_test[:10])\n",
    "        assert pred.shape == (10,)\n",
    "        print(\"[PASS] 测试 2: 预测输出形状正确\")\n",
    "    except Exception as e:\n",
    "        print(f\"[FAIL] 测试 2: {e}\")\n",
    "    \n",
    "    # 测试 3: 特征重要性维度正确\n",
    "    try:\n",
    "        imp = model.feature_importances_\n",
    "        assert len(imp) == X_train.shape[1]\n",
    "        assert abs(sum(imp) - 1.0) < 1e-6\n",
    "        print(\"[PASS] 测试 3: 特征重要性维度正确\")\n",
    "    except Exception as e:\n",
    "        print(f\"[FAIL] 测试 3: {e}\")\n",
    "    \n",
    "    # 测试 4: 交叉验证可以运行\n",
    "    try:\n",
    "        scores = cross_val_score(model, X_train[:200], y_train[:200], cv=3)\n",
    "        assert len(scores) == 3\n",
    "        print(\"[PASS] 测试 4: 交叉验证运行成功\")\n",
    "    except Exception as e:\n",
    "        print(f\"[FAIL] 测试 4: {e}\")\n",
    "    \n",
    "    # 测试 5: 评估函数正常工作\n",
    "    try:\n",
    "        metrics = evaluate_model(model, X_train[:100], y_train[:100], X_test[:50], y_test[:50])\n",
    "        assert all(key in metrics for key in ['train_mse', 'test_mse', 'train_r2', 'test_r2'])\n",
    "        print(\"[PASS] 测试 5: 评估函数正常工作\")\n",
    "    except Exception as e:\n",
    "        print(f\"[FAIL] 测试 5: {e}\")\n",
    "    \n",
    "    print(\"=\"*50)\n",
    "    print(\"测试完成!\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "run_tests()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
