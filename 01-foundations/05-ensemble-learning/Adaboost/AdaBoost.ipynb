{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title-cell",
   "metadata": {},
   "source": [
    "# AdaBoost 自适应提升算法\n",
    "\n",
    "## 算法原理\n",
    "\n",
    "AdaBoost (Adaptive Boosting) 是一种迭代式的集成学习算法，其核心思想是：\n",
    "\n",
    "1. **样本权重调整**：每轮迭代后，增加被错误分类样本的权重，减少被正确分类样本的权重\n",
    "2. **弱学习器组合**：将多个弱学习器（通常是决策树桩）通过加权投票组合成强学习器\n",
    "3. **串行训练**：每个弱学习器都试图修正前一个学习器的错误\n",
    "\n",
    "## 数学表达\n",
    "\n",
    "对于 $M$ 个弱学习器，最终预测为：\n",
    "\n",
    "$$H(x) = \\text{sign}\\left(\\sum_{m=1}^{M} \\alpha_m h_m(x)\\right)$$\n",
    "\n",
    "其中 $\\alpha_m$ 是第 $m$ 个弱学习器的权重，$h_m(x)$ 是弱学习器的预测。\n",
    "\n",
    "## 关键参数\n",
    "\n",
    "- `n_estimators`: 弱学习器数量，过多可能导致过拟合\n",
    "- `learning_rate`: 学习率，控制每个弱学习器的贡献度\n",
    "- `estimator`: 基学习器（默认为决策树桩 max_depth=1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 设置随机种子以保证结果可复现\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-section",
   "metadata": {},
   "source": [
    "## 1. 数据准备\n",
    "\n",
    "使用经典的鸢尾花（Iris）数据集进行演示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据集\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"训练集大小: {X_train.shape[0]}\")\n",
    "print(f\"测试集大小: {X_test.shape[0]}\")\n",
    "print(f\"特征数量: {X.shape[1]}\")\n",
    "print(f\"类别数量: {len(np.unique(y))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-section",
   "metadata": {},
   "source": [
    "## 2. AdaBoost 模型训练\n",
    "\n",
    "使用决策树桩（深度为1的决策树）作为基学习器，这是 AdaBoost 最常见的配置。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-cell",
   "metadata": {},
   "outputs": [],
   "source": "# 定义基学习器：决策树桩\nbase_estimator = DecisionTreeClassifier(max_depth=1, random_state=RANDOM_STATE)\n\n# 创建 AdaBoost 分类器\n# 注意：sklearn 1.6+ 中 SAMME.R 已废弃，使用 SAMME 算法\nada_clf = AdaBoostClassifier(\n    estimator=base_estimator,    # 基学习器\n    n_estimators=200,            # 弱学习器数量\n    learning_rate=0.5,           # 学习率\n    algorithm='SAMME',           # 使用 SAMME 算法\n    random_state=RANDOM_STATE\n)\n\n# 训练模型\nada_clf.fit(X_train, y_train)\n\n# 预测\ny_pred = ada_clf.predict(X_test)\n\n# 评估模型\ntrain_score = ada_clf.score(X_train, y_train)\ntest_score = ada_clf.score(X_test, y_test)\n\nprint(f\"训练集准确率: {train_score:.4f}\")\nprint(f\"测试集准确率: {test_score:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cv-section",
   "metadata": {},
   "source": [
    "## 3. 交叉验证评估\n",
    "\n",
    "使用 5 折交叉验证来更可靠地评估模型性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cv-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 交叉验证\n",
    "cv_scores = cross_val_score(ada_clf, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"交叉验证分数: {cv_scores}\")\n",
    "print(f\"平均准确率: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analysis-section",
   "metadata": {},
   "source": [
    "## 4. 学习曲线分析\n",
    "\n",
    "分析不同数量的弱学习器对模型性能的影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analysis-cell",
   "metadata": {},
   "outputs": [],
   "source": "# 分析弱学习器数量对性能的影响\nn_estimators_range = [10, 50, 100, 200, 300]\nresults = []\n\nfor n_est in n_estimators_range:\n    clf = AdaBoostClassifier(\n        estimator=DecisionTreeClassifier(max_depth=1, random_state=RANDOM_STATE),\n        n_estimators=n_est,\n        learning_rate=0.5,\n        algorithm='SAMME',\n        random_state=RANDOM_STATE\n    )\n    clf.fit(X_train, y_train)\n    train_acc = clf.score(X_train, y_train)\n    test_acc = clf.score(X_test, y_test)\n    results.append((n_est, train_acc, test_acc))\n    print(f\"n_estimators={n_est:3d}: 训练准确率={train_acc:.4f}, 测试准确率={test_acc:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "id": "verify-section",
   "metadata": {},
   "source": [
    "## 5. 单元测试验证\n",
    "\n",
    "验证模型的基本功能是否正常。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单元测试\n",
    "def test_adaboost():\n",
    "    \"\"\"AdaBoost 模型功能测试\"\"\"\n",
    "    # 测试1: 模型应该能够训练\n",
    "    assert hasattr(ada_clf, 'estimators_'), \"模型未正确训练\"\n",
    "    \n",
    "    # 测试2: 弱学习器数量应该正确\n",
    "    assert len(ada_clf.estimators_) == 200, \"弱学习器数量不正确\"\n",
    "    \n",
    "    # 测试3: 预测结果形状应该正确\n",
    "    assert y_pred.shape == y_test.shape, \"预测结果形状不正确\"\n",
    "    \n",
    "    # 测试4: 准确率应该在合理范围内\n",
    "    assert test_score >= 0.8, f\"测试集准确率过低: {test_score}\"\n",
    "    \n",
    "    # 测试5: 交叉验证应该返回正确数量的分数\n",
    "    assert len(cv_scores) == 5, \"交叉验证折数不正确\"\n",
    "    \n",
    "    print(\"所有测试通过!\")\n",
    "\n",
    "test_adaboost()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-section",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "### AdaBoost 的优势\n",
    "- 不易过拟合（在某些条件下）\n",
    "- 可以使用各种弱学习器\n",
    "- 理论基础扎实\n",
    "\n",
    "### AdaBoost 的局限\n",
    "- 对噪声和异常值敏感\n",
    "- 训练是串行的，无法并行化\n",
    "- 需要足够的数据量\n",
    "\n",
    "### 调参建议\n",
    "1. 先固定 `learning_rate=1.0`，调整 `n_estimators`\n",
    "2. 再降低 `learning_rate`，相应增加 `n_estimators`\n",
    "3. 使用交叉验证选择最佳参数组合"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}