# 分类算法与评估指标

> **核心主题**：二分类、多分类、多标签、主流分类算法、性能评估与不平衡处理
> **前置知识**：线性代数（向量、内积）、概率统计（条件概率、贝叶斯定理）、基础优化（梯度下降）

---

## 知识图谱

```
分类
├── 问题类型
│   ├── 二分类
│   ├── 多分类
│   └── 多标签分类
├── 主要算法
│   ├── 逻辑回归 (基线模型)
│   ├── 线性/核 SVM
│   ├── 决策树与随机森林
│   ├── 朴素贝叶斯
│   ├── K 近邻 (KNN)
│   └── 简单神经网络
├── 模型输出
│   ├── 预测标签
│   └── 预测置信度/概率
├── 评估与诊断
│   ├── 混淆矩阵
│   ├── 准确率 vs 精确率 vs 召回率
│   ├── F1 与 PR 曲线
│   ├── ROC 曲线与 AUC
│   └── 多分类与多标签指标
└── 工程实践
    ├── 数据预处理与特征缩放
    ├── 类别不平衡处理
    ├── 超参数调优 (CV + 搜索)
    └── 实验设计与结果复现
```

---

## 1. 分类任务与问题类型

### 1.1 分类的定义

- 给定带标签的数据集 $\{(x_i, y_i)\}_{i=1}^m$，目标是学习一个函数 $f(x)$，将新样本映射到离散标签空间 $\mathcal{Y}$。
- 与回归的主要区别在于输出空间是**离散的**。

### 1.2 三种常见任务

1. **二分类 (Binary Classification)**  
   - 标签集合：$\mathcal{Y} = \{0,1\}$ 或 $\{-1, +1\}$。  
   - 示例：垃圾邮件检测、欺诈检测、疾病诊断（阳性/阴性）。

2. **多分类 (Multi‑Class)**  
   - 标签集合：$\mathcal{Y} = \{1,\dots,K\}$，各类别互斥。  
   - 示例：数字识别 (0–9)、新闻主题分类。

3. **多标签分类 (Multi‑Label)**  
   - 每个样本对应一个标签子集 $Y_i \subseteq \mathcal{L}$。  
   - 示例：图像标注（“人”“海滩”“日落”同时存在）、音乐标签。

---

## 2. 核心算法与适用场景

本小节重点不是穷举所有算法，而是给出一套**优先使用顺序**和**各方法的适用条件**。

### 2.1 逻辑回归：线性可分任务的首选基线

- **形式**：
  $$
  P(y=1\mid x) = \sigma(w^\top x + b) = \frac{1}{1 + e^{-(w^\top x + b)}}.
  $$
- **损失函数**：对数损失 (Log Loss)，对应极大似然估计。
- **优点**：
  - 训练和预测都很快；
  - 输出**有校准意义的概率**；
  - 可解释性强：权重符号与大小直接反映特征作用；
  - 支持 L1/L2 正则化。
- **局限**：
  - 决策边界是线性的；复杂非线性任务需要加入特征工程或核方法；
  - 对异常值敏感，需要合理的鲁棒预处理。
- **何时优先用**：
  - 结构化数值/类别特征，维度中等；
  - 需要概率输出或可解释性；
  - 作为所有复杂模型之前的基线。

### 2.2 SVM：间隔最大化与核方法

- 线性 SVM 与逻辑回归在形式上类似，但目标是**最大化间隔**而非拟合概率。
- 核 SVM 通过核函数构造高维特征空间，能处理复杂非线性边界。
- **优点**：
  - 在线性可分或近似可分任务上表现强；
  - 使用合适核函数可拟合复杂边界；
  - 对少量高维数据（如文本、图像特征）很有效。
- **局限**：
  - 对特征缩放极度敏感；
  - 核 SVM 在大样本下训练成本高；
  - 概率输出需要额外校准。

### 2.3 决策树与随机森林：可解释与“开箱即用”的强力基线

- 决策树：
  - 以“if–else”形式划分特征空间；
  - 对非线性、特征交互很敏感；
  - 易过拟合，需要深度/叶子大小等正则化。
- 随机森林：
  - 大量子样本 + 子特征上的树的集成；
  - 几乎不需要特征缩放；
  - 对大多数表格数据非常鲁棒。
- **何时优先用**：
  - 结构化数据、特征类型杂（数值+类别）；
  - 只需要较强性能，不特别在意推理速度或模型大小；
  - 希望得到**特征重要性**。

### 2.4 朴素贝叶斯：文本任务与小样本场景

- 基于贝叶斯定理和条件独立假设：
  $$
  P(y\mid x_1,\dots,x_n) \propto P(y)\prod_i P(x_i\mid y).
  $$
- 常见变体：
  - 高斯 NB：连续特征；
  - 多项式 NB、伯努利 NB：文本/计数特征。
- **优点**：
  - 训练和预测超快；
  - 对高维稀疏特征友好（如 TF‑IDF）；
  - 在样本很少时仍有不错表现。
- **局限**：
  - 强独立性假设通常不成立；
  - 上限由假设偏差决定。

### 2.5 KNN：懒惰学习与“局部投票”

- 思想：样本标签由其最近的 $k$ 个邻居标签多数表决。
- **优点**：
  - 无显式训练阶段；
  - 自然支持多分类；
  - 决策边界可非常复杂。
- **局限**：
  - 预测时复杂度高 ($O(mn)$)，不适合大数据；
  - 对特征缩放敏感；
  - 对噪声和无关特征敏感。

### 2.6 简单神经网络：非线性表达的平滑扩展

- 单隐层 MLP 已可逼近广泛函数族；
- 适用于：
  - 特征规模较大且存在复杂非线性关系；
  - 样本量足够；
  - 允许一定训练时间和调参成本。

---

## 3. 多分类与多标签策略

### 3.1 一对多 (OvR / OvA)

- 训练 $K$ 个二分类器，每个对应“类别 $k$ vs 其它”；
- 预测时选择得分最高的类别；
- 绝大多数线性模型和 SVM 在多分类时采用 OvR。

### 3.2 一对一 (OvO)

- 为每一对类别训练一个分类器，总数 $K(K-1)/2$；
- 预测时通过多数投票决定类别；
- `SVC` 默认采用 OvO，在类数不大时表现良好。

### 3.3 多标签分类常见方法

1. **二元相关性 (Binary Relevance)**：为每个标签训练独立二分类器。简单但忽略标签相关性。  
2. **分类器链 (Classifier Chains)**：按顺序预测标签，前面标签作为后面模型的额外特征。可建模标签依赖。  
3. **标签幂集 (Label Powerset)**：将每种标签组合视作单独类别，适合标签组合较少的情况。

---

## 4. 评估指标与曲线

### 4.1 混淆矩阵与基本概念

二分类混淆矩阵：

```
                 预测 Positive   预测 Negative
真实 Positive        TP              FN
真实 Negative        FP              TN
```

常用指标：

- 准确率：$\text{Acc} = \dfrac{TP+TN}{TP+TN+FP+FN}$；
- 精确率：$\text{Prec} = \dfrac{TP}{TP+FP}$；
- 召回率（真正例率）：$\text{Rec} = \dfrac{TP}{TP+FN}$；
- 特异度（真负例率）：$\text{Spec} = \dfrac{TN}{TN+FP}$。

### 4.2 F1 分数与 PR 曲线

- F1 为精确率与召回率的调和平均：
  $$
  F_1 = \frac{2\cdot \text{Prec}\cdot \text{Rec}}{\text{Prec} + \text{Rec}}.
  $$
- 在类别不平衡时，比单靠准确率更有意义。
- 精确率–召回率曲线 (PR curve)：在不同决策阈值下的精确率–召回率轨迹；  
  **PR‑AUC** 在严重不平衡数据下常优于 ROC‑AUC。

### 4.3 ROC 曲线与 AUC

- ROC 曲线：以假正例率 (FPR) 为横轴，真正例率 (TPR) 为纵轴；
- AUC 为 ROC 曲线下面积：
  - 1 表示完美分类器；
  - 0.5 接近随机猜测。
- 在类别较平衡且两类同等重要时，ROC‑AUC 是稳健比较不同模型的指标。

### 4.4 多分类与多标签指标

常用平均方法：

- **micro**：按样本级别统计 TP/FP/FN，再计算指标；对大类权重更高；
- **macro**：对每类单独算指标再做算术平均；对小类敏感；
- **weighted**：按类别支持度加权平均，兼顾不平衡。

---

## 5. 工程实践与实验设计

### 5.1 数据预处理

- 缩放：
  - 必须：逻辑回归、SVM、KNN、神经网络；
  - 不必：决策树、随机森林、朴素贝叶斯（基于计数的）。
- 类别变量编码：
  - 线性模型/SVM：通常用独热编码 (One‑Hot)；
  - 树模型：可接受整数编码，但需避免“人为顺序”的含义。
- 处理缺失值：简单插值（均值/众数）或基于模型的插值；注意不要在整个数据上 `fit` 预处理器，避免数据泄露。

### 5.2 类别不平衡处理

- 重采样：
  - 过采样：如 SMOTE、ADASYN；
  - 欠采样：随机删除多数类样本。
- 使用类别权重：
  - `class_weight="balanced"` 或手动指定 `{类: 权重}`；
  - 等价于对不同类别使用不同的惩罚系数 $C$。
- 评估指标：
  - 减少对准确率的依赖；
  - 使用 F1、PR‑AUC、召回率等更关注少数类的指标。

### 5.3 超参数搜索与交叉验证

典型流程：

1. 用简单模型（如逻辑回归或随机森林）建立基线；  
2. 使用 `StratifiedKFold` 做分层交叉验证，确保类别比例稳定；  
3. 使用 `GridSearchCV`/`RandomizedSearchCV` 搜索关键超参数；
4. 固定随机种子和数据划分，保证可复现。

示例（逻辑回归调参）：

```python
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV, StratifiedKFold

param_grid = {
    "C": [0.01, 0.1, 1, 10],
    "penalty": ["l2"],
    "solver": ["lbfgs"]
}

log_clf = LogisticRegression(max_iter=1000, class_weight="balanced")
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

grid = GridSearchCV(
    log_clf,
    param_grid=param_grid,
    cv=cv,
    scoring="f1_weighted",
    n_jobs=-1
)
grid.fit(X_train, y_train)
best_model = grid.best_estimator_
```

### 5.4 建议的实验组合

在 `MNIST/MNIST.ipynb` 这类数据集上，你可以按照以下顺序逐步增加复杂度：

1. 逻辑回归：作为线性基线，观察错误样本（如“3/5”混淆）。  
2. 线性 SVM：比较与逻辑回归的差异；调整 `C`。  
3. RBF‑SVM：在子集上搜索 `C` 和 `gamma`，看是否能捕获更复杂边界。  
4. 随机森林：比较在不做特征缩放时的表现和训练时间。  
5. 简单 MLP：引入一层隐藏层，观察与线性模型的差距。  
6. 对比多种指标（Acc、F1、ROC‑AUC），并通过混淆矩阵分析具体错误类型。

---

## 小结

- 分类问题的关键不在于“记住多少算法名字”，而在于：
  - 正确认识任务（类别数、是否多标签、是否不平衡）；
  - 选择合适的基线模型与评估指标；
  - 通过交叉验证和合理的实验设计迭代模型。
- 更复杂的模型（核方法、集成、深度网络）都是在这套基础框架上的自然延展。
