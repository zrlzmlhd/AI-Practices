# 09 - å®æˆ˜é¡¹ç›®

ä»ç†è®ºåˆ°å®è·µï¼Œé€šè¿‡çœŸå®é¡¹ç›®æ£€éªŒå’Œå·©å›ºæ‰€å­¦çŸ¥è¯†ã€‚

## æ¨¡å—æ¦‚è§ˆ

| å±æ€§ | å€¼ |
|:-----|:---|
| **å‰ç½®è¦æ±‚** | å®Œæˆ 01-04 æ¨¡å—å­¦ä¹  |
| **é¡¹ç›®æ•°é‡** | 19+ ä¸ªå®Œæ•´é¡¹ç›® |
| **éš¾åº¦èŒƒå›´** | â­â­ ~ â­â­â­â­â­ |
| **ç‰¹è‰²** | å« Kaggle é‡‘ç‰Œæ–¹æ¡ˆ |

## é¡¹ç›®åˆ†ç±»

### ğŸ“Š 01-ML åŸºç¡€é¡¹ç›®

å…¥é—¨çº§æœºå™¨å­¦ä¹ é¡¹ç›®ï¼Œé€‚åˆåˆå­¦è€…ç»ƒæ‰‹ã€‚

| é¡¹ç›® | æè¿° | æŠ€æœ¯æ ˆ | éš¾åº¦ |
|:-----|:-----|:-------|:----:|
| **Titanic ç”Ÿå­˜é¢„æµ‹** | ç»å…¸äºŒåˆ†ç±»é—®é¢˜ï¼Œå­¦ä¹ ç‰¹å¾å·¥ç¨‹ | XGBoost, Pandas | â­â­ |
| **Otto äº§å“åˆ†ç±»** | å¤šåˆ†ç±»é—®é¢˜ï¼Œå­¦ä¹ é›†æˆæ–¹æ³• | LightGBM, Stacking | â­â­â­ |
| **House Prices é¢„æµ‹** | å›å½’é—®é¢˜ï¼Œå­¦ä¹ æ•°æ®é¢„å¤„ç† | Ridge, Lasso, XGBoost | â­â­ |

### ğŸ‘ï¸ 02-è®¡ç®—æœºè§†è§‰é¡¹ç›®

å›¾åƒè¯†åˆ«ä¸å¤„ç†ç›¸å…³é¡¹ç›®ã€‚

| é¡¹ç›® | æè¿° | æŠ€æœ¯æ ˆ | éš¾åº¦ |
|:-----|:-----|:-------|:----:|
| **MNIST æ‰‹å†™æ•°å­—è¯†åˆ«** | CNN å…¥é—¨ç»å…¸é¡¹ç›® | TensorFlow, Keras | â­â­ |
| **CIFAR-10 å›¾åƒåˆ†ç±»** | å¤šç±»åˆ«å›¾åƒåˆ†ç±» | ResNet, Data Augmentation | â­â­â­ |
| **å›¾åƒé£æ ¼è¿ç§»** | ç¥ç»é£æ ¼è¿ç§»å®ç° | VGG19, PyTorch | â­â­â­ |

### ğŸ“ 03-NLP é¡¹ç›®

è‡ªç„¶è¯­è¨€å¤„ç†ç›¸å…³é¡¹ç›®ã€‚

| é¡¹ç›® | æè¿° | æŠ€æœ¯æ ˆ | éš¾åº¦ |
|:-----|:-----|:-------|:----:|
| **LSTM æƒ…æ„Ÿåˆ†æ** | ç”µå½±è¯„è®ºæƒ…æ„Ÿåˆ†ç±» | LSTM, Word2Vec | â­â­â­ |
| **Transformer æ–‡æœ¬åˆ†ç±»** | åŸºäºæ³¨æ„åŠ›æœºåˆ¶çš„åˆ†ç±» | Transformer, PyTorch | â­â­â­â­ |
| **å‘½åå®ä½“è¯†åˆ« (NER)** | åºåˆ—æ ‡æ³¨ä»»åŠ¡ | BiLSTM-CRF, BERT | â­â­â­â­ |
| **æ–‡æœ¬æ‘˜è¦ç”Ÿæˆ** | Seq2Seq æ‘˜è¦æ¨¡å‹ | T5, Transformers | â­â­â­â­ |

### ğŸ“ˆ 04-æ—¶åºé¢„æµ‹é¡¹ç›®

æ—¶é—´åºåˆ—åˆ†æä¸é¢„æµ‹ã€‚

| é¡¹ç›® | æè¿° | æŠ€æœ¯æ ˆ | éš¾åº¦ |
|:-----|:-----|:-------|:----:|
| **æ¸©åº¦é¢„æµ‹ LSTM** | å¤šå˜é‡æ—¶åºé¢„æµ‹ | LSTM, Keras | â­â­â­ |
| **è‚¡ç¥¨ä»·æ ¼é¢„æµ‹** | é‡‘èæ—¶åºåˆ†æ | LSTM, Attention | â­â­â­â­ |
| **èƒ½æºæ¶ˆè€—é¢„æµ‹** | å¤šæ­¥é¢„æµ‹é—®é¢˜ | Transformer, Prophet | â­â­â­â­ |

### ğŸ† 05-Kaggle ç«èµ›é¡¹ç›®

çœŸå®ç«èµ›çš„å®Œæ•´è§£å†³æ–¹æ¡ˆã€‚

#### ğŸ¥‡ é‡‘ç‰Œæ–¹æ¡ˆ

| ç«èµ› | æ’å | å¥–é‡‘æ±  | æ ¸å¿ƒæŠ€æœ¯ |
|:-----|:----:|:------:|:---------|
| **Feedback Prize - ELL** | Top 1% | $160,000 | DeBERTa, Multi-task Learning, Pseudo Labeling |
| **RSNA Abdominal Trauma** | Top 1% | $140,000 | EfficientNet, 3D CNN, Multi-label Classification |

#### ğŸ¥ˆ é“¶ç‰Œæ–¹æ¡ˆ

| ç«èµ› | æ’å | æ ¸å¿ƒæŠ€æœ¯ |
|:-----|:----:|:---------|
| **American Express Default** | Top 5% | GBDT Ensemble, Feature Engineering, Time Series |

#### ğŸ¥‰ é“œç‰Œæ–¹æ¡ˆ

| ç«èµ› | æ’å | æ ¸å¿ƒæŠ€æœ¯ |
|:-----|:----:|:---------|
| **RSNA Lumbar Spine** | Top 10% | 3D Medical Imaging, Segmentation, Classification |

---

## é¡¹ç›®è¯¦è§£

### Feedback Prize - ELL (ğŸ¥‡ é‡‘ç‰Œ)

**ç«èµ›èƒŒæ™¯**ï¼šè¯„ä¼°è‹±è¯­å­¦ä¹ è€…çš„å†™ä½œæ°´å¹³ï¼Œé¢„æµ‹ 6 ä¸ªç»´åº¦çš„åˆ†æ•°ã€‚

**è§£å†³æ–¹æ¡ˆäº®ç‚¹**ï¼š

```
æ•°æ®å¤„ç† â”€â”€â–º æ¨¡å‹æ¶æ„ â”€â”€â–º è®­ç»ƒç­–ç•¥ â”€â”€â–º åå¤„ç†
    â”‚            â”‚            â”‚           â”‚
    â–¼            â–¼            â–¼           â–¼
 æ–‡æœ¬æ¸…æ´—    DeBERTa-v3   å¤šä»»åŠ¡å­¦ä¹     æ¨¡å‹èåˆ
 æ•°æ®å¢å¼º    Large       ä¼ªæ ‡ç­¾       é˜ˆå€¼ä¼˜åŒ–
 åˆ†å±‚é‡‡æ ·    + Pooling   å¯¹æŠ—è®­ç»ƒ     TTA
```

**æ ¸å¿ƒä»£ç ç»“æ„**ï¼š

```python
class FeedbackModel(nn.Module):
    def __init__(self, model_name, num_labels=6):
        super().__init__()
        self.backbone = AutoModel.from_pretrained(model_name)
        self.pooler = MeanPooling()
        self.classifier = nn.Linear(hidden_size, num_labels)

    def forward(self, input_ids, attention_mask):
        outputs = self.backbone(input_ids, attention_mask)
        pooled = self.pooler(outputs.last_hidden_state, attention_mask)
        return self.classifier(pooled)
```

**å…³é”®æŠ€æœ¯**ï¼š
- **DeBERTa-v3-Large**: æœ€å¼ºé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹
- **Multi-task Learning**: åŒæ—¶é¢„æµ‹ 6 ä¸ªç›®æ ‡
- **Pseudo Labeling**: åˆ©ç”¨æ— æ ‡ç­¾æ•°æ®
- **Adversarial Training**: AWP å¯¹æŠ—è®­ç»ƒæå‡é²æ£’æ€§

---

### RSNA Abdominal Trauma (ğŸ¥‡ é‡‘ç‰Œ)

**ç«èµ›èƒŒæ™¯**ï¼šä» CT æ‰«æå›¾åƒä¸­æ£€æµ‹è…¹éƒ¨åˆ›ä¼¤ã€‚

**è§£å†³æ–¹æ¡ˆäº®ç‚¹**ï¼š

| é˜¶æ®µ | æ–¹æ³• | è¯´æ˜ |
|:-----|:-----|:-----|
| **é¢„å¤„ç†** | 3D Volume Processing | å¤„ç† DICOM æ ¼å¼åŒ»å­¦å½±åƒ |
| **æ¨¡å‹** | EfficientNet-B5 + 3D CNN | 2D åˆ‡ç‰‡ + 3D ä½“ç§¯ç‰¹å¾ |
| **è®­ç»ƒ** | Multi-label Classification | å¤šå™¨å®˜æŸä¼¤æ£€æµ‹ |
| **æ¨ç†** | TTA + Ensemble | æµ‹è¯•æ—¶å¢å¼º + æ¨¡å‹èåˆ |

**æ•°æ®å¤„ç†æµç¨‹**ï¼š

```python
def process_dicom(dicom_path):
    # è¯»å– DICOM åºåˆ—
    slices = load_dicom_series(dicom_path)

    # çª—å®½çª—ä½è°ƒæ•´
    volume = apply_windowing(slices, window_center=40, window_width=400)

    # é‡é‡‡æ ·åˆ°ç»Ÿä¸€å°ºå¯¸
    volume = resample_volume(volume, target_spacing=[1.5, 1.5, 3.0])

    return volume
```

---

## é¡¹ç›®è¿è¡ŒæŒ‡å—

### ç¯å¢ƒå‡†å¤‡

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd 09-practical-projects

# å®‰è£…é¡¹ç›®ä¾èµ–
pip install -r requirements.txt

# ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚éœ€è¦ï¼‰
python scripts/download_models.py
```

### è¿è¡Œç¤ºä¾‹

::: code-group

```bash [Titanic]
cd 01-ml-basics/titanic-survival-xgboost
jupyter lab titanic_analysis.ipynb
```

```bash [Feedback Prize]
cd 05-kaggle-competitions/01-Feedback-ELL
python train.py --config configs/deberta_large.yaml
```

```bash [RSNA]
cd 05-kaggle-competitions/02-RSNA-Abdominal
python train.py --fold 0 --model efficientnet_b5
```

:::

---

## å­¦ä¹ å»ºè®®

### å…¥é—¨è€…è·¯çº¿

```
Titanic â”€â”€â–º MNIST â”€â”€â–º æƒ…æ„Ÿåˆ†æ â”€â”€â–º æ¸©åº¦é¢„æµ‹
   â”‚          â”‚          â”‚           â”‚
   â–¼          â–¼          â–¼           â–¼
 ç‰¹å¾å·¥ç¨‹    CNNåŸºç¡€    RNN/LSTM    æ—¶åºå»ºæ¨¡
```

### è¿›é˜¶è€…è·¯çº¿

```
Otto å¤šåˆ†ç±» â”€â”€â–º Transformer æ–‡æœ¬åˆ†ç±» â”€â”€â–º Kaggle é“¶ç‰Œæ–¹æ¡ˆ
      â”‚                â”‚                      â”‚
      â–¼                â–¼                      â–¼
   é›†æˆå­¦ä¹       æ³¨æ„åŠ›æœºåˆ¶           å·¥ä¸šçº§æ–¹æ¡ˆ
```

### ç«èµ›è€…è·¯çº¿

```
Kaggle é“œç‰Œ â”€â”€â–º Kaggle é“¶ç‰Œ â”€â”€â–º Kaggle é‡‘ç‰Œ
      â”‚              â”‚              â”‚
      â–¼              â–¼              â–¼
   åŸºç¡€æ–¹æ¡ˆ      ä¼˜åŒ–æŠ€å·§      é¡¶çº§æ–¹æ¡ˆ
```

---

## å‚è€ƒèµ„æº

### Kaggle ç›¸å…³
- [Kaggle å®˜æ–¹æ–‡æ¡£](https://www.kaggle.com/docs)
- [Kaggle ç«èµ›æŠ€å·§æ±‡æ€»](https://www.kaggle.com/competitions)

### è®ºæ–‡
- Vaswani et al. (2017). Attention Is All You Need
- He et al. (2020). DeBERTa: Decoding-enhanced BERT with Disentangled Attention

### å·¥å…·
- [Weights & Biases](https://wandb.ai/) - å®éªŒè¿½è¸ª
- [Optuna](https://optuna.org/) - è¶…å‚æ•°ä¼˜åŒ–
